{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical,np_utils\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, LSTM, Activation,Dropout,Masking, Embedding\n",
    "from keras import optimizers\n",
    "from  keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.image as pimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_plot(self,n_epochs):\n",
    "    #iters = range(len(self.epoch))\n",
    "    iters = range(n_epochs)\n",
    "    plt.figure()\n",
    "    # acc\n",
    "    plt.plot(iters, self.history['acc'] [:n_epochs],'r', label='train acc', linewidth=1.0)\n",
    "    # loss\n",
    "    plt.plot(iters, self.history['loss'][:n_epochs], 'g', label='train loss', linewidth=1.0)\n",
    "    \n",
    "    # val_acc\n",
    "    plt.plot(iters, self.history['val_acc'][:n_epochs], 'b', label='val acc', linewidth=1.0)\n",
    "    # val_loss\n",
    "    plt.plot(iters, self.history['val_loss'][:n_epochs], 'k', label='val loss', linewidth=1.0)\n",
    "    plt.grid(True)\n",
    "    plt.ylim(0,1.2)\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(loc='best',shadow=True, fontsize='6')#loc=\"upper right\"\n",
    "    plt.savefig('loss of lstm 01.png', dpi=400)\n",
    "    sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_data_01=np.load('D:\\\\GitHub\\\\Neural-Network-Theory-and-Applications-Homework-SJTU2018\\\\Homework Assignment 4\\\\data_used\\\\01.npz')\n",
    "files_in_zip_01 = zip_data_01.keys()\n",
    "label01= np.load('D:\\\\GitHub\\\\Neural-Network-Theory-and-Applications-Homework-SJTU2018\\\\Homework Assignment 4\\\\data_used\\\\label.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下一个cell：数据预处理，将01.npz数据集变成（15,265,310）的形式，长度不够265的补零\n",
    "也就是说，将变长序列变为定长序列，\n",
    "变形方法：https://stackoverflow.com/questions/35751306/python-how-to-pad-numpy-array-with-zeros \n",
    "行为解释：https://www.cnblogs.com/leeshum/p/6089286.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data01=np.zeros((15,265,310))\n",
    "for i in range(15):\n",
    "    for j in range(265):\n",
    "        if j < zip_data_01[files_in_zip_01[i]].shape[1]:\n",
    "            data01[i,j,:]=zip_data_01[files_in_zip_01[i]][:,j,:].reshape(310)\n",
    "        else:\n",
    "            data01[i,j,:]=np.zeros(310)\n",
    "data01/=np.max(data01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=data01[:9,:,:]\n",
    "x_test=data01[9:,:,:]\n",
    "y_train=label01[:9]\n",
    "y_test=label01[9:]\n",
    "y_train = np_utils.to_categorical(y_train, num_classes=3)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_1 (Masking)          (None, 265, 310)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 265, 310)          770040    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               224768    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 1,003,259\n",
      "Trainable params: 1,003,259\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "    #model.add(Embedding(81250, 128, mask_zero=True))\n",
    "model.add(Masking(mask_value=0,input_shape=(265, 310)))\n",
    "model.add(LSTM(128,return_sequences=True))#\n",
    "#model.add(Activation('relu'))\n",
    "model.add(LSTM(128))\n",
    "#model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "RMS = optimizers.RMSprop(lr=1e-5)\n",
    "model.compile(optimizer=RMS,\n",
    "      loss='categorical_crossentropy',\n",
    "      metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "filepath=\"model-3-best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "earlystop=EarlyStopping(monitor='val_loss', patience=20, verbose=2, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load a model\n",
    "model=load_model('D:/GitHub/Neural-Network-Theory-and-Applications-Homework-SJTU2018/Homework Assignment 4/model-3-best.hdf5')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ------------\n",
      "Train on 9 samples, validate on 6 samples\n",
      "Epoch 1/600\n",
      "Epoch 00001: val_loss improved from inf to 1.11676, saving model to model-3-best.hdf5\n",
      " - 6s - loss: 1.1321 - acc: 0.5556 - val_loss: 1.1168 - val_acc: 0.3333\n",
      "Epoch 2/600\n",
      "Epoch 00002: val_loss improved from 1.11676 to 1.09272, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.1041 - acc: 0.4444 - val_loss: 1.0927 - val_acc: 0.5000\n",
      "Epoch 3/600\n",
      "Epoch 00003: val_loss improved from 1.09272 to 1.08368, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0899 - acc: 0.4444 - val_loss: 1.0837 - val_acc: 0.5000\n",
      "Epoch 4/600\n",
      "Epoch 00004: val_loss improved from 1.08368 to 1.07328, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0795 - acc: 0.5556 - val_loss: 1.0733 - val_acc: 0.5000\n",
      "Epoch 5/600\n",
      "Epoch 00005: val_loss improved from 1.07328 to 1.06056, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0722 - acc: 0.5556 - val_loss: 1.0606 - val_acc: 0.5000\n",
      "Epoch 6/600\n",
      "Epoch 00006: val_loss improved from 1.06056 to 1.05324, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0644 - acc: 0.4444 - val_loss: 1.0532 - val_acc: 0.5000\n",
      "Epoch 7/600\n",
      "Epoch 00007: val_loss improved from 1.05324 to 1.04546, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0549 - acc: 0.4444 - val_loss: 1.0455 - val_acc: 0.5000\n",
      "Epoch 8/600\n",
      "Epoch 00008: val_loss improved from 1.04546 to 1.04059, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0481 - acc: 0.3333 - val_loss: 1.0406 - val_acc: 0.5000\n",
      "Epoch 9/600\n",
      "Epoch 00009: val_loss improved from 1.04059 to 1.03624, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0427 - acc: 0.3333 - val_loss: 1.0362 - val_acc: 0.5000\n",
      "Epoch 10/600\n",
      "Epoch 00010: val_loss improved from 1.03624 to 1.03269, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0376 - acc: 0.3333 - val_loss: 1.0327 - val_acc: 0.5000\n",
      "Epoch 11/600\n",
      "Epoch 00011: val_loss improved from 1.03269 to 1.02862, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0333 - acc: 0.4444 - val_loss: 1.0286 - val_acc: 0.5000\n",
      "Epoch 12/600\n",
      "Epoch 00012: val_loss improved from 1.02862 to 1.02640, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0295 - acc: 0.4444 - val_loss: 1.0264 - val_acc: 0.5000\n",
      "Epoch 13/600\n",
      "Epoch 00013: val_loss improved from 1.02640 to 1.02127, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0250 - acc: 0.4444 - val_loss: 1.0213 - val_acc: 0.5000\n",
      "Epoch 14/600\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 3s - loss: 1.0219 - acc: 0.4444 - val_loss: 1.0234 - val_acc: 0.5000\n",
      "Epoch 15/600\n",
      "Epoch 00015: val_loss improved from 1.02127 to 1.01441, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0198 - acc: 0.4444 - val_loss: 1.0144 - val_acc: 0.5000\n",
      "Epoch 16/600\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 3s - loss: 1.0179 - acc: 0.4444 - val_loss: 1.0212 - val_acc: 0.5000\n",
      "Epoch 17/600\n",
      "Epoch 00017: val_loss improved from 1.01441 to 1.01226, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0151 - acc: 0.4444 - val_loss: 1.0123 - val_acc: 0.5000\n",
      "Epoch 18/600\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 3s - loss: 1.0107 - acc: 0.4444 - val_loss: 1.0187 - val_acc: 0.6667\n",
      "Epoch 19/600\n",
      "Epoch 00019: val_loss improved from 1.01226 to 1.00871, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0078 - acc: 0.5556 - val_loss: 1.0087 - val_acc: 0.6667\n",
      "Epoch 20/600\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 3s - loss: 1.0048 - acc: 0.7778 - val_loss: 1.0207 - val_acc: 0.6667\n",
      "Epoch 21/600\n",
      "Epoch 00021: val_loss improved from 1.00871 to 0.99298, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0035 - acc: 0.6667 - val_loss: 0.9930 - val_acc: 0.6667\n",
      "Epoch 22/600\n",
      "Epoch 00022: val_loss improved from 0.99298 to 0.98610, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9893 - acc: 0.8889 - val_loss: 0.9861 - val_acc: 0.6667\n",
      "Epoch 23/600\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 3s - loss: 0.9826 - acc: 0.8889 - val_loss: 0.9937 - val_acc: 0.8333\n",
      "Epoch 24/600\n",
      "Epoch 00024: val_loss improved from 0.98610 to 0.98005, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9853 - acc: 1.0000 - val_loss: 0.9800 - val_acc: 0.8333\n",
      "Epoch 25/600\n",
      "Epoch 00025: val_loss improved from 0.98005 to 0.97699, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9737 - acc: 1.0000 - val_loss: 0.9770 - val_acc: 0.8333\n",
      "Epoch 26/600\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 3s - loss: 0.9880 - acc: 0.8889 - val_loss: 0.9788 - val_acc: 0.8333\n",
      "Epoch 27/600\n",
      "Epoch 00027: val_loss improved from 0.97699 to 0.97297, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9728 - acc: 1.0000 - val_loss: 0.9730 - val_acc: 0.8333\n",
      "Epoch 28/600\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 3s - loss: 0.9690 - acc: 1.0000 - val_loss: 0.9906 - val_acc: 0.8333\n",
      "Epoch 29/600\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 3s - loss: 0.9806 - acc: 1.0000 - val_loss: 0.9897 - val_acc: 0.8333\n",
      "Epoch 30/600\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 3s - loss: 0.9762 - acc: 1.0000 - val_loss: 0.9885 - val_acc: 0.8333\n",
      "Epoch 31/600\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 3s - loss: 0.9732 - acc: 1.0000 - val_loss: 0.9871 - val_acc: 0.8333\n",
      "Epoch 32/600\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 3s - loss: 0.9702 - acc: 1.0000 - val_loss: 0.9858 - val_acc: 0.8333\n",
      "Epoch 33/600\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 3s - loss: 0.9670 - acc: 1.0000 - val_loss: 0.9847 - val_acc: 0.8333\n",
      "Epoch 34/600\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 3s - loss: 0.9636 - acc: 1.0000 - val_loss: 0.9830 - val_acc: 0.8333\n",
      "Epoch 35/600\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 3s - loss: 0.9604 - acc: 1.0000 - val_loss: 0.9821 - val_acc: 0.8333\n",
      "Epoch 36/600\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 3s - loss: 0.9573 - acc: 1.0000 - val_loss: 0.9797 - val_acc: 0.8333\n",
      "Epoch 37/600\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 3s - loss: 0.9541 - acc: 1.0000 - val_loss: 0.9788 - val_acc: 0.8333\n",
      "Epoch 38/600\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 3s - loss: 0.9505 - acc: 1.0000 - val_loss: 0.9769 - val_acc: 0.8333\n",
      "Epoch 39/600\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 3s - loss: 0.9477 - acc: 1.0000 - val_loss: 0.9754 - val_acc: 0.8333\n",
      "Epoch 40/600\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 3s - loss: 0.9451 - acc: 1.0000 - val_loss: 0.9735 - val_acc: 0.8333\n",
      "Epoch 41/600\n",
      "Epoch 00041: val_loss improved from 0.97297 to 0.97219, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9420 - acc: 1.0000 - val_loss: 0.9722 - val_acc: 0.8333\n",
      "Epoch 42/600\n",
      "Epoch 00042: val_loss improved from 0.97219 to 0.97035, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9394 - acc: 1.0000 - val_loss: 0.9704 - val_acc: 0.8333\n",
      "Epoch 43/600\n",
      "Epoch 00043: val_loss improved from 0.97035 to 0.96892, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9379 - acc: 1.0000 - val_loss: 0.9689 - val_acc: 0.8333\n",
      "Epoch 44/600\n",
      "Epoch 00044: val_loss improved from 0.96892 to 0.96583, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9377 - acc: 1.0000 - val_loss: 0.9658 - val_acc: 0.8333\n",
      "Epoch 45/600\n",
      "Epoch 00045: val_loss improved from 0.96583 to 0.96456, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9305 - acc: 1.0000 - val_loss: 0.9646 - val_acc: 0.8333\n",
      "Epoch 46/600\n",
      "Epoch 00046: val_loss improved from 0.96456 to 0.96080, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9277 - acc: 1.0000 - val_loss: 0.9608 - val_acc: 0.8333\n",
      "Epoch 47/600\n",
      "Epoch 00047: val_loss improved from 0.96080 to 0.95933, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9253 - acc: 1.0000 - val_loss: 0.9593 - val_acc: 0.8333\n",
      "Epoch 48/600\n",
      "Epoch 00048: val_loss improved from 0.95933 to 0.94999, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9231 - acc: 1.0000 - val_loss: 0.9500 - val_acc: 0.8333\n",
      "Epoch 49/600\n",
      "Epoch 00049: val_loss improved from 0.94999 to 0.94693, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9195 - acc: 1.0000 - val_loss: 0.9469 - val_acc: 0.8333\n",
      "Epoch 50/600\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 3s - loss: 0.9061 - acc: 1.0000 - val_loss: 0.9701 - val_acc: 0.8333\n",
      "Epoch 51/600\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 3s - loss: 0.9264 - acc: 1.0000 - val_loss: 0.9570 - val_acc: 0.8333\n",
      "Epoch 52/600\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 3s - loss: 0.9119 - acc: 1.0000 - val_loss: 0.9529 - val_acc: 0.8333\n",
      "Epoch 53/600\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 3s - loss: 0.9064 - acc: 1.0000 - val_loss: 0.9501 - val_acc: 0.8333\n",
      "Epoch 54/600\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 3s - loss: 0.9009 - acc: 1.0000 - val_loss: 0.9477 - val_acc: 0.8333\n",
      "Epoch 55/600\n",
      "Epoch 00055: val_loss improved from 0.94693 to 0.94635, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8966 - acc: 1.0000 - val_loss: 0.9463 - val_acc: 0.8333\n",
      "Epoch 56/600\n",
      "Epoch 00056: val_loss improved from 0.94635 to 0.94528, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8928 - acc: 1.0000 - val_loss: 0.9453 - val_acc: 0.8333\n",
      "Epoch 57/600\n",
      "Epoch 00057: val_loss improved from 0.94528 to 0.94420, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8893 - acc: 1.0000 - val_loss: 0.9442 - val_acc: 0.8333\n",
      "Epoch 58/600\n",
      "Epoch 00058: val_loss improved from 0.94420 to 0.94318, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8862 - acc: 1.0000 - val_loss: 0.9432 - val_acc: 0.8333\n",
      "Epoch 59/600\n",
      "Epoch 00059: val_loss improved from 0.94318 to 0.94238, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8833 - acc: 1.0000 - val_loss: 0.9424 - val_acc: 0.8333\n",
      "Epoch 60/600\n",
      "Epoch 00060: val_loss improved from 0.94238 to 0.94085, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8806 - acc: 1.0000 - val_loss: 0.9409 - val_acc: 0.8333\n",
      "Epoch 61/600\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 3s - loss: 0.8812 - acc: 1.0000 - val_loss: 0.9409 - val_acc: 0.8333\n",
      "Epoch 62/600\n",
      "Epoch 00062: val_loss improved from 0.94085 to 0.93714, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8800 - acc: 1.0000 - val_loss: 0.9371 - val_acc: 0.8333\n",
      "Epoch 63/600\n",
      "Epoch 00063: val_loss did not improve\n",
      " - 3s - loss: 0.8751 - acc: 1.0000 - val_loss: 0.9379 - val_acc: 0.8333\n",
      "Epoch 64/600\n",
      "Epoch 00064: val_loss improved from 0.93714 to 0.92924, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8977 - acc: 0.8889 - val_loss: 0.9292 - val_acc: 0.8333\n",
      "Epoch 65/600\n",
      "Epoch 00065: val_loss improved from 0.92924 to 0.92783, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8867 - acc: 1.0000 - val_loss: 0.9278 - val_acc: 0.8333\n",
      "Epoch 66/600\n",
      "Epoch 00066: val_loss did not improve\n",
      " - 3s - loss: 0.8591 - acc: 1.0000 - val_loss: 0.9393 - val_acc: 0.8333\n",
      "Epoch 67/600\n",
      "Epoch 00067: val_loss did not improve\n",
      " - 3s - loss: 0.8939 - acc: 0.8889 - val_loss: 0.9357 - val_acc: 0.8333\n",
      "Epoch 68/600\n",
      "Epoch 00068: val_loss improved from 0.92783 to 0.92222, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9162 - acc: 0.7778 - val_loss: 0.9222 - val_acc: 0.8333\n",
      "Epoch 69/600\n",
      "Epoch 00069: val_loss improved from 0.92222 to 0.91773, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9101 - acc: 0.8889 - val_loss: 0.9177 - val_acc: 0.8333\n",
      "Epoch 70/600\n",
      "Epoch 00070: val_loss improved from 0.91773 to 0.91279, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8906 - acc: 1.0000 - val_loss: 0.9128 - val_acc: 0.8333\n",
      "Epoch 71/600\n",
      "Epoch 00071: val_loss improved from 0.91279 to 0.91038, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8839 - acc: 1.0000 - val_loss: 0.9104 - val_acc: 0.8333\n",
      "Epoch 72/600\n",
      "Epoch 00072: val_loss improved from 0.91038 to 0.90945, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8771 - acc: 1.0000 - val_loss: 0.9094 - val_acc: 0.8333\n",
      "Epoch 73/600\n",
      "Epoch 00073: val_loss improved from 0.90945 to 0.90836, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8737 - acc: 1.0000 - val_loss: 0.9084 - val_acc: 0.8333\n",
      "Epoch 74/600\n",
      "Epoch 00074: val_loss improved from 0.90836 to 0.90689, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8710 - acc: 1.0000 - val_loss: 0.9069 - val_acc: 0.8333\n",
      "Epoch 75/600\n",
      "Epoch 00075: val_loss improved from 0.90689 to 0.90535, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8742 - acc: 1.0000 - val_loss: 0.9053 - val_acc: 0.8333\n",
      "Epoch 76/600\n",
      "Epoch 00076: val_loss improved from 0.90535 to 0.90377, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8709 - acc: 1.0000 - val_loss: 0.9038 - val_acc: 0.8333\n",
      "Epoch 77/600\n",
      "Epoch 00077: val_loss improved from 0.90377 to 0.90249, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8643 - acc: 1.0000 - val_loss: 0.9025 - val_acc: 0.8333\n",
      "Epoch 78/600\n",
      "Epoch 00078: val_loss improved from 0.90249 to 0.90127, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8607 - acc: 1.0000 - val_loss: 0.9013 - val_acc: 0.8333\n",
      "Epoch 79/600\n",
      "Epoch 00079: val_loss improved from 0.90127 to 0.90004, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8572 - acc: 1.0000 - val_loss: 0.9000 - val_acc: 0.8333\n",
      "Epoch 80/600\n",
      "Epoch 00080: val_loss improved from 0.90004 to 0.89831, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8539 - acc: 1.0000 - val_loss: 0.8983 - val_acc: 0.8333\n",
      "Epoch 81/600\n",
      "Epoch 00081: val_loss improved from 0.89831 to 0.89688, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8512 - acc: 1.0000 - val_loss: 0.8969 - val_acc: 0.8333\n",
      "Epoch 82/600\n",
      "Epoch 00082: val_loss improved from 0.89688 to 0.89519, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8486 - acc: 1.0000 - val_loss: 0.8952 - val_acc: 0.8333\n",
      "Epoch 83/600\n",
      "Epoch 00083: val_loss improved from 0.89519 to 0.89391, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8463 - acc: 1.0000 - val_loss: 0.8939 - val_acc: 0.8333\n",
      "Epoch 84/600\n",
      "Epoch 00084: val_loss improved from 0.89391 to 0.89202, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8438 - acc: 1.0000 - val_loss: 0.8920 - val_acc: 0.8333\n",
      "Epoch 85/600\n",
      "Epoch 00085: val_loss improved from 0.89202 to 0.89173, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8412 - acc: 1.0000 - val_loss: 0.8917 - val_acc: 0.8333\n",
      "Epoch 86/600\n",
      "Epoch 00086: val_loss improved from 0.89173 to 0.88982, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8391 - acc: 1.0000 - val_loss: 0.8898 - val_acc: 0.8333\n",
      "Epoch 87/600\n",
      "Epoch 00087: val_loss improved from 0.88982 to 0.88957, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8366 - acc: 1.0000 - val_loss: 0.8896 - val_acc: 0.8333\n",
      "Epoch 88/600\n",
      "Epoch 00088: val_loss improved from 0.88957 to 0.88702, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8344 - acc: 1.0000 - val_loss: 0.8870 - val_acc: 0.8333\n",
      "Epoch 89/600\n",
      "Epoch 00089: val_loss improved from 0.88702 to 0.88693, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8315 - acc: 1.0000 - val_loss: 0.8869 - val_acc: 0.8333\n",
      "Epoch 90/600\n",
      "Epoch 00090: val_loss improved from 0.88693 to 0.88347, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8290 - acc: 1.0000 - val_loss: 0.8835 - val_acc: 0.8333\n",
      "Epoch 91/600\n",
      "Epoch 00091: val_loss did not improve\n",
      " - 3s - loss: 0.8268 - acc: 1.0000 - val_loss: 0.8842 - val_acc: 0.8333\n",
      "Epoch 92/600\n",
      "Epoch 00092: val_loss improved from 0.88347 to 0.88194, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8260 - acc: 1.0000 - val_loss: 0.8819 - val_acc: 0.8333\n",
      "Epoch 93/600\n",
      "Epoch 00093: val_loss improved from 0.88194 to 0.87964, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8259 - acc: 1.0000 - val_loss: 0.8796 - val_acc: 0.8333\n",
      "Epoch 94/600\n",
      "Epoch 00094: val_loss improved from 0.87964 to 0.87656, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8244 - acc: 1.0000 - val_loss: 0.8766 - val_acc: 0.8333\n",
      "Epoch 95/600\n",
      "Epoch 00095: val_loss improved from 0.87656 to 0.87640, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8206 - acc: 1.0000 - val_loss: 0.8764 - val_acc: 0.8333\n",
      "Epoch 96/600\n",
      "Epoch 00096: val_loss improved from 0.87640 to 0.87427, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8157 - acc: 1.0000 - val_loss: 0.8743 - val_acc: 0.8333\n",
      "Epoch 97/600\n",
      "Epoch 00097: val_loss did not improve\n",
      " - 3s - loss: 0.8126 - acc: 1.0000 - val_loss: 0.8759 - val_acc: 0.8333\n",
      "Epoch 98/600\n",
      "Epoch 00098: val_loss improved from 0.87427 to 0.87163, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8102 - acc: 1.0000 - val_loss: 0.8716 - val_acc: 0.8333\n",
      "Epoch 99/600\n",
      "Epoch 00099: val_loss did not improve\n",
      " - 3s - loss: 0.8072 - acc: 1.0000 - val_loss: 0.8767 - val_acc: 0.8333\n",
      "Epoch 100/600\n",
      "Epoch 00100: val_loss improved from 0.87163 to 0.86646, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8053 - acc: 1.0000 - val_loss: 0.8665 - val_acc: 0.8333\n",
      "Epoch 101/600\n",
      "Epoch 00101: val_loss did not improve\n",
      " - 3s - loss: 0.8036 - acc: 1.0000 - val_loss: 0.8702 - val_acc: 0.6667\n",
      "Epoch 102/600\n",
      "Epoch 00102: val_loss did not improve\n",
      " - 3s - loss: 0.8075 - acc: 1.0000 - val_loss: 0.8800 - val_acc: 1.0000\n",
      "Epoch 103/600\n",
      "Epoch 00103: val_loss improved from 0.86646 to 0.86420, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8275 - acc: 1.0000 - val_loss: 0.8642 - val_acc: 0.8333\n",
      "Epoch 104/600\n",
      "Epoch 00104: val_loss did not improve\n",
      " - 3s - loss: 0.8092 - acc: 1.0000 - val_loss: 0.8996 - val_acc: 0.8333\n",
      "Epoch 105/600\n",
      "Epoch 00105: val_loss did not improve\n",
      " - 3s - loss: 0.8234 - acc: 1.0000 - val_loss: 0.8674 - val_acc: 0.6667\n",
      "Epoch 106/600\n",
      "Epoch 00106: val_loss improved from 0.86420 to 0.85892, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8098 - acc: 1.0000 - val_loss: 0.8589 - val_acc: 0.8333\n",
      "Epoch 107/600\n",
      "Epoch 00107: val_loss did not improve\n",
      " - 3s - loss: 0.8057 - acc: 1.0000 - val_loss: 0.8620 - val_acc: 0.8333\n",
      "Epoch 108/600\n",
      "Epoch 00108: val_loss did not improve\n",
      " - 3s - loss: 0.7993 - acc: 1.0000 - val_loss: 0.8626 - val_acc: 0.6667\n",
      "Epoch 109/600\n",
      "Epoch 00109: val_loss did not improve\n",
      " - 3s - loss: 0.7886 - acc: 1.0000 - val_loss: 0.8672 - val_acc: 0.8333\n",
      "Epoch 110/600\n",
      "Epoch 00110: val_loss improved from 0.85892 to 0.85718, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7874 - acc: 1.0000 - val_loss: 0.8572 - val_acc: 0.8333\n",
      "Epoch 111/600\n",
      "Epoch 00111: val_loss did not improve\n",
      " - 3s - loss: 0.7815 - acc: 1.0000 - val_loss: 0.8593 - val_acc: 0.8333\n",
      "Epoch 112/600\n",
      "Epoch 00112: val_loss did not improve\n",
      " - 3s - loss: 0.7999 - acc: 1.0000 - val_loss: 0.8744 - val_acc: 0.8333\n",
      "Epoch 113/600\n",
      "Epoch 00113: val_loss did not improve\n",
      " - 3s - loss: 0.8432 - acc: 0.7778 - val_loss: 0.8712 - val_acc: 0.8333\n",
      "Epoch 114/600\n",
      "Epoch 00114: val_loss did not improve\n",
      " - 3s - loss: 0.8389 - acc: 0.8889 - val_loss: 0.8692 - val_acc: 0.8333\n",
      "Epoch 115/600\n",
      "Epoch 00115: val_loss did not improve\n",
      " - 3s - loss: 0.8289 - acc: 0.8889 - val_loss: 0.8686 - val_acc: 0.8333\n",
      "Epoch 116/600\n",
      "Epoch 00116: val_loss did not improve\n",
      " - 3s - loss: 0.8236 - acc: 0.8889 - val_loss: 0.8653 - val_acc: 0.8333\n",
      "Epoch 117/600\n",
      "Epoch 00117: val_loss did not improve\n",
      " - 3s - loss: 0.8224 - acc: 0.8889 - val_loss: 0.8632 - val_acc: 0.8333\n",
      "Epoch 118/600\n",
      "Epoch 00118: val_loss did not improve\n",
      " - 3s - loss: 0.8179 - acc: 0.8889 - val_loss: 0.8596 - val_acc: 0.8333\n",
      "Epoch 119/600\n",
      "Epoch 00119: val_loss improved from 0.85718 to 0.85435, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8160 - acc: 1.0000 - val_loss: 0.8544 - val_acc: 0.8333\n",
      "Epoch 120/600\n",
      "Epoch 00120: val_loss did not improve\n",
      " - 3s - loss: 0.8125 - acc: 0.8889 - val_loss: 0.8574 - val_acc: 0.8333\n",
      "Epoch 121/600\n",
      "Epoch 00121: val_loss improved from 0.85435 to 0.84870, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8108 - acc: 1.0000 - val_loss: 0.8487 - val_acc: 0.8333\n",
      "Epoch 122/600\n",
      "Epoch 00122: val_loss did not improve\n",
      " - 3s - loss: 0.7899 - acc: 1.0000 - val_loss: 0.8502 - val_acc: 0.8333\n",
      "Epoch 123/600\n",
      "Epoch 00123: val_loss did not improve\n",
      " - 3s - loss: 0.7811 - acc: 1.0000 - val_loss: 0.8767 - val_acc: 0.8333\n",
      "Epoch 124/600\n",
      "Epoch 00124: val_loss did not improve\n",
      " - 3s - loss: 0.8166 - acc: 0.8889 - val_loss: 0.8726 - val_acc: 0.8333\n",
      "Epoch 125/600\n",
      "Epoch 00125: val_loss did not improve\n",
      " - 3s - loss: 0.8063 - acc: 0.8889 - val_loss: 0.8728 - val_acc: 0.8333\n",
      "Epoch 126/600\n",
      "Epoch 00126: val_loss did not improve\n",
      " - 3s - loss: 0.8015 - acc: 0.8889 - val_loss: 0.8700 - val_acc: 0.8333\n",
      "Epoch 127/600\n",
      "Epoch 00127: val_loss did not improve\n",
      " - 3s - loss: 0.7963 - acc: 0.8889 - val_loss: 0.8510 - val_acc: 0.8333\n",
      "Epoch 128/600\n",
      "Epoch 00128: val_loss improved from 0.84870 to 0.84148, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7695 - acc: 1.0000 - val_loss: 0.8415 - val_acc: 0.8333\n",
      "Epoch 129/600\n",
      "Epoch 00129: val_loss improved from 0.84148 to 0.83533, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7655 - acc: 1.0000 - val_loss: 0.8353 - val_acc: 0.8333\n",
      "Epoch 130/600\n",
      "Epoch 00130: val_loss did not improve\n",
      " - 3s - loss: 0.7627 - acc: 1.0000 - val_loss: 0.8366 - val_acc: 0.8333\n",
      "Epoch 131/600\n",
      "Epoch 00131: val_loss improved from 0.83533 to 0.82911, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7613 - acc: 1.0000 - val_loss: 0.8291 - val_acc: 0.8333\n",
      "Epoch 132/600\n",
      "Epoch 00132: val_loss did not improve\n",
      " - 3s - loss: 0.7605 - acc: 1.0000 - val_loss: 0.8369 - val_acc: 0.6667\n",
      "Epoch 133/600\n",
      "Epoch 00133: val_loss improved from 0.82911 to 0.82238, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7613 - acc: 1.0000 - val_loss: 0.8224 - val_acc: 0.8333\n",
      "Epoch 134/600\n",
      "Epoch 00134: val_loss did not improve\n",
      " - 3s - loss: 0.7592 - acc: 1.0000 - val_loss: 0.8338 - val_acc: 0.6667\n",
      "Epoch 135/600\n",
      "Epoch 00135: val_loss improved from 0.82238 to 0.82031, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7601 - acc: 1.0000 - val_loss: 0.8203 - val_acc: 0.8333\n",
      "Epoch 136/600\n",
      "Epoch 00136: val_loss did not improve\n",
      " - 3s - loss: 0.7577 - acc: 1.0000 - val_loss: 0.8330 - val_acc: 0.6667\n",
      "Epoch 137/600\n",
      "Epoch 00137: val_loss did not improve\n",
      " - 3s - loss: 0.7482 - acc: 1.0000 - val_loss: 0.8247 - val_acc: 0.8333\n",
      "Epoch 138/600\n",
      "Epoch 00138: val_loss did not improve\n",
      " - 3s - loss: 0.7445 - acc: 1.0000 - val_loss: 0.8300 - val_acc: 0.8333\n",
      "Epoch 139/600\n",
      "Epoch 00139: val_loss did not improve\n",
      " - 3s - loss: 0.7431 - acc: 1.0000 - val_loss: 0.8228 - val_acc: 0.8333\n",
      "Epoch 140/600\n",
      "Epoch 00140: val_loss did not improve\n",
      " - 3s - loss: 0.7405 - acc: 1.0000 - val_loss: 0.8307 - val_acc: 0.6667\n",
      "Epoch 141/600\n",
      "Epoch 00141: val_loss improved from 0.82031 to 0.81719, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7377 - acc: 1.0000 - val_loss: 0.8172 - val_acc: 0.8333\n",
      "Epoch 142/600\n",
      "Epoch 00142: val_loss did not improve\n",
      " - 3s - loss: 0.7409 - acc: 1.0000 - val_loss: 0.8269 - val_acc: 0.6667\n",
      "Epoch 143/600\n",
      "Epoch 00143: val_loss improved from 0.81719 to 0.80974, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7236 - acc: 1.0000 - val_loss: 0.8097 - val_acc: 0.8333\n",
      "Epoch 144/600\n",
      "Epoch 00144: val_loss did not improve\n",
      " - 3s - loss: 0.7214 - acc: 1.0000 - val_loss: 0.8236 - val_acc: 0.6667\n",
      "Epoch 145/600\n",
      "Epoch 00145: val_loss did not improve\n",
      " - 3s - loss: 0.7332 - acc: 1.0000 - val_loss: 0.8283 - val_acc: 0.8333\n",
      "Epoch 146/600\n",
      "Epoch 00146: val_loss did not improve\n",
      " - 3s - loss: 0.7575 - acc: 0.8889 - val_loss: 0.8408 - val_acc: 0.6667\n",
      "Epoch 147/600\n",
      "Epoch 00147: val_loss did not improve\n",
      " - 3s - loss: 0.7537 - acc: 1.0000 - val_loss: 0.8230 - val_acc: 0.8333\n",
      "Epoch 148/600\n",
      "Epoch 00148: val_loss did not improve\n",
      " - 3s - loss: 0.7514 - acc: 1.0000 - val_loss: 0.8205 - val_acc: 0.8333\n",
      "Epoch 149/600\n",
      "Epoch 00149: val_loss did not improve\n",
      " - 3s - loss: 0.7314 - acc: 1.0000 - val_loss: 0.8144 - val_acc: 0.8333\n",
      "Epoch 150/600\n",
      "Epoch 00150: val_loss did not improve\n",
      " - 3s - loss: 0.7137 - acc: 1.0000 - val_loss: 0.8463 - val_acc: 0.6667\n",
      "Epoch 151/600\n",
      "Epoch 00151: val_loss did not improve\n",
      " - 3s - loss: 0.7096 - acc: 1.0000 - val_loss: 0.8302 - val_acc: 0.8333\n",
      "Epoch 152/600\n",
      "Epoch 00152: val_loss did not improve\n",
      " - 3s - loss: 0.7081 - acc: 1.0000 - val_loss: 0.8184 - val_acc: 0.6667\n",
      "Epoch 153/600\n",
      "Epoch 00153: val_loss did not improve\n",
      " - 3s - loss: 0.7063 - acc: 1.0000 - val_loss: 0.8221 - val_acc: 0.8333\n",
      "Epoch 154/600\n",
      "Epoch 00154: val_loss did not improve\n",
      " - 3s - loss: 0.7055 - acc: 1.0000 - val_loss: 0.8322 - val_acc: 0.8333\n",
      "Epoch 155/600\n",
      "Epoch 00155: val_loss did not improve\n",
      " - 3s - loss: 0.7094 - acc: 1.0000 - val_loss: 0.8599 - val_acc: 0.8333\n",
      "Epoch 156/600\n",
      "Epoch 00156: val_loss did not improve\n",
      " - 3s - loss: 0.7683 - acc: 0.8889 - val_loss: 0.8169 - val_acc: 0.8333\n",
      "Epoch 157/600\n",
      "Epoch 00157: val_loss did not improve\n",
      " - 3s - loss: 0.7665 - acc: 1.0000 - val_loss: 0.8123 - val_acc: 0.8333\n",
      "Epoch 158/600\n",
      "Epoch 00158: val_loss did not improve\n",
      " - 3s - loss: 0.7397 - acc: 1.0000 - val_loss: 0.8341 - val_acc: 0.8333\n",
      "Epoch 159/600\n",
      "Epoch 00159: val_loss did not improve\n",
      " - 3s - loss: 0.7319 - acc: 1.0000 - val_loss: 0.8399 - val_acc: 0.6667\n",
      "Epoch 160/600\n",
      "Epoch 00160: val_loss improved from 0.80974 to 0.78896, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7305 - acc: 1.0000 - val_loss: 0.7890 - val_acc: 0.8333\n",
      "Epoch 161/600\n",
      "Epoch 00161: val_loss did not improve\n",
      " - 3s - loss: 0.7040 - acc: 1.0000 - val_loss: 0.8045 - val_acc: 0.6667\n",
      "Epoch 162/600\n",
      "Epoch 00162: val_loss improved from 0.78896 to 0.78729, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.6965 - acc: 1.0000 - val_loss: 0.7873 - val_acc: 0.8333\n",
      "Epoch 163/600\n",
      "Epoch 00163: val_loss did not improve\n",
      " - 3s - loss: 0.6917 - acc: 1.0000 - val_loss: 0.8015 - val_acc: 0.6667\n",
      "Epoch 164/600\n",
      "Epoch 00164: val_loss improved from 0.78729 to 0.78265, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.6871 - acc: 1.0000 - val_loss: 0.7826 - val_acc: 0.8333\n",
      "Epoch 165/600\n",
      "Epoch 00165: val_loss did not improve\n",
      " - 3s - loss: 0.6842 - acc: 1.0000 - val_loss: 0.7988 - val_acc: 0.6667\n",
      "Epoch 166/600\n",
      "Epoch 00166: val_loss improved from 0.78265 to 0.77746, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.6821 - acc: 1.0000 - val_loss: 0.7775 - val_acc: 0.8333\n",
      "Epoch 167/600\n",
      "Epoch 00167: val_loss did not improve\n",
      " - 3s - loss: 0.6807 - acc: 1.0000 - val_loss: 0.7998 - val_acc: 0.6667\n",
      "Epoch 168/600\n",
      "Epoch 00168: val_loss improved from 0.77746 to 0.76790, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.6801 - acc: 1.0000 - val_loss: 0.7679 - val_acc: 0.8333\n",
      "Epoch 169/600\n",
      "Epoch 00169: val_loss did not improve\n",
      " - 3s - loss: 0.6768 - acc: 1.0000 - val_loss: 0.7889 - val_acc: 0.6667\n",
      "Epoch 170/600\n",
      "Epoch 00170: val_loss improved from 0.76790 to 0.76765, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.6747 - acc: 1.0000 - val_loss: 0.7676 - val_acc: 0.8333\n",
      "Epoch 171/600\n",
      "Epoch 00171: val_loss did not improve\n",
      " - 3s - loss: 0.6715 - acc: 1.0000 - val_loss: 0.7905 - val_acc: 0.6667\n",
      "Epoch 172/600\n",
      "Epoch 00172: val_loss improved from 0.76765 to 0.76442, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.6693 - acc: 1.0000 - val_loss: 0.7644 - val_acc: 0.8333\n",
      "Epoch 173/600\n",
      "Epoch 00173: val_loss did not improve\n",
      " - 3s - loss: 0.6670 - acc: 1.0000 - val_loss: 0.7849 - val_acc: 0.6667\n",
      "Epoch 174/600\n",
      "Epoch 00174: val_loss improved from 0.76442 to 0.75591, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.6656 - acc: 1.0000 - val_loss: 0.7559 - val_acc: 0.8333\n",
      "Epoch 175/600\n",
      "Epoch 00175: val_loss did not improve\n",
      " - 3s - loss: 0.6745 - acc: 1.0000 - val_loss: 0.7942 - val_acc: 0.6667\n",
      "Epoch 176/600\n",
      "Epoch 00176: val_loss did not improve\n",
      " - 3s - loss: 0.6718 - acc: 1.0000 - val_loss: 0.7964 - val_acc: 0.6667\n",
      "Epoch 177/600\n",
      "Epoch 00177: val_loss did not improve\n",
      " - 3s - loss: 0.6743 - acc: 1.0000 - val_loss: 0.7946 - val_acc: 0.6667\n",
      "Epoch 178/600\n",
      "Epoch 00178: val_loss did not improve\n",
      " - 3s - loss: 0.6694 - acc: 1.0000 - val_loss: 0.7887 - val_acc: 0.6667\n",
      "Epoch 179/600\n",
      "Epoch 00179: val_loss did not improve\n",
      " - 3s - loss: 0.6635 - acc: 1.0000 - val_loss: 0.7864 - val_acc: 0.6667\n",
      "Epoch 180/600\n",
      "Epoch 00180: val_loss did not improve\n",
      " - 3s - loss: 0.6724 - acc: 1.0000 - val_loss: 0.7935 - val_acc: 0.6667\n",
      "Epoch 181/600\n",
      "Epoch 00181: val_loss did not improve\n",
      " - 3s - loss: 0.6706 - acc: 1.0000 - val_loss: 0.7852 - val_acc: 0.6667\n",
      "Epoch 182/600\n",
      "Epoch 00182: val_loss did not improve\n",
      " - 3s - loss: 0.6523 - acc: 1.0000 - val_loss: 0.7843 - val_acc: 0.6667\n",
      "Epoch 183/600\n",
      "Epoch 00183: val_loss did not improve\n",
      " - 3s - loss: 0.6479 - acc: 1.0000 - val_loss: 0.7814 - val_acc: 0.6667\n",
      "Epoch 184/600\n",
      "Epoch 00184: val_loss did not improve\n",
      " - 3s - loss: 0.6664 - acc: 1.0000 - val_loss: 0.7872 - val_acc: 0.6667\n",
      "Epoch 185/600\n",
      "Epoch 00185: val_loss did not improve\n",
      " - 3s - loss: 0.6615 - acc: 1.0000 - val_loss: 0.7838 - val_acc: 0.6667\n",
      "Epoch 186/600\n",
      "Epoch 00186: val_loss did not improve\n",
      " - 3s - loss: 0.6576 - acc: 1.0000 - val_loss: 0.7840 - val_acc: 0.6667\n",
      "Epoch 187/600\n",
      "Epoch 00187: val_loss did not improve\n",
      " - 3s - loss: 0.6492 - acc: 1.0000 - val_loss: 0.7976 - val_acc: 0.6667\n",
      "Epoch 188/600\n",
      "Epoch 00188: val_loss did not improve\n",
      " - 3s - loss: 0.7191 - acc: 0.8889 - val_loss: 0.8099 - val_acc: 0.6667\n",
      "Epoch 189/600\n",
      "Epoch 00189: val_loss did not improve\n",
      " - 3s - loss: 0.7020 - acc: 1.0000 - val_loss: 0.8062 - val_acc: 0.6667\n",
      "Epoch 190/600\n",
      "Epoch 00190: val_loss did not improve\n",
      " - 3s - loss: 0.6850 - acc: 1.0000 - val_loss: 0.7802 - val_acc: 0.6667\n",
      "Epoch 191/600\n",
      "Epoch 00191: val_loss did not improve\n",
      " - 3s - loss: 0.6479 - acc: 1.0000 - val_loss: 0.7773 - val_acc: 0.6667\n",
      "Epoch 192/600\n",
      "Epoch 00192: val_loss did not improve\n",
      " - 3s - loss: 0.6315 - acc: 1.0000 - val_loss: 0.7753 - val_acc: 0.6667\n",
      "Epoch 193/600\n",
      "Epoch 00193: val_loss did not improve\n",
      " - 3s - loss: 0.6302 - acc: 1.0000 - val_loss: 0.7574 - val_acc: 0.6667\n",
      "Epoch 194/600\n",
      "Epoch 00194: val_loss did not improve\n",
      " - 3s - loss: 0.6367 - acc: 1.0000 - val_loss: 0.7626 - val_acc: 0.6667\n",
      "Epoch 195/600\n",
      "Epoch 00195: val_loss did not improve\n",
      " - 3s - loss: 0.6294 - acc: 1.0000 - val_loss: 0.7675 - val_acc: 0.6667\n",
      "Epoch 196/600\n",
      "Epoch 00196: val_loss did not improve\n",
      " - 3s - loss: 0.6204 - acc: 1.0000 - val_loss: 0.7667 - val_acc: 0.6667\n",
      "Epoch 197/600\n",
      "Epoch 00197: val_loss did not improve\n",
      " - 3s - loss: 0.6162 - acc: 1.0000 - val_loss: 0.7624 - val_acc: 0.6667\n",
      "Epoch 198/600\n",
      "Epoch 00198: val_loss did not improve\n",
      " - 3s - loss: 0.6122 - acc: 1.0000 - val_loss: 0.7588 - val_acc: 0.6667\n",
      "Epoch 199/600\n",
      "Epoch 00199: val_loss improved from 0.75591 to 0.75255, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.6098 - acc: 1.0000 - val_loss: 0.7525 - val_acc: 0.6667\n",
      "Epoch 200/600\n",
      "Epoch 00200: val_loss did not improve\n",
      " - 3s - loss: 0.6075 - acc: 1.0000 - val_loss: 0.7583 - val_acc: 0.8333\n",
      "Epoch 201/600\n",
      "Epoch 00201: val_loss improved from 0.75255 to 0.74547, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.6040 - acc: 1.0000 - val_loss: 0.7455 - val_acc: 0.6667\n",
      "Epoch 202/600\n",
      "Epoch 00202: val_loss did not improve\n",
      " - 3s - loss: 0.6043 - acc: 1.0000 - val_loss: 0.7600 - val_acc: 0.8333\n",
      "Epoch 203/600\n",
      "Epoch 00203: val_loss improved from 0.74547 to 0.73901, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.6069 - acc: 1.0000 - val_loss: 0.7390 - val_acc: 0.6667\n",
      "Epoch 204/600\n",
      "Epoch 00204: val_loss improved from 0.73901 to 0.73832, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.6055 - acc: 1.0000 - val_loss: 0.7383 - val_acc: 0.6667\n",
      "Epoch 205/600\n",
      "Epoch 00205: val_loss improved from 0.73832 to 0.71831, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.6119 - acc: 1.0000 - val_loss: 0.7183 - val_acc: 0.8333\n",
      "Epoch 206/600\n",
      "Epoch 00206: val_loss did not improve\n",
      " - 3s - loss: 0.5988 - acc: 1.0000 - val_loss: 0.7272 - val_acc: 0.8333\n",
      "Epoch 207/600\n",
      "Epoch 00207: val_loss did not improve\n",
      " - 3s - loss: 0.5931 - acc: 1.0000 - val_loss: 0.7232 - val_acc: 0.6667\n",
      "Epoch 208/600\n",
      "Epoch 00208: val_loss did not improve\n",
      " - 3s - loss: 0.5869 - acc: 1.0000 - val_loss: 0.7221 - val_acc: 0.6667\n",
      "Epoch 209/600\n",
      "Epoch 00209: val_loss improved from 0.71831 to 0.70083, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.5882 - acc: 1.0000 - val_loss: 0.7008 - val_acc: 0.6667\n",
      "Epoch 210/600\n",
      "Epoch 00210: val_loss did not improve\n",
      " - 3s - loss: 0.5892 - acc: 1.0000 - val_loss: 0.7278 - val_acc: 0.6667\n",
      "Epoch 211/600\n",
      "Epoch 00211: val_loss did not improve\n",
      " - 3s - loss: 0.5953 - acc: 1.0000 - val_loss: 0.7058 - val_acc: 0.6667\n",
      "Epoch 212/600\n",
      "Epoch 00212: val_loss did not improve\n",
      " - 3s - loss: 0.5807 - acc: 1.0000 - val_loss: 0.7127 - val_acc: 0.6667\n",
      "Epoch 213/600\n",
      "Epoch 00213: val_loss improved from 0.70083 to 0.69919, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.5751 - acc: 1.0000 - val_loss: 0.6992 - val_acc: 0.6667\n",
      "Epoch 214/600\n",
      "Epoch 00214: val_loss did not improve\n",
      " - 3s - loss: 0.5713 - acc: 1.0000 - val_loss: 0.7016 - val_acc: 0.6667\n",
      "Epoch 215/600\n",
      "Epoch 00215: val_loss improved from 0.69919 to 0.69107, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.5681 - acc: 1.0000 - val_loss: 0.6911 - val_acc: 0.6667\n",
      "Epoch 216/600\n",
      "Epoch 00216: val_loss improved from 0.69107 to 0.68995, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.5671 - acc: 1.0000 - val_loss: 0.6899 - val_acc: 0.6667\n",
      "Epoch 217/600\n",
      "Epoch 00217: val_loss improved from 0.68995 to 0.68232, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.5639 - acc: 1.0000 - val_loss: 0.6823 - val_acc: 0.6667\n",
      "Epoch 218/600\n",
      "Epoch 00218: val_loss did not improve\n",
      " - 3s - loss: 0.5624 - acc: 1.0000 - val_loss: 0.6975 - val_acc: 0.6667\n",
      "Epoch 219/600\n",
      "Epoch 00219: val_loss did not improve\n",
      " - 3s - loss: 0.5641 - acc: 1.0000 - val_loss: 0.6907 - val_acc: 0.8333\n",
      "Epoch 220/600\n",
      "Epoch 00220: val_loss did not improve\n",
      " - 3s - loss: 0.5722 - acc: 1.0000 - val_loss: 0.7299 - val_acc: 0.6667\n",
      "Epoch 221/600\n",
      "Epoch 00221: val_loss did not improve\n",
      " - 3s - loss: 0.6076 - acc: 1.0000 - val_loss: 0.7250 - val_acc: 1.0000\n",
      "Epoch 222/600\n",
      "Epoch 00222: val_loss did not improve\n",
      " - 3s - loss: 0.5624 - acc: 1.0000 - val_loss: 0.7113 - val_acc: 1.0000\n",
      "Epoch 223/600\n",
      "Epoch 00223: val_loss did not improve\n",
      " - 3s - loss: 0.5541 - acc: 1.0000 - val_loss: 0.7023 - val_acc: 0.8333\n",
      "Epoch 224/600\n",
      "Epoch 00224: val_loss did not improve\n",
      " - 3s - loss: 0.5499 - acc: 1.0000 - val_loss: 0.6856 - val_acc: 0.8333\n",
      "Epoch 225/600\n",
      "Epoch 00225: val_loss did not improve\n",
      " - 3s - loss: 0.5480 - acc: 1.0000 - val_loss: 0.6827 - val_acc: 0.8333\n",
      "Epoch 226/600\n",
      "Epoch 00226: val_loss improved from 0.68232 to 0.67665, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.5437 - acc: 1.0000 - val_loss: 0.6767 - val_acc: 0.8333\n",
      "Epoch 227/600\n",
      "Epoch 00227: val_loss improved from 0.67665 to 0.67130, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.5408 - acc: 1.0000 - val_loss: 0.6713 - val_acc: 0.8333\n",
      "Epoch 228/600\n",
      "Epoch 00228: val_loss did not improve\n",
      " - 3s - loss: 0.5384 - acc: 1.0000 - val_loss: 0.6795 - val_acc: 0.6667\n",
      "Epoch 229/600\n",
      "Epoch 00229: val_loss improved from 0.67130 to 0.66737, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.5369 - acc: 1.0000 - val_loss: 0.6674 - val_acc: 0.6667\n",
      "Epoch 230/600\n",
      "Epoch 00230: val_loss did not improve\n",
      " - 3s - loss: 0.5333 - acc: 1.0000 - val_loss: 0.6821 - val_acc: 0.6667\n",
      "Epoch 231/600\n",
      "Epoch 00231: val_loss improved from 0.66737 to 0.66684, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.5320 - acc: 1.0000 - val_loss: 0.6668 - val_acc: 0.6667\n",
      "Epoch 232/600\n",
      "Epoch 00232: val_loss did not improve\n",
      " - 3s - loss: 0.5288 - acc: 1.0000 - val_loss: 0.6801 - val_acc: 0.6667\n",
      "Epoch 233/600\n",
      "Epoch 00233: val_loss improved from 0.66684 to 0.66529, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.5273 - acc: 1.0000 - val_loss: 0.6653 - val_acc: 0.6667\n",
      "Epoch 234/600\n",
      "Epoch 00234: val_loss did not improve\n",
      " - 3s - loss: 0.5249 - acc: 1.0000 - val_loss: 0.6772 - val_acc: 0.6667\n",
      "Epoch 235/600\n",
      "Epoch 00235: val_loss did not improve\n",
      " - 3s - loss: 0.5258 - acc: 1.0000 - val_loss: 0.6867 - val_acc: 0.6667\n",
      "Epoch 236/600\n",
      "Epoch 00236: val_loss did not improve\n",
      " - 3s - loss: 0.5225 - acc: 1.0000 - val_loss: 0.6786 - val_acc: 0.6667\n",
      "Epoch 237/600\n",
      "Epoch 00237: val_loss did not improve\n",
      " - 3s - loss: 0.5211 - acc: 1.0000 - val_loss: 0.6934 - val_acc: 0.6667\n",
      "Epoch 238/600\n",
      "Epoch 00238: val_loss did not improve\n",
      " - 3s - loss: 0.5513 - acc: 1.0000 - val_loss: 0.7153 - val_acc: 0.6667\n",
      "Epoch 239/600\n",
      "Epoch 00239: val_loss did not improve\n",
      " - 3s - loss: 0.5964 - acc: 1.0000 - val_loss: 0.7601 - val_acc: 0.8333\n",
      "Epoch 240/600\n",
      "Epoch 00240: val_loss did not improve\n",
      " - 3s - loss: 0.6212 - acc: 0.8889 - val_loss: 0.7178 - val_acc: 0.6667\n",
      "Epoch 241/600\n",
      "Epoch 00241: val_loss did not improve\n",
      " - 3s - loss: 0.5853 - acc: 1.0000 - val_loss: 0.7201 - val_acc: 1.0000\n",
      "Epoch 242/600\n",
      "Epoch 00242: val_loss did not improve\n",
      " - 3s - loss: 0.5986 - acc: 1.0000 - val_loss: 0.7608 - val_acc: 0.6667\n",
      "Epoch 243/600\n",
      "Epoch 00243: val_loss did not improve\n",
      " - 3s - loss: 0.5435 - acc: 1.0000 - val_loss: 0.6909 - val_acc: 0.6667\n",
      "Epoch 244/600\n",
      "Epoch 00244: val_loss did not improve\n",
      " - 3s - loss: 0.5808 - acc: 1.0000 - val_loss: 0.6690 - val_acc: 0.8333\n",
      "Epoch 245/600\n",
      "Epoch 00245: val_loss did not improve\n",
      " - 3s - loss: 0.5361 - acc: 1.0000 - val_loss: 0.6667 - val_acc: 0.8333\n",
      "Epoch 246/600\n",
      "Epoch 00246: val_loss did not improve\n",
      " - 3s - loss: 0.5311 - acc: 1.0000 - val_loss: 0.6672 - val_acc: 0.6667\n",
      "Epoch 247/600\n",
      "Epoch 00247: val_loss did not improve\n",
      " - 3s - loss: 0.5250 - acc: 1.0000 - val_loss: 0.6717 - val_acc: 0.6667\n",
      "Epoch 248/600\n",
      "Epoch 00248: val_loss improved from 0.66529 to 0.66211, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.5222 - acc: 1.0000 - val_loss: 0.6621 - val_acc: 0.6667\n",
      "Epoch 249/600\n",
      "Epoch 00249: val_loss did not improve\n",
      " - 3s - loss: 0.5225 - acc: 1.0000 - val_loss: 0.6851 - val_acc: 0.6667\n",
      "Epoch 250/600\n",
      "Epoch 00250: val_loss did not improve\n",
      " - 3s - loss: 0.5216 - acc: 1.0000 - val_loss: 0.6676 - val_acc: 0.6667\n",
      "Epoch 251/600\n",
      "Epoch 00251: val_loss did not improve\n",
      " - 3s - loss: 0.5176 - acc: 1.0000 - val_loss: 0.6629 - val_acc: 0.6667\n",
      "Epoch 252/600\n",
      "Epoch 00252: val_loss improved from 0.66211 to 0.66099, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.5149 - acc: 1.0000 - val_loss: 0.6610 - val_acc: 0.6667\n",
      "Epoch 253/600\n",
      "Epoch 00253: val_loss did not improve\n",
      " - 3s - loss: 0.5131 - acc: 1.0000 - val_loss: 0.6634 - val_acc: 0.6667\n",
      "Epoch 254/600\n",
      "Epoch 00254: val_loss improved from 0.66099 to 0.65538, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.5119 - acc: 1.0000 - val_loss: 0.6554 - val_acc: 0.6667\n",
      "Epoch 255/600\n",
      "Epoch 00255: val_loss did not improve\n",
      " - 3s - loss: 0.5086 - acc: 1.0000 - val_loss: 0.6748 - val_acc: 0.6667\n",
      "Epoch 256/600\n",
      "Epoch 00256: val_loss improved from 0.65538 to 0.64573, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.4918 - acc: 1.0000 - val_loss: 0.6457 - val_acc: 0.6667\n",
      "Epoch 257/600\n",
      "Epoch 00257: val_loss improved from 0.64573 to 0.63917, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.4848 - acc: 1.0000 - val_loss: 0.6392 - val_acc: 0.6667\n",
      "Epoch 258/600\n",
      "Epoch 00258: val_loss improved from 0.63917 to 0.63878, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.4821 - acc: 1.0000 - val_loss: 0.6388 - val_acc: 0.6667\n",
      "Epoch 259/600\n",
      "Epoch 00259: val_loss improved from 0.63878 to 0.63753, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.4818 - acc: 1.0000 - val_loss: 0.6375 - val_acc: 0.6667\n",
      "Epoch 260/600\n",
      "Epoch 00260: val_loss did not improve\n",
      " - 3s - loss: 0.4797 - acc: 1.0000 - val_loss: 0.6529 - val_acc: 0.6667\n",
      "Epoch 261/600\n",
      "Epoch 00261: val_loss did not improve\n",
      " - 3s - loss: 0.4834 - acc: 1.0000 - val_loss: 0.6481 - val_acc: 0.6667\n",
      "Epoch 262/600\n",
      "Epoch 00262: val_loss did not improve\n",
      " - 3s - loss: 0.4792 - acc: 1.0000 - val_loss: 0.6392 - val_acc: 0.6667\n",
      "Epoch 263/600\n",
      "Epoch 00263: val_loss did not improve\n",
      " - 3s - loss: 0.4714 - acc: 1.0000 - val_loss: 0.6425 - val_acc: 0.6667\n",
      "Epoch 264/600\n",
      "Epoch 00264: val_loss improved from 0.63753 to 0.62500, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.4699 - acc: 1.0000 - val_loss: 0.6250 - val_acc: 0.6667\n",
      "Epoch 265/600\n",
      "Epoch 00265: val_loss did not improve\n",
      " - 3s - loss: 0.5062 - acc: 1.0000 - val_loss: 0.6814 - val_acc: 0.6667\n",
      "Epoch 266/600\n",
      "Epoch 00266: val_loss did not improve\n",
      " - 3s - loss: 0.5368 - acc: 0.8889 - val_loss: 0.6636 - val_acc: 0.6667\n",
      "Epoch 267/600\n",
      "Epoch 00267: val_loss did not improve\n",
      " - 3s - loss: 0.5014 - acc: 1.0000 - val_loss: 0.6568 - val_acc: 0.6667\n",
      "Epoch 268/600\n",
      "Epoch 00268: val_loss did not improve\n",
      " - 3s - loss: 0.4932 - acc: 1.0000 - val_loss: 0.6401 - val_acc: 0.6667\n",
      "Epoch 269/600\n",
      "Epoch 00269: val_loss did not improve\n",
      " - 3s - loss: 0.4868 - acc: 1.0000 - val_loss: 0.6638 - val_acc: 0.6667\n",
      "Epoch 270/600\n",
      "Epoch 00270: val_loss did not improve\n",
      " - 3s - loss: 0.4853 - acc: 1.0000 - val_loss: 0.6518 - val_acc: 0.6667\n",
      "Epoch 271/600\n",
      "Epoch 00271: val_loss did not improve\n",
      " - 3s - loss: 0.4789 - acc: 1.0000 - val_loss: 0.6804 - val_acc: 0.6667\n",
      "Epoch 272/600\n",
      "Epoch 00272: val_loss did not improve\n",
      " - 3s - loss: 0.5217 - acc: 1.0000 - val_loss: 0.6851 - val_acc: 0.8333\n",
      "Epoch 273/600\n",
      "Epoch 00273: val_loss did not improve\n",
      " - 3s - loss: 0.5464 - acc: 1.0000 - val_loss: 0.6888 - val_acc: 0.6667\n",
      "Epoch 274/600\n",
      "Epoch 00274: val_loss did not improve\n",
      " - 3s - loss: 0.5318 - acc: 1.0000 - val_loss: 0.6878 - val_acc: 0.6667\n",
      "Epoch 275/600\n",
      "Epoch 00275: val_loss did not improve\n",
      " - 3s - loss: 0.5034 - acc: 1.0000 - val_loss: 0.6960 - val_acc: 0.6667\n",
      "Epoch 276/600\n",
      "Epoch 00276: val_loss did not improve\n",
      " - 3s - loss: 0.4910 - acc: 1.0000 - val_loss: 0.6945 - val_acc: 0.6667\n",
      "Epoch 277/600\n",
      "Epoch 00277: val_loss did not improve\n",
      " - 3s - loss: 0.4861 - acc: 1.0000 - val_loss: 0.6890 - val_acc: 0.6667\n",
      "Epoch 278/600\n",
      "Epoch 00278: val_loss did not improve\n",
      " - 3s - loss: 0.4822 - acc: 1.0000 - val_loss: 0.6784 - val_acc: 0.6667\n",
      "Epoch 279/600\n",
      "Epoch 00279: val_loss did not improve\n",
      " - 3s - loss: 0.4778 - acc: 1.0000 - val_loss: 0.6812 - val_acc: 0.6667\n",
      "Epoch 280/600\n",
      "Epoch 00280: val_loss did not improve\n",
      " - 3s - loss: 0.4757 - acc: 1.0000 - val_loss: 0.6676 - val_acc: 0.6667\n",
      "Epoch 281/600\n",
      "Epoch 00281: val_loss did not improve\n",
      " - 3s - loss: 0.4743 - acc: 1.0000 - val_loss: 0.6802 - val_acc: 0.6667\n",
      "Epoch 282/600\n",
      "Epoch 00282: val_loss did not improve\n",
      " - 3s - loss: 0.4782 - acc: 1.0000 - val_loss: 0.6444 - val_acc: 0.6667\n",
      "Epoch 283/600\n",
      "Epoch 00283: val_loss did not improve\n",
      " - 3s - loss: 0.4808 - acc: 1.0000 - val_loss: 0.6856 - val_acc: 0.6667\n",
      "Epoch 284/600\n",
      "Epoch 00284: val_loss did not improve\n",
      " - 3s - loss: 0.4780 - acc: 1.0000 - val_loss: 0.6767 - val_acc: 0.6667\n",
      "Epoch 285/600\n",
      "Epoch 00285: val_loss did not improve\n",
      " - 3s - loss: 0.4672 - acc: 1.0000 - val_loss: 0.6741 - val_acc: 0.6667\n",
      "Epoch 286/600\n",
      "Epoch 00286: val_loss did not improve\n",
      " - 3s - loss: 0.4638 - acc: 1.0000 - val_loss: 0.6749 - val_acc: 0.6667\n",
      "Epoch 287/600\n",
      "Epoch 00287: val_loss did not improve\n",
      " - 3s - loss: 0.4610 - acc: 1.0000 - val_loss: 0.6721 - val_acc: 0.6667\n",
      "Epoch 288/600\n",
      "Epoch 00288: val_loss did not improve\n",
      " - 3s - loss: 0.4609 - acc: 1.0000 - val_loss: 0.6722 - val_acc: 0.6667\n",
      "Epoch 289/600\n",
      "Epoch 00289: val_loss did not improve\n",
      " - 3s - loss: 0.4588 - acc: 1.0000 - val_loss: 0.6425 - val_acc: 0.6667\n",
      "Epoch 290/600\n",
      "Epoch 00290: val_loss did not improve\n",
      " - 3s - loss: 0.4560 - acc: 1.0000 - val_loss: 0.6801 - val_acc: 0.6667\n",
      "Epoch 291/600\n",
      "Epoch 00291: val_loss did not improve\n",
      " - 3s - loss: 0.4565 - acc: 1.0000 - val_loss: 0.6360 - val_acc: 0.6667\n",
      "Epoch 292/600\n",
      "Epoch 00292: val_loss did not improve\n",
      " - 3s - loss: 0.4532 - acc: 1.0000 - val_loss: 0.6749 - val_acc: 0.6667\n",
      "Epoch 293/600\n",
      "Epoch 00293: val_loss did not improve\n",
      " - 3s - loss: 0.4588 - acc: 1.0000 - val_loss: 0.6734 - val_acc: 0.6667\n",
      "Epoch 294/600\n",
      "Epoch 00294: val_loss did not improve\n",
      " - 3s - loss: 0.4546 - acc: 1.0000 - val_loss: 0.6758 - val_acc: 0.6667\n",
      "Epoch 295/600\n",
      "Epoch 00295: val_loss did not improve\n",
      " - 3s - loss: 0.4499 - acc: 1.0000 - val_loss: 0.6424 - val_acc: 0.6667\n",
      "Epoch 296/600\n",
      "Epoch 00296: val_loss did not improve\n",
      " - 3s - loss: 0.4437 - acc: 1.0000 - val_loss: 0.6675 - val_acc: 0.6667\n",
      "Epoch 297/600\n",
      "Epoch 00297: val_loss improved from 0.62500 to 0.61317, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.4887 - acc: 0.8889 - val_loss: 0.6132 - val_acc: 0.6667\n",
      "Epoch 298/600\n",
      "Epoch 00298: val_loss did not improve\n",
      " - 3s - loss: 0.4778 - acc: 1.0000 - val_loss: 0.6667 - val_acc: 0.6667\n",
      "Epoch 299/600\n",
      "Epoch 00299: val_loss did not improve\n",
      " - 3s - loss: 0.4921 - acc: 0.8889 - val_loss: 0.6554 - val_acc: 0.6667\n",
      "Epoch 300/600\n",
      "Epoch 00300: val_loss did not improve\n",
      " - 3s - loss: 0.4817 - acc: 1.0000 - val_loss: 0.6421 - val_acc: 0.6667\n",
      "Epoch 301/600\n",
      "Epoch 00301: val_loss improved from 0.61317 to 0.61015, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.4610 - acc: 1.0000 - val_loss: 0.6102 - val_acc: 0.6667\n",
      "Epoch 302/600\n",
      "Epoch 00302: val_loss did not improve\n",
      " - 3s - loss: 0.4696 - acc: 1.0000 - val_loss: 0.6506 - val_acc: 0.6667\n",
      "Epoch 303/600\n",
      "Epoch 00303: val_loss did not improve\n",
      " - 3s - loss: 0.4688 - acc: 1.0000 - val_loss: 0.6275 - val_acc: 0.6667\n",
      "Epoch 304/600\n",
      "Epoch 00304: val_loss did not improve\n",
      " - 3s - loss: 0.4495 - acc: 1.0000 - val_loss: 0.6377 - val_acc: 0.6667\n",
      "Epoch 305/600\n",
      "Epoch 00305: val_loss did not improve\n",
      " - 3s - loss: 0.4413 - acc: 1.0000 - val_loss: 0.6243 - val_acc: 0.6667\n",
      "Epoch 306/600\n",
      "Epoch 00306: val_loss did not improve\n",
      " - 3s - loss: 0.4365 - acc: 1.0000 - val_loss: 0.6352 - val_acc: 0.6667\n",
      "Epoch 307/600\n",
      "Epoch 00307: val_loss did not improve\n",
      " - 3s - loss: 0.4362 - acc: 1.0000 - val_loss: 0.6237 - val_acc: 0.6667\n",
      "Epoch 308/600\n",
      "Epoch 00308: val_loss did not improve\n",
      " - 3s - loss: 0.4276 - acc: 1.0000 - val_loss: 0.6274 - val_acc: 0.6667\n",
      "Epoch 309/600\n",
      "Epoch 00309: val_loss did not improve\n",
      " - 3s - loss: 0.4243 - acc: 1.0000 - val_loss: 0.6233 - val_acc: 0.8333\n",
      "Epoch 310/600\n",
      "Epoch 00310: val_loss did not improve\n",
      " - 3s - loss: 0.4193 - acc: 1.0000 - val_loss: 0.6244 - val_acc: 0.8333\n",
      "Epoch 311/600\n",
      "Epoch 00311: val_loss improved from 0.61015 to 0.58234, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.4207 - acc: 1.0000 - val_loss: 0.5823 - val_acc: 0.8333\n",
      "Epoch 312/600\n",
      "Epoch 00312: val_loss did not improve\n",
      " - 3s - loss: 0.4223 - acc: 1.0000 - val_loss: 0.6140 - val_acc: 0.8333\n",
      "Epoch 313/600\n",
      "Epoch 00313: val_loss did not improve\n",
      " - 3s - loss: 0.5001 - acc: 1.0000 - val_loss: 0.5830 - val_acc: 0.8333\n",
      "Epoch 314/600\n",
      "Epoch 00314: val_loss did not improve\n",
      " - 3s - loss: 0.5140 - acc: 1.0000 - val_loss: 0.5986 - val_acc: 0.8333\n",
      "Epoch 315/600\n",
      "Epoch 00315: val_loss did not improve\n",
      " - 3s - loss: 0.4720 - acc: 1.0000 - val_loss: 0.7475 - val_acc: 0.6667\n",
      "Epoch 316/600\n",
      "Epoch 00316: val_loss did not improve\n",
      " - 3s - loss: 0.5244 - acc: 0.8889 - val_loss: 0.6252 - val_acc: 0.8333\n",
      "Epoch 317/600\n",
      "Epoch 00317: val_loss did not improve\n",
      " - 3s - loss: 0.4732 - acc: 1.0000 - val_loss: 0.6394 - val_acc: 0.8333\n",
      "Epoch 318/600\n",
      "Epoch 00318: val_loss did not improve\n",
      " - 3s - loss: 0.4361 - acc: 1.0000 - val_loss: 0.6275 - val_acc: 0.8333\n",
      "Epoch 319/600\n",
      "Epoch 00319: val_loss did not improve\n",
      " - 3s - loss: 0.4225 - acc: 1.0000 - val_loss: 0.6317 - val_acc: 0.8333\n",
      "Epoch 320/600\n",
      "Epoch 00320: val_loss did not improve\n",
      " - 3s - loss: 0.4175 - acc: 1.0000 - val_loss: 0.6519 - val_acc: 0.8333\n",
      "Epoch 321/600\n",
      "Epoch 00321: val_loss did not improve\n",
      " - 3s - loss: 0.4137 - acc: 1.0000 - val_loss: 0.6513 - val_acc: 0.8333\n",
      "Epoch 322/600\n",
      "Epoch 00322: val_loss did not improve\n",
      " - 3s - loss: 0.4102 - acc: 1.0000 - val_loss: 0.6572 - val_acc: 0.8333\n",
      "Epoch 323/600\n",
      "Epoch 00323: val_loss did not improve\n",
      " - 3s - loss: 0.4073 - acc: 1.0000 - val_loss: 0.6548 - val_acc: 0.8333\n",
      "Epoch 324/600\n",
      "Epoch 00324: val_loss did not improve\n",
      " - 3s - loss: 0.4037 - acc: 1.0000 - val_loss: 0.6567 - val_acc: 0.8333\n",
      "Epoch 325/600\n",
      "Epoch 00325: val_loss did not improve\n",
      " - 3s - loss: 0.4007 - acc: 1.0000 - val_loss: 0.6528 - val_acc: 0.8333\n",
      "Epoch 326/600\n",
      "Epoch 00326: val_loss did not improve\n",
      " - 3s - loss: 0.3982 - acc: 1.0000 - val_loss: 0.6555 - val_acc: 0.8333\n",
      "Epoch 327/600\n",
      "Epoch 00327: val_loss did not improve\n",
      " - 3s - loss: 0.3959 - acc: 1.0000 - val_loss: 0.6726 - val_acc: 0.6667\n",
      "Epoch 328/600\n",
      "Epoch 00328: val_loss did not improve\n",
      " - 3s - loss: 0.3887 - acc: 1.0000 - val_loss: 0.7070 - val_acc: 0.6667\n",
      "Epoch 329/600\n",
      "Epoch 00329: val_loss did not improve\n",
      " - 3s - loss: 0.4844 - acc: 1.0000 - val_loss: 0.6974 - val_acc: 0.8333\n",
      "Epoch 330/600\n",
      "Epoch 00330: val_loss did not improve\n",
      " - 3s - loss: 0.4456 - acc: 1.0000 - val_loss: 0.6469 - val_acc: 0.8333\n",
      "Epoch 331/600\n",
      "Epoch 00331: val_loss did not improve\n",
      " - 3s - loss: 0.3990 - acc: 1.0000 - val_loss: 0.6299 - val_acc: 0.8333\n",
      "Epoch 332/600\n",
      "Epoch 00332: val_loss did not improve\n",
      " - 3s - loss: 0.3855 - acc: 1.0000 - val_loss: 0.6380 - val_acc: 0.8333\n",
      "Epoch 333/600\n",
      "Epoch 00333: val_loss did not improve\n",
      " - 3s - loss: 0.3801 - acc: 1.0000 - val_loss: 0.6131 - val_acc: 0.8333\n",
      "Epoch 334/600\n",
      "Epoch 00334: val_loss did not improve\n",
      " - 3s - loss: 0.3742 - acc: 1.0000 - val_loss: 0.6358 - val_acc: 0.8333\n",
      "Epoch 335/600\n",
      "Epoch 00335: val_loss did not improve\n",
      " - 3s - loss: 0.3644 - acc: 1.0000 - val_loss: 0.6223 - val_acc: 0.8333\n",
      "Epoch 336/600\n",
      "Epoch 00336: val_loss did not improve\n",
      " - 3s - loss: 0.3617 - acc: 1.0000 - val_loss: 0.6353 - val_acc: 0.8333\n",
      "Epoch 337/600\n",
      "Epoch 00337: val_loss did not improve\n",
      " - 3s - loss: 0.3599 - acc: 1.0000 - val_loss: 0.6511 - val_acc: 0.8333\n",
      "Epoch 338/600\n",
      "Epoch 00338: val_loss did not improve\n",
      " - 3s - loss: 0.3570 - acc: 1.0000 - val_loss: 0.6436 - val_acc: 0.8333\n",
      "Epoch 339/600\n",
      "Epoch 00339: val_loss did not improve\n",
      " - 3s - loss: 0.3539 - acc: 1.0000 - val_loss: 0.6530 - val_acc: 0.8333\n",
      "Epoch 340/600\n",
      "Epoch 00340: val_loss did not improve\n",
      " - 3s - loss: 0.3516 - acc: 1.0000 - val_loss: 0.6469 - val_acc: 0.8333\n",
      "Epoch 341/600\n",
      "Epoch 00341: val_loss did not improve\n",
      " - 3s - loss: 0.3508 - acc: 1.0000 - val_loss: 0.6681 - val_acc: 0.6667\n",
      "Epoch 342/600\n",
      "Epoch 00342: val_loss did not improve\n",
      " - 3s - loss: 0.3491 - acc: 1.0000 - val_loss: 0.6478 - val_acc: 0.8333\n",
      "Epoch 343/600\n",
      "Epoch 00343: val_loss did not improve\n",
      " - 3s - loss: 0.3484 - acc: 1.0000 - val_loss: 0.6726 - val_acc: 0.6667\n",
      "Epoch 344/600\n",
      "Epoch 00344: val_loss did not improve\n",
      " - 3s - loss: 0.3511 - acc: 1.0000 - val_loss: 0.6673 - val_acc: 0.8333\n",
      "Epoch 345/600\n",
      "Epoch 00345: val_loss did not improve\n",
      " - 3s - loss: 0.3454 - acc: 1.0000 - val_loss: 0.6421 - val_acc: 0.8333\n",
      "Epoch 346/600\n",
      "Epoch 00346: val_loss did not improve\n",
      " - 3s - loss: 0.3477 - acc: 1.0000 - val_loss: 0.6243 - val_acc: 0.8333\n",
      "Epoch 347/600\n",
      "Epoch 00347: val_loss improved from 0.58234 to 0.57309, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.3635 - acc: 1.0000 - val_loss: 0.5731 - val_acc: 0.8333\n",
      "Epoch 348/600\n",
      "Epoch 00348: val_loss did not improve\n",
      " - 3s - loss: 0.4072 - acc: 1.0000 - val_loss: 0.6595 - val_acc: 0.6667\n",
      "Epoch 349/600\n",
      "Epoch 00349: val_loss did not improve\n",
      " - 3s - loss: 0.4055 - acc: 1.0000 - val_loss: 0.7994 - val_acc: 0.5000\n",
      "Epoch 350/600\n",
      "Epoch 00350: val_loss did not improve\n",
      " - 3s - loss: 0.5215 - acc: 0.8889 - val_loss: 0.6467 - val_acc: 0.8333\n",
      "Epoch 351/600\n",
      "Epoch 00351: val_loss did not improve\n",
      " - 3s - loss: 0.3994 - acc: 1.0000 - val_loss: 0.6252 - val_acc: 0.8333\n",
      "Epoch 352/600\n",
      "Epoch 00352: val_loss did not improve\n",
      " - 3s - loss: 0.3895 - acc: 1.0000 - val_loss: 0.6391 - val_acc: 0.8333\n",
      "Epoch 353/600\n",
      "Epoch 00353: val_loss did not improve\n",
      " - 3s - loss: 0.3843 - acc: 1.0000 - val_loss: 0.6438 - val_acc: 0.8333\n",
      "Epoch 354/600\n",
      "Epoch 00354: val_loss did not improve\n",
      " - 3s - loss: 0.3866 - acc: 1.0000 - val_loss: 0.6538 - val_acc: 0.8333\n",
      "Epoch 355/600\n",
      "Epoch 00355: val_loss did not improve\n",
      " - 3s - loss: 0.3812 - acc: 1.0000 - val_loss: 0.6498 - val_acc: 0.8333\n",
      "Epoch 356/600\n",
      "Epoch 00356: val_loss did not improve\n",
      " - 3s - loss: 0.3762 - acc: 1.0000 - val_loss: 0.6444 - val_acc: 0.8333\n",
      "Epoch 357/600\n",
      "Epoch 00357: val_loss did not improve\n",
      " - 3s - loss: 0.3678 - acc: 1.0000 - val_loss: 0.6460 - val_acc: 0.8333\n",
      "Epoch 358/600\n",
      "Epoch 00358: val_loss did not improve\n",
      " - 3s - loss: 0.3649 - acc: 1.0000 - val_loss: 0.6436 - val_acc: 0.8333\n",
      "Epoch 359/600\n",
      "Epoch 00359: val_loss did not improve\n",
      " - 3s - loss: 0.3639 - acc: 1.0000 - val_loss: 0.6407 - val_acc: 0.8333\n",
      "Epoch 360/600\n",
      "Epoch 00360: val_loss did not improve\n",
      " - 3s - loss: 0.3581 - acc: 1.0000 - val_loss: 0.6433 - val_acc: 0.8333\n",
      "Epoch 361/600\n",
      "Epoch 00361: val_loss did not improve\n",
      " - 3s - loss: 0.3590 - acc: 1.0000 - val_loss: 0.6423 - val_acc: 0.8333\n",
      "Epoch 362/600\n",
      "Epoch 00362: val_loss did not improve\n",
      " - 3s - loss: 0.3520 - acc: 1.0000 - val_loss: 0.6668 - val_acc: 0.8333\n",
      "Epoch 363/600\n",
      "Epoch 00363: val_loss did not improve\n",
      " - 3s - loss: 0.3488 - acc: 1.0000 - val_loss: 0.6691 - val_acc: 0.8333\n",
      "Epoch 364/600\n",
      "Epoch 00364: val_loss did not improve\n",
      " - 3s - loss: 0.3490 - acc: 1.0000 - val_loss: 0.6697 - val_acc: 0.8333\n",
      "Epoch 365/600\n",
      "Epoch 00365: val_loss did not improve\n",
      " - 3s - loss: 0.3444 - acc: 1.0000 - val_loss: 0.6726 - val_acc: 0.8333\n",
      "Epoch 366/600\n",
      "Epoch 00366: val_loss did not improve\n",
      " - 3s - loss: 0.3423 - acc: 1.0000 - val_loss: 0.6584 - val_acc: 0.8333\n",
      "Epoch 367/600\n",
      "Epoch 00367: val_loss did not improve\n",
      " - 3s - loss: 0.3408 - acc: 1.0000 - val_loss: 0.6717 - val_acc: 0.8333\n",
      "Epoch 368/600\n",
      "Epoch 00368: val_loss did not improve\n",
      " - 3s - loss: 0.3406 - acc: 1.0000 - val_loss: 0.6467 - val_acc: 0.8333\n",
      "Epoch 369/600\n",
      "Epoch 00369: val_loss did not improve\n",
      " - 3s - loss: 0.3446 - acc: 1.0000 - val_loss: 0.6398 - val_acc: 0.8333\n",
      "Epoch 370/600\n",
      "Epoch 00370: val_loss did not improve\n",
      " - 3s - loss: 0.3397 - acc: 1.0000 - val_loss: 0.6485 - val_acc: 0.8333\n",
      "Epoch 371/600\n",
      "Epoch 00371: val_loss did not improve\n",
      " - 3s - loss: 0.3368 - acc: 1.0000 - val_loss: 0.6696 - val_acc: 0.8333\n",
      "Epoch 372/600\n",
      "Epoch 00372: val_loss did not improve\n",
      " - 3s - loss: 0.3321 - acc: 1.0000 - val_loss: 0.6570 - val_acc: 0.8333\n",
      "Epoch 373/600\n",
      "Epoch 00373: val_loss did not improve\n",
      " - 3s - loss: 0.3317 - acc: 1.0000 - val_loss: 0.6518 - val_acc: 0.8333\n",
      "Epoch 374/600\n",
      "Epoch 00374: val_loss did not improve\n",
      " - 3s - loss: 0.3367 - acc: 1.0000 - val_loss: 0.6187 - val_acc: 0.8333\n",
      "Epoch 375/600\n",
      "Epoch 00375: val_loss did not improve\n",
      " - 3s - loss: 0.3527 - acc: 1.0000 - val_loss: 0.7388 - val_acc: 0.6667\n",
      "Epoch 376/600\n",
      "Epoch 00376: val_loss did not improve\n",
      " - 3s - loss: 0.3384 - acc: 1.0000 - val_loss: 0.6503 - val_acc: 0.6667\n",
      "Epoch 377/600\n",
      "Epoch 00377: val_loss did not improve\n",
      " - 3s - loss: 0.3320 - acc: 1.0000 - val_loss: 0.6440 - val_acc: 0.8333\n",
      "Epoch 378/600\n",
      "Epoch 00378: val_loss did not improve\n",
      " - 3s - loss: 0.3255 - acc: 1.0000 - val_loss: 0.6591 - val_acc: 0.8333\n",
      "Epoch 379/600\n",
      "Epoch 00379: val_loss did not improve\n",
      " - 3s - loss: 0.3281 - acc: 1.0000 - val_loss: 0.6603 - val_acc: 0.6667\n",
      "Epoch 380/600\n",
      "Epoch 00380: val_loss did not improve\n",
      " - 3s - loss: 0.3491 - acc: 1.0000 - val_loss: 0.6419 - val_acc: 0.8333\n",
      "Epoch 381/600\n",
      "Epoch 00381: val_loss did not improve\n",
      " - 3s - loss: 0.3269 - acc: 1.0000 - val_loss: 0.6488 - val_acc: 0.8333\n",
      "Epoch 382/600\n",
      "Epoch 00382: val_loss did not improve\n",
      " - 3s - loss: 0.3257 - acc: 1.0000 - val_loss: 0.6469 - val_acc: 0.8333\n",
      "Epoch 383/600\n",
      "Epoch 00383: val_loss did not improve\n",
      " - 3s - loss: 0.3174 - acc: 1.0000 - val_loss: 0.6375 - val_acc: 0.8333\n",
      "Epoch 384/600\n",
      "Epoch 00384: val_loss did not improve\n",
      " - 3s - loss: 0.3138 - acc: 1.0000 - val_loss: 0.6423 - val_acc: 0.8333\n",
      "Epoch 385/600\n",
      "Epoch 00385: val_loss did not improve\n",
      " - 3s - loss: 0.3113 - acc: 1.0000 - val_loss: 0.6372 - val_acc: 0.8333\n",
      "Epoch 386/600\n",
      "Epoch 00386: val_loss did not improve\n",
      " - 3s - loss: 0.3092 - acc: 1.0000 - val_loss: 0.6369 - val_acc: 0.8333\n",
      "Epoch 387/600\n",
      "Epoch 00387: val_loss did not improve\n",
      " - 3s - loss: 0.3075 - acc: 1.0000 - val_loss: 0.6304 - val_acc: 0.8333\n",
      "Epoch 388/600\n",
      "Epoch 00388: val_loss did not improve\n",
      " - 3s - loss: 0.3058 - acc: 1.0000 - val_loss: 0.6391 - val_acc: 0.8333\n",
      "Epoch 389/600\n",
      "Epoch 00389: val_loss did not improve\n",
      " - 3s - loss: 0.3041 - acc: 1.0000 - val_loss: 0.6274 - val_acc: 0.8333\n",
      "Epoch 390/600\n",
      "Epoch 00390: val_loss did not improve\n",
      " - 3s - loss: 0.3023 - acc: 1.0000 - val_loss: 0.6462 - val_acc: 0.8333\n",
      "Epoch 391/600\n",
      "Epoch 00391: val_loss did not improve\n",
      " - 3s - loss: 0.2985 - acc: 1.0000 - val_loss: 0.6328 - val_acc: 0.8333\n",
      "Epoch 392/600\n",
      "Epoch 00392: val_loss did not improve\n",
      " - 3s - loss: 0.2975 - acc: 1.0000 - val_loss: 0.6686 - val_acc: 0.6667\n",
      "Epoch 393/600\n",
      "Epoch 00393: val_loss did not improve\n",
      " - 3s - loss: 0.3098 - acc: 1.0000 - val_loss: 0.6496 - val_acc: 0.6667\n",
      "Epoch 394/600\n",
      "Epoch 00394: val_loss did not improve\n",
      " - 3s - loss: 0.3130 - acc: 1.0000 - val_loss: 0.5839 - val_acc: 0.8333\n",
      "Epoch 395/600\n",
      "Epoch 00395: val_loss did not improve\n",
      " - 3s - loss: 0.2980 - acc: 1.0000 - val_loss: 0.6024 - val_acc: 0.8333\n",
      "Epoch 396/600\n",
      "Epoch 00396: val_loss improved from 0.57309 to 0.56747, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.2926 - acc: 1.0000 - val_loss: 0.5675 - val_acc: 0.8333\n",
      "Epoch 397/600\n",
      "Epoch 00397: val_loss did not improve\n",
      " - 3s - loss: 0.2840 - acc: 1.0000 - val_loss: 0.6866 - val_acc: 0.6667\n",
      "Epoch 398/600\n",
      "Epoch 00398: val_loss did not improve\n",
      " - 3s - loss: 0.3610 - acc: 1.0000 - val_loss: 0.5792 - val_acc: 0.8333\n",
      "Epoch 399/600\n",
      "Epoch 00399: val_loss did not improve\n",
      " - 3s - loss: 0.3514 - acc: 1.0000 - val_loss: 0.6038 - val_acc: 0.8333\n",
      "Epoch 400/600\n",
      "Epoch 00400: val_loss did not improve\n",
      " - 3s - loss: 0.2992 - acc: 1.0000 - val_loss: 0.6006 - val_acc: 0.8333\n",
      "Epoch 401/600\n",
      "Epoch 00401: val_loss did not improve\n",
      " - 3s - loss: 0.2876 - acc: 1.0000 - val_loss: 0.5926 - val_acc: 0.8333\n",
      "Epoch 402/600\n",
      "Epoch 00402: val_loss did not improve\n",
      " - 3s - loss: 0.2822 - acc: 1.0000 - val_loss: 0.6043 - val_acc: 0.8333\n",
      "Epoch 403/600\n",
      "Epoch 00403: val_loss did not improve\n",
      " - 3s - loss: 0.2797 - acc: 1.0000 - val_loss: 0.5982 - val_acc: 0.8333\n",
      "Epoch 404/600\n",
      "Epoch 00404: val_loss did not improve\n",
      " - 3s - loss: 0.2762 - acc: 1.0000 - val_loss: 0.5938 - val_acc: 0.8333\n",
      "Epoch 405/600\n",
      "Epoch 00405: val_loss did not improve\n",
      " - 3s - loss: 0.2715 - acc: 1.0000 - val_loss: 0.5943 - val_acc: 0.8333\n",
      "Epoch 406/600\n",
      "Epoch 00406: val_loss did not improve\n",
      " - 3s - loss: 0.2685 - acc: 1.0000 - val_loss: 0.5917 - val_acc: 0.8333\n",
      "Epoch 407/600\n",
      "Epoch 00407: val_loss did not improve\n",
      " - 3s - loss: 0.2662 - acc: 1.0000 - val_loss: 0.5953 - val_acc: 0.8333\n",
      "Epoch 408/600\n",
      "Epoch 00408: val_loss did not improve\n",
      " - 3s - loss: 0.2645 - acc: 1.0000 - val_loss: 0.5927 - val_acc: 0.8333\n",
      "Epoch 409/600\n",
      "Epoch 00409: val_loss did not improve\n",
      " - 3s - loss: 0.2618 - acc: 1.0000 - val_loss: 0.5904 - val_acc: 0.6667\n",
      "Epoch 410/600\n",
      "Epoch 00410: val_loss did not improve\n",
      " - 3s - loss: 0.2595 - acc: 1.0000 - val_loss: 0.5956 - val_acc: 0.6667\n",
      "Epoch 411/600\n",
      "Epoch 00411: val_loss did not improve\n",
      " - 3s - loss: 0.2576 - acc: 1.0000 - val_loss: 0.5939 - val_acc: 0.6667\n",
      "Epoch 412/600\n",
      "Epoch 00412: val_loss did not improve\n",
      " - 3s - loss: 0.2564 - acc: 1.0000 - val_loss: 0.5945 - val_acc: 0.6667\n",
      "Epoch 413/600\n",
      "Epoch 00413: val_loss did not improve\n",
      " - 3s - loss: 0.2536 - acc: 1.0000 - val_loss: 0.5929 - val_acc: 0.6667\n",
      "Epoch 414/600\n",
      "Epoch 00414: val_loss did not improve\n",
      " - 3s - loss: 0.2529 - acc: 1.0000 - val_loss: 0.6017 - val_acc: 0.6667\n",
      "Epoch 415/600\n",
      "Epoch 00415: val_loss did not improve\n",
      " - 3s - loss: 0.2558 - acc: 1.0000 - val_loss: 0.5699 - val_acc: 0.8333\n",
      "Epoch 416/600\n",
      "Epoch 00416: val_loss did not improve\n",
      " - 3s - loss: 0.2505 - acc: 1.0000 - val_loss: 0.5992 - val_acc: 0.8333\n",
      "Epoch 417/600\n",
      "Epoch 00417: val_loss did not improve\n",
      " - 3s - loss: 0.2495 - acc: 1.0000 - val_loss: 0.6131 - val_acc: 0.6667\n",
      "Epoch 418/600\n",
      "Epoch 00418: val_loss did not improve\n",
      " - 3s - loss: 0.2523 - acc: 1.0000 - val_loss: 0.6248 - val_acc: 0.6667\n",
      "Epoch 419/600\n",
      "Epoch 00419: val_loss did not improve\n",
      " - 3s - loss: 0.2475 - acc: 1.0000 - val_loss: 0.6058 - val_acc: 0.6667\n",
      "Epoch 420/600\n",
      "Epoch 00420: val_loss did not improve\n",
      " - 3s - loss: 0.2475 - acc: 1.0000 - val_loss: 0.6100 - val_acc: 0.6667\n",
      "Epoch 421/600\n",
      "Epoch 00421: val_loss did not improve\n",
      " - 3s - loss: 0.2436 - acc: 1.0000 - val_loss: 0.6133 - val_acc: 0.6667\n",
      "Epoch 422/600\n",
      "Epoch 00422: val_loss did not improve\n",
      " - 3s - loss: 0.2407 - acc: 1.0000 - val_loss: 0.6267 - val_acc: 0.6667\n",
      "Epoch 423/600\n",
      "Epoch 00423: val_loss did not improve\n",
      " - 3s - loss: 0.2386 - acc: 1.0000 - val_loss: 0.6220 - val_acc: 0.6667\n",
      "Epoch 424/600\n",
      "Epoch 00424: val_loss did not improve\n",
      " - 3s - loss: 0.2381 - acc: 1.0000 - val_loss: 0.6340 - val_acc: 0.6667\n",
      "Epoch 425/600\n",
      "Epoch 00425: val_loss did not improve\n",
      " - 3s - loss: 0.2430 - acc: 1.0000 - val_loss: 0.6235 - val_acc: 0.6667\n",
      "Epoch 426/600\n",
      "Epoch 00426: val_loss did not improve\n",
      " - 3s - loss: 0.2416 - acc: 1.0000 - val_loss: 0.6488 - val_acc: 0.6667\n",
      "Epoch 427/600\n",
      "Epoch 00427: val_loss did not improve\n",
      " - 3s - loss: 0.2394 - acc: 1.0000 - val_loss: 0.5928 - val_acc: 0.6667\n",
      "Epoch 428/600\n",
      "Epoch 00428: val_loss did not improve\n",
      " - 3s - loss: 0.2399 - acc: 1.0000 - val_loss: 0.5939 - val_acc: 0.6667\n",
      "Epoch 429/600\n",
      "Epoch 00429: val_loss did not improve\n",
      " - 3s - loss: 0.2362 - acc: 1.0000 - val_loss: 0.5952 - val_acc: 0.6667\n",
      "Epoch 430/600\n",
      "Epoch 00430: val_loss did not improve\n",
      " - 3s - loss: 0.2334 - acc: 1.0000 - val_loss: 0.5981 - val_acc: 0.6667\n",
      "Epoch 431/600\n",
      "Epoch 00431: val_loss did not improve\n",
      " - 3s - loss: 0.2316 - acc: 1.0000 - val_loss: 0.6178 - val_acc: 0.6667\n",
      "Epoch 432/600\n",
      "Epoch 00432: val_loss did not improve\n",
      " - 3s - loss: 0.2279 - acc: 1.0000 - val_loss: 0.6771 - val_acc: 0.5000\n",
      "Epoch 433/600\n",
      "Epoch 00433: val_loss did not improve\n",
      " - 3s - loss: 0.2262 - acc: 1.0000 - val_loss: 0.6571 - val_acc: 0.6667\n",
      "Epoch 434/600\n",
      "Epoch 00434: val_loss did not improve\n",
      " - 3s - loss: 0.2239 - acc: 1.0000 - val_loss: 0.6677 - val_acc: 0.6667\n",
      "Epoch 435/600\n",
      "Epoch 00435: val_loss did not improve\n",
      " - 3s - loss: 0.2222 - acc: 1.0000 - val_loss: 0.6812 - val_acc: 0.6667\n",
      "Epoch 436/600\n",
      "Epoch 00436: val_loss did not improve\n",
      " - 3s - loss: 0.2207 - acc: 1.0000 - val_loss: 0.6697 - val_acc: 0.6667\n",
      "Epoch 437/600\n",
      "Epoch 00437: val_loss did not improve\n",
      " - 3s - loss: 0.2201 - acc: 1.0000 - val_loss: 0.6655 - val_acc: 0.6667\n",
      "Epoch 438/600\n",
      "Epoch 00438: val_loss did not improve\n",
      " - 3s - loss: 0.2183 - acc: 1.0000 - val_loss: 0.6264 - val_acc: 0.8333\n",
      "Epoch 439/600\n",
      "Epoch 00439: val_loss did not improve\n",
      " - 3s - loss: 0.2200 - acc: 1.0000 - val_loss: 0.6211 - val_acc: 0.8333\n",
      "Epoch 440/600\n",
      "Epoch 00440: val_loss did not improve\n",
      " - 3s - loss: 0.2253 - acc: 1.0000 - val_loss: 0.5811 - val_acc: 0.8333\n",
      "Epoch 441/600\n",
      "Epoch 00441: val_loss did not improve\n",
      " - 3s - loss: 0.3648 - acc: 0.8889 - val_loss: 0.5894 - val_acc: 0.6667\n",
      "Epoch 442/600\n",
      "Epoch 00442: val_loss did not improve\n",
      " - 3s - loss: 0.2748 - acc: 1.0000 - val_loss: 0.5790 - val_acc: 0.6667\n",
      "Epoch 443/600\n",
      "Epoch 00443: val_loss did not improve\n",
      " - 3s - loss: 0.2905 - acc: 1.0000 - val_loss: 0.8003 - val_acc: 0.5000\n",
      "Epoch 444/600\n",
      "Epoch 00444: val_loss improved from 0.56747 to 0.54472, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.3501 - acc: 0.8889 - val_loss: 0.5447 - val_acc: 0.8333\n",
      "Epoch 445/600\n",
      "Epoch 00445: val_loss improved from 0.54472 to 0.51157, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.2769 - acc: 1.0000 - val_loss: 0.5116 - val_acc: 0.8333\n",
      "Epoch 446/600\n",
      "Epoch 00446: val_loss did not improve\n",
      " - 3s - loss: 0.2524 - acc: 1.0000 - val_loss: 0.5683 - val_acc: 0.6667\n",
      "Epoch 447/600\n",
      "Epoch 00447: val_loss did not improve\n",
      " - 3s - loss: 0.2437 - acc: 1.0000 - val_loss: 0.5645 - val_acc: 0.6667\n",
      "Epoch 448/600\n",
      "Epoch 00448: val_loss did not improve\n",
      " - 3s - loss: 0.2367 - acc: 1.0000 - val_loss: 0.5612 - val_acc: 0.6667\n",
      "Epoch 449/600\n",
      "Epoch 00449: val_loss did not improve\n",
      " - 3s - loss: 0.2289 - acc: 1.0000 - val_loss: 0.5634 - val_acc: 0.6667\n",
      "Epoch 450/600\n",
      "Epoch 00450: val_loss did not improve\n",
      " - 3s - loss: 0.2231 - acc: 1.0000 - val_loss: 0.5567 - val_acc: 0.8333\n",
      "Epoch 451/600\n",
      "Epoch 00451: val_loss did not improve\n",
      " - 3s - loss: 0.2161 - acc: 1.0000 - val_loss: 0.5216 - val_acc: 0.8333\n",
      "Epoch 452/600\n",
      "Epoch 00452: val_loss did not improve\n",
      " - 3s - loss: 0.2095 - acc: 1.0000 - val_loss: 0.5281 - val_acc: 0.8333\n",
      "Epoch 453/600\n",
      "Epoch 00453: val_loss did not improve\n",
      " - 3s - loss: 0.2068 - acc: 1.0000 - val_loss: 0.5658 - val_acc: 0.8333\n",
      "Epoch 454/600\n",
      "Epoch 00454: val_loss did not improve\n",
      " - 3s - loss: 0.2043 - acc: 1.0000 - val_loss: 0.5691 - val_acc: 0.8333\n",
      "Epoch 455/600\n",
      "Epoch 00455: val_loss did not improve\n",
      " - 3s - loss: 0.2025 - acc: 1.0000 - val_loss: 0.5619 - val_acc: 0.8333\n",
      "Epoch 456/600\n",
      "Epoch 00456: val_loss did not improve\n",
      " - 3s - loss: 0.2019 - acc: 1.0000 - val_loss: 0.5889 - val_acc: 0.8333\n",
      "Epoch 457/600\n",
      "Epoch 00457: val_loss did not improve\n",
      " - 3s - loss: 0.2020 - acc: 1.0000 - val_loss: 0.5680 - val_acc: 0.6667\n",
      "Epoch 458/600\n",
      "Epoch 00458: val_loss did not improve\n",
      " - 3s - loss: 0.2013 - acc: 1.0000 - val_loss: 0.5869 - val_acc: 0.8333\n",
      "Epoch 459/600\n",
      "Epoch 00459: val_loss did not improve\n",
      " - 3s - loss: 0.1982 - acc: 1.0000 - val_loss: 0.5899 - val_acc: 0.8333\n",
      "Epoch 460/600\n",
      "Epoch 00460: val_loss did not improve\n",
      " - 3s - loss: 0.1966 - acc: 1.0000 - val_loss: 0.6019 - val_acc: 0.8333\n",
      "Epoch 461/600\n",
      "Epoch 00461: val_loss did not improve\n",
      " - 3s - loss: 0.1954 - acc: 1.0000 - val_loss: 0.5703 - val_acc: 0.6667\n",
      "Epoch 462/600\n",
      "Epoch 00462: val_loss did not improve\n",
      " - 3s - loss: 0.1945 - acc: 1.0000 - val_loss: 0.6118 - val_acc: 0.8333\n",
      "Epoch 463/600\n",
      "Epoch 00463: val_loss did not improve\n",
      " - 3s - loss: 0.1940 - acc: 1.0000 - val_loss: 0.5634 - val_acc: 0.6667\n",
      "Epoch 464/600\n",
      "Epoch 00464: val_loss did not improve\n",
      " - 3s - loss: 0.1992 - acc: 1.0000 - val_loss: 0.5674 - val_acc: 0.8333\n",
      "Epoch 465/600\n",
      "Epoch 00465: val_loss did not improve\n",
      " - 3s - loss: 0.1943 - acc: 1.0000 - val_loss: 0.5691 - val_acc: 0.8333\n",
      "Epoch 466/600\n",
      "Epoch 00466: val_loss did not improve\n",
      " - 3s - loss: 0.1929 - acc: 1.0000 - val_loss: 0.5790 - val_acc: 0.8333\n",
      "Epoch 467/600\n",
      "Epoch 00467: val_loss did not improve\n",
      " - 3s - loss: 0.1895 - acc: 1.0000 - val_loss: 0.5904 - val_acc: 0.8333\n",
      "Epoch 468/600\n",
      "Epoch 00468: val_loss did not improve\n",
      " - 3s - loss: 0.1877 - acc: 1.0000 - val_loss: 0.6025 - val_acc: 0.8333\n",
      "Epoch 469/600\n",
      "Epoch 00469: val_loss did not improve\n",
      " - 3s - loss: 0.1863 - acc: 1.0000 - val_loss: 0.5991 - val_acc: 0.8333\n",
      "Epoch 470/600\n",
      "Epoch 00470: val_loss did not improve\n",
      " - 3s - loss: 0.1853 - acc: 1.0000 - val_loss: 0.5683 - val_acc: 0.8333\n",
      "Epoch 471/600\n",
      "Epoch 00471: val_loss did not improve\n",
      " - 3s - loss: 0.1862 - acc: 1.0000 - val_loss: 0.5480 - val_acc: 0.8333\n",
      "Epoch 472/600\n",
      "Epoch 00472: val_loss did not improve\n",
      " - 3s - loss: 0.1914 - acc: 1.0000 - val_loss: 0.5787 - val_acc: 0.8333\n",
      "Epoch 473/600\n",
      "Epoch 00473: val_loss did not improve\n",
      " - 3s - loss: 0.1867 - acc: 1.0000 - val_loss: 0.5367 - val_acc: 0.8333\n",
      "Epoch 474/600\n",
      "Epoch 00474: val_loss did not improve\n",
      " - 3s - loss: 0.1882 - acc: 1.0000 - val_loss: 0.5599 - val_acc: 0.8333\n",
      "Epoch 475/600\n",
      "Epoch 00475: val_loss did not improve\n",
      " - 3s - loss: 0.1835 - acc: 1.0000 - val_loss: 0.5559 - val_acc: 0.8333\n",
      "Epoch 476/600\n",
      "Epoch 00476: val_loss did not improve\n",
      " - 3s - loss: 0.1802 - acc: 1.0000 - val_loss: 0.5316 - val_acc: 0.8333\n",
      "Epoch 477/600\n",
      "Epoch 00477: val_loss did not improve\n",
      " - 3s - loss: 0.1783 - acc: 1.0000 - val_loss: 0.5581 - val_acc: 0.8333\n",
      "Epoch 478/600\n",
      "Epoch 00478: val_loss did not improve\n",
      " - 3s - loss: 0.1770 - acc: 1.0000 - val_loss: 0.5217 - val_acc: 0.8333\n",
      "Epoch 479/600\n",
      "Epoch 00479: val_loss did not improve\n",
      " - 3s - loss: 0.1775 - acc: 1.0000 - val_loss: 0.5313 - val_acc: 0.8333\n",
      "Epoch 480/600\n",
      "Epoch 00480: val_loss did not improve\n",
      " - 3s - loss: 0.1754 - acc: 1.0000 - val_loss: 0.5319 - val_acc: 0.8333\n",
      "Epoch 481/600\n",
      "Epoch 00481: val_loss did not improve\n",
      " - 3s - loss: 0.1838 - acc: 1.0000 - val_loss: 0.5354 - val_acc: 0.8333\n",
      "Epoch 482/600\n",
      "Epoch 00482: val_loss did not improve\n",
      " - 3s - loss: 0.1836 - acc: 1.0000 - val_loss: 0.5623 - val_acc: 0.8333\n",
      "Epoch 483/600\n",
      "Epoch 00483: val_loss did not improve\n",
      " - 3s - loss: 0.1839 - acc: 1.0000 - val_loss: 0.5171 - val_acc: 0.8333\n",
      "Epoch 484/600\n",
      "Epoch 00484: val_loss improved from 0.51157 to 0.47403, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.1803 - acc: 1.0000 - val_loss: 0.4740 - val_acc: 0.8333\n",
      "Epoch 485/600\n",
      "Epoch 00485: val_loss did not improve\n",
      " - 3s - loss: 0.1788 - acc: 1.0000 - val_loss: 0.5311 - val_acc: 0.8333\n",
      "Epoch 486/600\n",
      "Epoch 00486: val_loss did not improve\n",
      " - 3s - loss: 0.1710 - acc: 1.0000 - val_loss: 0.5508 - val_acc: 0.8333\n",
      "Epoch 487/600\n",
      "Epoch 00487: val_loss did not improve\n",
      " - 3s - loss: 0.1691 - acc: 1.0000 - val_loss: 0.5565 - val_acc: 0.8333\n",
      "Epoch 488/600\n",
      "Epoch 00488: val_loss did not improve\n",
      " - 3s - loss: 0.1676 - acc: 1.0000 - val_loss: 0.5631 - val_acc: 0.8333\n",
      "Epoch 489/600\n",
      "Epoch 00489: val_loss did not improve\n",
      " - 3s - loss: 0.1663 - acc: 1.0000 - val_loss: 0.5399 - val_acc: 0.8333\n",
      "Epoch 490/600\n",
      "Epoch 00490: val_loss did not improve\n",
      " - 3s - loss: 0.1656 - acc: 1.0000 - val_loss: 0.5555 - val_acc: 0.8333\n",
      "Epoch 491/600\n",
      "Epoch 00491: val_loss did not improve\n",
      " - 3s - loss: 0.1650 - acc: 1.0000 - val_loss: 0.5326 - val_acc: 0.8333\n",
      "Epoch 492/600\n",
      "Epoch 00492: val_loss did not improve\n",
      " - 3s - loss: 0.1676 - acc: 1.0000 - val_loss: 0.5692 - val_acc: 0.8333\n",
      "Epoch 493/600\n",
      "Epoch 00493: val_loss improved from 0.47403 to 0.46467, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.1634 - acc: 1.0000 - val_loss: 0.4647 - val_acc: 0.8333\n",
      "Epoch 494/600\n",
      "Epoch 00494: val_loss did not improve\n",
      " - 3s - loss: 0.1662 - acc: 1.0000 - val_loss: 0.5516 - val_acc: 0.8333\n",
      "Epoch 495/600\n",
      "Epoch 00495: val_loss did not improve\n",
      " - 3s - loss: 0.1592 - acc: 1.0000 - val_loss: 0.5458 - val_acc: 0.8333\n",
      "Epoch 496/600\n",
      "Epoch 00496: val_loss did not improve\n",
      " - 3s - loss: 0.1615 - acc: 1.0000 - val_loss: 0.5512 - val_acc: 0.8333\n",
      "Epoch 497/600\n",
      "Epoch 00497: val_loss did not improve\n",
      " - 3s - loss: 0.2279 - acc: 1.0000 - val_loss: 0.6627 - val_acc: 0.6667\n",
      "Epoch 498/600\n",
      "Epoch 00498: val_loss did not improve\n",
      " - 3s - loss: 0.5940 - acc: 0.6667 - val_loss: 0.6649 - val_acc: 0.6667\n",
      "Epoch 499/600\n",
      "Epoch 00499: val_loss did not improve\n",
      " - 3s - loss: 0.4166 - acc: 0.8889 - val_loss: 0.5814 - val_acc: 0.6667\n",
      "Epoch 500/600\n",
      "Epoch 00500: val_loss did not improve\n",
      " - 3s - loss: 0.3361 - acc: 1.0000 - val_loss: 0.5674 - val_acc: 0.8333\n",
      "Epoch 501/600\n",
      "Epoch 00501: val_loss did not improve\n",
      " - 3s - loss: 0.3303 - acc: 1.0000 - val_loss: 0.5589 - val_acc: 0.8333\n",
      "Epoch 502/600\n",
      "Epoch 00502: val_loss did not improve\n",
      " - 3s - loss: 0.3101 - acc: 1.0000 - val_loss: 0.5269 - val_acc: 0.8333\n",
      "Epoch 503/600\n",
      "Epoch 00503: val_loss did not improve\n",
      " - 3s - loss: 0.2845 - acc: 1.0000 - val_loss: 0.5015 - val_acc: 0.8333\n",
      "Epoch 504/600\n",
      "Epoch 00504: val_loss did not improve\n",
      " - 3s - loss: 0.2711 - acc: 1.0000 - val_loss: 0.4843 - val_acc: 0.8333\n",
      "Epoch 505/600\n",
      "Epoch 00505: val_loss did not improve\n",
      " - 3s - loss: 0.2557 - acc: 1.0000 - val_loss: 0.5226 - val_acc: 0.8333\n",
      "Epoch 506/600\n",
      "Epoch 00506: val_loss did not improve\n",
      " - 3s - loss: 0.2708 - acc: 1.0000 - val_loss: 0.5170 - val_acc: 0.8333\n",
      "Epoch 507/600\n",
      "Epoch 00507: val_loss did not improve\n",
      " - 3s - loss: 0.2316 - acc: 1.0000 - val_loss: 0.4714 - val_acc: 0.8333\n",
      "Epoch 508/600\n",
      "Epoch 00508: val_loss did not improve\n",
      " - 3s - loss: 0.2367 - acc: 1.0000 - val_loss: 0.5413 - val_acc: 0.8333\n",
      "Epoch 509/600\n",
      "Epoch 00509: val_loss improved from 0.46467 to 0.46369, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.2377 - acc: 1.0000 - val_loss: 0.4637 - val_acc: 0.8333\n",
      "Epoch 510/600\n",
      "Epoch 00510: val_loss did not improve\n",
      " - 3s - loss: 0.2343 - acc: 1.0000 - val_loss: 0.5738 - val_acc: 0.6667\n",
      "Epoch 511/600\n",
      "Epoch 00511: val_loss did not improve\n",
      " - 3s - loss: 0.2232 - acc: 1.0000 - val_loss: 0.5663 - val_acc: 0.6667\n",
      "Epoch 512/600\n",
      "Epoch 00512: val_loss did not improve\n",
      " - 3s - loss: 0.2170 - acc: 1.0000 - val_loss: 0.5128 - val_acc: 0.8333\n",
      "Epoch 513/600\n",
      "Epoch 00513: val_loss did not improve\n",
      " - 3s - loss: 0.2083 - acc: 1.0000 - val_loss: 0.6185 - val_acc: 0.6667\n",
      "Epoch 514/600\n",
      "Epoch 00514: val_loss improved from 0.46369 to 0.45838, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.2109 - acc: 1.0000 - val_loss: 0.4584 - val_acc: 0.8333\n",
      "Epoch 515/600\n",
      "Epoch 00515: val_loss did not improve\n",
      " - 3s - loss: 0.2204 - acc: 1.0000 - val_loss: 0.4892 - val_acc: 0.8333\n",
      "Epoch 516/600\n",
      "Epoch 00516: val_loss did not improve\n",
      " - 3s - loss: 0.2172 - acc: 1.0000 - val_loss: 0.4736 - val_acc: 0.8333\n",
      "Epoch 517/600\n",
      "Epoch 00517: val_loss did not improve\n",
      " - 3s - loss: 0.1993 - acc: 1.0000 - val_loss: 0.4767 - val_acc: 0.8333\n",
      "Epoch 518/600\n",
      "Epoch 00518: val_loss did not improve\n",
      " - 3s - loss: 0.2112 - acc: 1.0000 - val_loss: 0.4779 - val_acc: 0.8333\n",
      "Epoch 519/600\n",
      "Epoch 00519: val_loss did not improve\n",
      " - 3s - loss: 0.2002 - acc: 1.0000 - val_loss: 0.5000 - val_acc: 0.8333\n",
      "Epoch 520/600\n",
      "Epoch 00520: val_loss did not improve\n",
      " - 3s - loss: 0.1851 - acc: 1.0000 - val_loss: 0.5069 - val_acc: 0.8333\n",
      "Epoch 521/600\n",
      "Epoch 00521: val_loss did not improve\n",
      " - 3s - loss: 0.1828 - acc: 1.0000 - val_loss: 0.5101 - val_acc: 0.8333\n",
      "Epoch 522/600\n",
      "Epoch 00522: val_loss did not improve\n",
      " - 3s - loss: 0.1803 - acc: 1.0000 - val_loss: 0.5120 - val_acc: 0.8333\n",
      "Epoch 523/600\n",
      "Epoch 00523: val_loss did not improve\n",
      " - 3s - loss: 0.1775 - acc: 1.0000 - val_loss: 0.5129 - val_acc: 0.8333\n",
      "Epoch 524/600\n",
      "Epoch 00524: val_loss did not improve\n",
      " - 3s - loss: 0.1750 - acc: 1.0000 - val_loss: 0.5411 - val_acc: 0.8333\n",
      "Epoch 525/600\n",
      "Epoch 00525: val_loss did not improve\n",
      " - 3s - loss: 0.1737 - acc: 1.0000 - val_loss: 0.5100 - val_acc: 0.8333\n",
      "Epoch 526/600\n",
      "Epoch 00526: val_loss did not improve\n",
      " - 3s - loss: 0.1723 - acc: 1.0000 - val_loss: 0.5582 - val_acc: 0.8333\n",
      "Epoch 527/600\n",
      "Epoch 00527: val_loss did not improve\n",
      " - 3s - loss: 0.1699 - acc: 1.0000 - val_loss: 0.5104 - val_acc: 0.8333\n",
      "Epoch 528/600\n",
      "Epoch 00528: val_loss did not improve\n",
      " - 3s - loss: 0.1790 - acc: 1.0000 - val_loss: 0.4799 - val_acc: 0.8333\n",
      "Epoch 529/600\n",
      "Epoch 00529: val_loss did not improve\n",
      " - 3s - loss: 0.1797 - acc: 1.0000 - val_loss: 0.5329 - val_acc: 0.8333\n",
      "Epoch 530/600\n",
      "Epoch 00530: val_loss did not improve\n",
      " - 3s - loss: 0.1730 - acc: 1.0000 - val_loss: 0.5804 - val_acc: 0.8333\n",
      "Epoch 531/600\n",
      "Epoch 00531: val_loss did not improve\n",
      " - 3s - loss: 0.1663 - acc: 1.0000 - val_loss: 0.5765 - val_acc: 0.8333\n",
      "Epoch 532/600\n",
      "Epoch 00532: val_loss did not improve\n",
      " - 3s - loss: 0.1631 - acc: 1.0000 - val_loss: 0.5254 - val_acc: 0.8333\n",
      "Epoch 533/600\n",
      "Epoch 00533: val_loss did not improve\n",
      " - 3s - loss: 0.1663 - acc: 1.0000 - val_loss: 0.5561 - val_acc: 0.8333\n",
      "Epoch 534/600\n",
      "Epoch 00534: val_loss did not improve\n",
      " - 3s - loss: 0.1643 - acc: 1.0000 - val_loss: 0.5556 - val_acc: 0.8333\n",
      "Epoch 535/600\n",
      "Epoch 00535: val_loss did not improve\n",
      " - 3s - loss: 0.1751 - acc: 1.0000 - val_loss: 0.5107 - val_acc: 0.8333\n",
      "Epoch 536/600\n",
      "Epoch 00536: val_loss did not improve\n",
      " - 3s - loss: 0.1703 - acc: 1.0000 - val_loss: 0.5967 - val_acc: 0.8333\n",
      "Epoch 537/600\n",
      "Epoch 00537: val_loss did not improve\n",
      " - 3s - loss: 0.1622 - acc: 1.0000 - val_loss: 0.5167 - val_acc: 0.8333\n",
      "Epoch 538/600\n",
      "Epoch 00538: val_loss did not improve\n",
      " - 3s - loss: 0.1600 - acc: 1.0000 - val_loss: 0.5834 - val_acc: 0.8333\n",
      "Epoch 539/600\n",
      "Epoch 00539: val_loss did not improve\n",
      " - 3s - loss: 0.1566 - acc: 1.0000 - val_loss: 0.5669 - val_acc: 0.8333\n",
      "Epoch 540/600\n",
      "Epoch 00540: val_loss did not improve\n",
      " - 3s - loss: 0.1555 - acc: 1.0000 - val_loss: 0.6152 - val_acc: 0.8333\n",
      "Epoch 541/600\n",
      "Epoch 00541: val_loss improved from 0.45838 to 0.44406, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.1565 - acc: 1.0000 - val_loss: 0.4441 - val_acc: 0.8333\n",
      "Epoch 542/600\n",
      "Epoch 00542: val_loss did not improve\n",
      " - 3s - loss: 0.1470 - acc: 1.0000 - val_loss: 0.4980 - val_acc: 0.8333\n",
      "Epoch 543/600\n",
      "Epoch 00543: val_loss did not improve\n",
      " - 3s - loss: 0.1460 - acc: 1.0000 - val_loss: 0.4905 - val_acc: 0.8333\n",
      "Epoch 544/600\n",
      "Epoch 00544: val_loss did not improve\n",
      " - 3s - loss: 0.1423 - acc: 1.0000 - val_loss: 0.4784 - val_acc: 0.8333\n",
      "Epoch 545/600\n",
      "Epoch 00545: val_loss did not improve\n",
      " - 3s - loss: 0.1410 - acc: 1.0000 - val_loss: 0.4708 - val_acc: 0.8333\n",
      "Epoch 546/600\n",
      "Epoch 00546: val_loss improved from 0.44406 to 0.43952, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.1394 - acc: 1.0000 - val_loss: 0.4395 - val_acc: 0.8333\n",
      "Epoch 547/600\n",
      "Epoch 00547: val_loss improved from 0.43952 to 0.39737, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.1407 - acc: 1.0000 - val_loss: 0.3974 - val_acc: 0.8333\n",
      "Epoch 548/600\n",
      "Epoch 00548: val_loss improved from 0.39737 to 0.39193, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.1379 - acc: 1.0000 - val_loss: 0.3919 - val_acc: 0.8333\n",
      "Epoch 549/600\n",
      "Epoch 00549: val_loss did not improve\n",
      " - 3s - loss: 0.1372 - acc: 1.0000 - val_loss: 0.4479 - val_acc: 0.8333\n",
      "Epoch 550/600\n",
      "Epoch 00550: val_loss did not improve\n",
      " - 3s - loss: 0.1370 - acc: 1.0000 - val_loss: 0.4545 - val_acc: 0.8333\n",
      "Epoch 551/600\n",
      "Epoch 00551: val_loss did not improve\n",
      " - 3s - loss: 0.1347 - acc: 1.0000 - val_loss: 0.4262 - val_acc: 0.8333\n",
      "Epoch 552/600\n",
      "Epoch 00552: val_loss did not improve\n",
      " - 3s - loss: 0.1350 - acc: 1.0000 - val_loss: 0.3991 - val_acc: 0.8333\n",
      "Epoch 553/600\n",
      "Epoch 00553: val_loss did not improve\n",
      " - 3s - loss: 0.1340 - acc: 1.0000 - val_loss: 0.4733 - val_acc: 0.8333\n",
      "Epoch 554/600\n",
      "Epoch 00554: val_loss did not improve\n",
      " - 3s - loss: 0.1332 - acc: 1.0000 - val_loss: 0.4531 - val_acc: 0.8333\n",
      "Epoch 555/600\n",
      "Epoch 00555: val_loss did not improve\n",
      " - 3s - loss: 0.1315 - acc: 1.0000 - val_loss: 0.4481 - val_acc: 0.8333\n",
      "Epoch 556/600\n",
      "Epoch 00556: val_loss did not improve\n",
      " - 3s - loss: 0.1315 - acc: 1.0000 - val_loss: 0.4078 - val_acc: 0.8333\n",
      "Epoch 557/600\n",
      "Epoch 00557: val_loss did not improve\n",
      " - 3s - loss: 0.1299 - acc: 1.0000 - val_loss: 0.4509 - val_acc: 0.8333\n",
      "Epoch 558/600\n",
      "Epoch 00558: val_loss did not improve\n",
      " - 3s - loss: 0.1295 - acc: 1.0000 - val_loss: 0.4250 - val_acc: 0.8333\n",
      "Epoch 559/600\n",
      "Epoch 00559: val_loss did not improve\n",
      " - 3s - loss: 0.1283 - acc: 1.0000 - val_loss: 0.4866 - val_acc: 0.8333\n",
      "Epoch 560/600\n",
      "Epoch 00560: val_loss did not improve\n",
      " - 3s - loss: 0.1295 - acc: 1.0000 - val_loss: 0.4219 - val_acc: 0.8333\n",
      "Epoch 561/600\n",
      "Epoch 00561: val_loss did not improve\n",
      " - 3s - loss: 0.1310 - acc: 1.0000 - val_loss: 0.4702 - val_acc: 0.8333\n",
      "Epoch 562/600\n",
      "Epoch 00562: val_loss did not improve\n",
      " - 3s - loss: 0.1273 - acc: 1.0000 - val_loss: 0.4047 - val_acc: 0.8333\n",
      "Epoch 563/600\n",
      "Epoch 00563: val_loss did not improve\n",
      " - 3s - loss: 0.1252 - acc: 1.0000 - val_loss: 0.4928 - val_acc: 0.8333\n",
      "Epoch 564/600\n",
      "Epoch 00564: val_loss did not improve\n",
      " - 3s - loss: 0.1258 - acc: 1.0000 - val_loss: 0.4909 - val_acc: 0.8333\n",
      "Epoch 565/600\n",
      "Epoch 00565: val_loss did not improve\n",
      " - 3s - loss: 0.1234 - acc: 1.0000 - val_loss: 0.4066 - val_acc: 0.8333\n",
      "Epoch 566/600\n",
      "Epoch 00566: val_loss did not improve\n",
      " - 3s - loss: 0.1243 - acc: 1.0000 - val_loss: 0.4033 - val_acc: 0.8333\n",
      "Epoch 567/600\n",
      "Epoch 00567: val_loss did not improve\n",
      " - 3s - loss: 0.1279 - acc: 1.0000 - val_loss: 0.5184 - val_acc: 0.8333\n",
      "Epoch 568/600\n",
      "Epoch 00568: val_loss did not improve\n",
      " - 3s - loss: 0.1390 - acc: 1.0000 - val_loss: 0.6810 - val_acc: 0.6667\n",
      "Epoch 569/600\n",
      "Epoch 00569: val_loss did not improve\n",
      " - 3s - loss: 0.2020 - acc: 1.0000 - val_loss: 0.4983 - val_acc: 0.8333\n",
      "Epoch 570/600\n",
      "Epoch 00570: val_loss did not improve\n",
      " - 3s - loss: 0.2177 - acc: 0.8889 - val_loss: 0.5484 - val_acc: 0.6667\n",
      "Epoch 571/600\n",
      "Epoch 00571: val_loss did not improve\n",
      " - 3s - loss: 0.1385 - acc: 1.0000 - val_loss: 0.5731 - val_acc: 0.6667\n",
      "Epoch 572/600\n",
      "Epoch 00572: val_loss did not improve\n",
      " - 3s - loss: 0.1826 - acc: 1.0000 - val_loss: 0.5201 - val_acc: 0.6667\n",
      "Epoch 573/600\n",
      "Epoch 00573: val_loss did not improve\n",
      " - 3s - loss: 0.1228 - acc: 1.0000 - val_loss: 0.5173 - val_acc: 0.6667\n",
      "Epoch 574/600\n",
      "Epoch 00574: val_loss did not improve\n",
      " - 3s - loss: 0.1209 - acc: 1.0000 - val_loss: 0.5333 - val_acc: 0.6667\n",
      "Epoch 575/600\n",
      "Epoch 00575: val_loss did not improve\n",
      " - 3s - loss: 0.1172 - acc: 1.0000 - val_loss: 0.5292 - val_acc: 0.6667\n",
      "Epoch 576/600\n",
      "Epoch 00576: val_loss did not improve\n",
      " - 3s - loss: 0.1152 - acc: 1.0000 - val_loss: 0.5284 - val_acc: 0.6667\n",
      "Epoch 577/600\n",
      "Epoch 00577: val_loss did not improve\n",
      " - 3s - loss: 0.1135 - acc: 1.0000 - val_loss: 0.5278 - val_acc: 0.6667\n",
      "Epoch 578/600\n",
      "Epoch 00578: val_loss did not improve\n",
      " - 3s - loss: 0.1127 - acc: 1.0000 - val_loss: 0.5279 - val_acc: 0.6667\n",
      "Epoch 579/600\n",
      "Epoch 00579: val_loss did not improve\n",
      " - 3s - loss: 0.1114 - acc: 1.0000 - val_loss: 0.5276 - val_acc: 0.6667\n",
      "Epoch 580/600\n",
      "Epoch 00580: val_loss did not improve\n",
      " - 3s - loss: 0.1107 - acc: 1.0000 - val_loss: 0.5286 - val_acc: 0.6667\n",
      "Epoch 581/600\n",
      "Epoch 00581: val_loss did not improve\n",
      " - 3s - loss: 0.1091 - acc: 1.0000 - val_loss: 0.5297 - val_acc: 0.6667\n",
      "Epoch 582/600\n",
      "Epoch 00582: val_loss did not improve\n",
      " - 3s - loss: 0.1085 - acc: 1.0000 - val_loss: 0.5303 - val_acc: 0.6667\n",
      "Epoch 583/600\n",
      "Epoch 00583: val_loss did not improve\n",
      " - 3s - loss: 0.1075 - acc: 1.0000 - val_loss: 0.5394 - val_acc: 0.6667\n",
      "Epoch 584/600\n",
      "Epoch 00584: val_loss did not improve\n",
      " - 3s - loss: 0.1061 - acc: 1.0000 - val_loss: 0.5606 - val_acc: 0.6667\n",
      "Epoch 585/600\n",
      "Epoch 00585: val_loss did not improve\n",
      " - 3s - loss: 0.1064 - acc: 1.0000 - val_loss: 0.5364 - val_acc: 0.6667\n",
      "Epoch 586/600\n",
      "Epoch 00586: val_loss did not improve\n",
      " - 3s - loss: 0.1053 - acc: 1.0000 - val_loss: 0.5702 - val_acc: 0.6667\n",
      "Epoch 587/600\n",
      "Epoch 00587: val_loss did not improve\n",
      " - 3s - loss: 0.1048 - acc: 1.0000 - val_loss: 0.5323 - val_acc: 0.6667\n",
      "Epoch 588/600\n",
      "Epoch 00588: val_loss did not improve\n",
      " - 3s - loss: 0.1047 - acc: 1.0000 - val_loss: 0.5624 - val_acc: 0.6667\n",
      "Epoch 589/600\n",
      "Epoch 00589: val_loss did not improve\n",
      " - 3s - loss: 0.1033 - acc: 1.0000 - val_loss: 0.5664 - val_acc: 0.6667\n",
      "Epoch 590/600\n",
      "Epoch 00590: val_loss did not improve\n",
      " - 3s - loss: 0.1023 - acc: 1.0000 - val_loss: 0.5687 - val_acc: 0.6667\n",
      "Epoch 591/600\n",
      "Epoch 00591: val_loss did not improve\n",
      " - 3s - loss: 0.1015 - acc: 1.0000 - val_loss: 0.5680 - val_acc: 0.6667\n",
      "Epoch 592/600\n",
      "Epoch 00592: val_loss did not improve\n",
      " - 3s - loss: 0.1032 - acc: 1.0000 - val_loss: 0.5707 - val_acc: 0.6667\n",
      "Epoch 593/600\n",
      "Epoch 00593: val_loss did not improve\n",
      " - 3s - loss: 0.1026 - acc: 1.0000 - val_loss: 0.5670 - val_acc: 0.6667\n",
      "Epoch 594/600\n",
      "Epoch 00594: val_loss did not improve\n",
      " - 3s - loss: 0.1017 - acc: 1.0000 - val_loss: 0.6024 - val_acc: 0.6667\n",
      "Epoch 595/600\n",
      "Epoch 00595: val_loss did not improve\n",
      " - 3s - loss: 0.1001 - acc: 1.0000 - val_loss: 0.6011 - val_acc: 0.6667\n",
      "Epoch 596/600\n",
      "Epoch 00596: val_loss did not improve\n",
      " - 3s - loss: 0.0980 - acc: 1.0000 - val_loss: 0.5641 - val_acc: 0.6667\n",
      "Epoch 597/600\n",
      "Epoch 00597: val_loss did not improve\n",
      " - 3s - loss: 0.0986 - acc: 1.0000 - val_loss: 0.6078 - val_acc: 0.6667\n",
      "Epoch 598/600\n",
      "Epoch 00598: val_loss did not improve\n",
      " - 3s - loss: 0.0961 - acc: 1.0000 - val_loss: 0.6030 - val_acc: 0.6667\n",
      "Epoch 599/600\n",
      "Epoch 00599: val_loss did not improve\n",
      " - 3s - loss: 0.0968 - acc: 1.0000 - val_loss: 0.5574 - val_acc: 0.6667\n",
      "Epoch 600/600\n",
      "Epoch 00600: val_loss did not improve\n",
      " - 3s - loss: 0.0992 - acc: 1.0000 - val_loss: 0.5676 - val_acc: 0.6667\n"
     ]
    }
   ],
   "source": [
    "print('Training ------------')\n",
    "model_history=model.fit(x_train, y_train,\n",
    "          validation_data=(x_test,y_test),epochs=300,verbose=2,\n",
    "          batch_size=9,callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEFCAYAAADqujDUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBIBCoVD4KUoAKBQKhZ/y/6X44hy/i+bjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1dd5c74ad30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_plot(model_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
