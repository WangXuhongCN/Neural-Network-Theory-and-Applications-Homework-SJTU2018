{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical,np_utils\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, LSTM, Activation,Dropout,Masking, Embedding\n",
    "from keras import optimizers\n",
    "from  keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.image as pimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_plot(self,n_epochs):\n",
    "    #iters = range(len(self.epoch))\n",
    "    iters = range(n_epochs)\n",
    "    plt.figure()\n",
    "    # acc\n",
    "    plt.plot(iters, self.history['acc'] [:n_epochs],'r', label='train acc', linewidth=1.0)\n",
    "    # loss\n",
    "    plt.plot(iters, self.history['loss'][:n_epochs], 'g', label='train loss', linewidth=1.0)\n",
    "    \n",
    "    # val_acc\n",
    "    plt.plot(iters, self.history['val_acc'][:n_epochs], 'b', label='val acc', linewidth=1.0)\n",
    "    # val_loss\n",
    "    plt.plot(iters, self.history['val_loss'][:n_epochs], 'k', label='val loss', linewidth=1.0)\n",
    "    plt.grid(True)\n",
    "    plt.ylim(0,1.2)\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(loc='best',shadow=True, fontsize='6')#loc=\"upper right\"\n",
    "    plt.savefig('loss of lstm 03.png', dpi=400)\n",
    "    sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_data_01=np.load('D:\\\\GitHub\\\\Neural-Network-Theory-and-Applications-Homework-SJTU2018\\\\Homework Assignment 4\\\\data_used\\\\01.npz')\n",
    "files_in_zip_01 = zip_data_01.keys()\n",
    "label01= np.load('D:\\\\GitHub\\\\Neural-Network-Theory-and-Applications-Homework-SJTU2018\\\\Homework Assignment 4\\\\data_used\\\\label.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下一个cell：数据预处理，将01.npz数据集变成（15,265,310）的形式，长度不够265的补零\n",
    "也就是说，将变长序列变为定长序列，\n",
    "变形方法：https://stackoverflow.com/questions/35751306/python-how-to-pad-numpy-array-with-zeros \n",
    "行为解释：https://www.cnblogs.com/leeshum/p/6089286.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data01=np.zeros((15,265,310))\n",
    "for i in range(15):\n",
    "    for j in range(265):\n",
    "        if j < zip_data_01[files_in_zip_01[i]].shape[1]:\n",
    "            data01[i,j,:]=zip_data_01[files_in_zip_01[i]][:,j,:].reshape(310)\n",
    "        else:\n",
    "            data01[i,j,:]=np.zeros(310)\n",
    "data01/=np.max(data01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=data01[:9,:,:]\n",
    "x_test=data01[9:,:,:]\n",
    "y_train=label01[:9]\n",
    "y_test=label01[9:]\n",
    "y_train = np_utils.to_categorical(y_train, num_classes=3)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_1 (Masking)          (None, 265, 310)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 265, 128)          224768    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 356,739\n",
      "Trainable params: 356,739\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "    #model.add(Embedding(81250, 128, mask_zero=True))\n",
    "model.add(Masking(mask_value=0,input_shape=(265, 310)))\n",
    "model.add(LSTM(128,return_sequences=True))#\n",
    "#model.add(Activation('relu'))\n",
    "model.add(LSTM(128))\n",
    "#model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "RMS = optimizers.RMSprop(lr=1e-5)\n",
    "model.compile(optimizer=RMS,\n",
    "      loss='categorical_crossentropy',\n",
    "      metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "filepath=\"model-3-best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "earlystop=EarlyStopping(monitor='val_loss', patience=20, verbose=2, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load a model\n",
    "model=load_model('D:/GitHub/Neural-Network-Theory-and-Applications-Homework-SJTU2018/Homework Assignment 4/model-3-best.hdf5')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ------------\n",
      "Train on 9 samples, validate on 6 samples\n",
      "Epoch 1/400\n",
      "Epoch 00001: val_loss improved from inf to 1.09821, saving model to model-3-best.hdf5\n",
      " - 6s - loss: 1.1001 - acc: 0.3333 - val_loss: 1.0982 - val_acc: 0.5000\n",
      "Epoch 2/400\n",
      "Epoch 00002: val_loss improved from 1.09821 to 1.09789, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0992 - acc: 0.4444 - val_loss: 1.0979 - val_acc: 0.5000\n",
      "Epoch 3/400\n",
      "Epoch 00003: val_loss improved from 1.09789 to 1.09763, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0988 - acc: 0.4444 - val_loss: 1.0976 - val_acc: 0.3333\n",
      "Epoch 4/400\n",
      "Epoch 00004: val_loss improved from 1.09763 to 1.09740, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0985 - acc: 0.3333 - val_loss: 1.0974 - val_acc: 0.5000\n",
      "Epoch 5/400\n",
      "Epoch 00005: val_loss improved from 1.09740 to 1.09719, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0982 - acc: 0.5556 - val_loss: 1.0972 - val_acc: 0.3333\n",
      "Epoch 6/400\n",
      "Epoch 00006: val_loss improved from 1.09719 to 1.09700, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0979 - acc: 0.4444 - val_loss: 1.0970 - val_acc: 0.5000\n",
      "Epoch 7/400\n",
      "Epoch 00007: val_loss improved from 1.09700 to 1.09681, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0976 - acc: 0.6667 - val_loss: 1.0968 - val_acc: 0.5000\n",
      "Epoch 8/400\n",
      "Epoch 00008: val_loss improved from 1.09681 to 1.09663, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0974 - acc: 0.4444 - val_loss: 1.0966 - val_acc: 0.5000\n",
      "Epoch 9/400\n",
      "Epoch 00009: val_loss improved from 1.09663 to 1.09646, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0972 - acc: 0.4444 - val_loss: 1.0965 - val_acc: 0.5000\n",
      "Epoch 10/400\n",
      "Epoch 00010: val_loss improved from 1.09646 to 1.09629, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0969 - acc: 0.4444 - val_loss: 1.0963 - val_acc: 0.5000\n",
      "Epoch 11/400\n",
      "Epoch 00011: val_loss improved from 1.09629 to 1.09612, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0967 - acc: 0.4444 - val_loss: 1.0961 - val_acc: 0.5000\n",
      "Epoch 12/400\n",
      "Epoch 00012: val_loss improved from 1.09612 to 1.09595, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0965 - acc: 0.4444 - val_loss: 1.0960 - val_acc: 0.5000\n",
      "Epoch 13/400\n",
      "Epoch 00013: val_loss improved from 1.09595 to 1.09579, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0963 - acc: 0.4444 - val_loss: 1.0958 - val_acc: 0.5000\n",
      "Epoch 14/400\n",
      "Epoch 00014: val_loss improved from 1.09579 to 1.09563, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0961 - acc: 0.5556 - val_loss: 1.0956 - val_acc: 0.5000\n",
      "Epoch 15/400\n",
      "Epoch 00015: val_loss improved from 1.09563 to 1.09547, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0959 - acc: 0.5556 - val_loss: 1.0955 - val_acc: 0.5000\n",
      "Epoch 16/400\n",
      "Epoch 00016: val_loss improved from 1.09547 to 1.09531, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0957 - acc: 0.5556 - val_loss: 1.0953 - val_acc: 0.5000\n",
      "Epoch 17/400\n",
      "Epoch 00017: val_loss improved from 1.09531 to 1.09516, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0954 - acc: 0.5556 - val_loss: 1.0952 - val_acc: 0.3333\n",
      "Epoch 18/400\n",
      "Epoch 00018: val_loss improved from 1.09516 to 1.09500, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0952 - acc: 0.5556 - val_loss: 1.0950 - val_acc: 0.3333\n",
      "Epoch 19/400\n",
      "Epoch 00019: val_loss improved from 1.09500 to 1.09484, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0950 - acc: 0.5556 - val_loss: 1.0948 - val_acc: 0.3333\n",
      "Epoch 20/400\n",
      "Epoch 00020: val_loss improved from 1.09484 to 1.09469, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0948 - acc: 0.5556 - val_loss: 1.0947 - val_acc: 0.3333\n",
      "Epoch 21/400\n",
      "Epoch 00021: val_loss improved from 1.09469 to 1.09453, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0946 - acc: 0.5556 - val_loss: 1.0945 - val_acc: 0.3333\n",
      "Epoch 22/400\n",
      "Epoch 00022: val_loss improved from 1.09453 to 1.09437, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0944 - acc: 0.5556 - val_loss: 1.0944 - val_acc: 0.3333\n",
      "Epoch 23/400\n",
      "Epoch 00023: val_loss improved from 1.09437 to 1.09421, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0942 - acc: 0.6667 - val_loss: 1.0942 - val_acc: 0.3333\n",
      "Epoch 24/400\n",
      "Epoch 00024: val_loss improved from 1.09421 to 1.09406, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0940 - acc: 0.6667 - val_loss: 1.0941 - val_acc: 0.3333\n",
      "Epoch 25/400\n",
      "Epoch 00025: val_loss improved from 1.09406 to 1.09390, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0938 - acc: 0.7778 - val_loss: 1.0939 - val_acc: 0.3333\n",
      "Epoch 26/400\n",
      "Epoch 00026: val_loss improved from 1.09390 to 1.09374, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0936 - acc: 0.7778 - val_loss: 1.0937 - val_acc: 0.3333\n",
      "Epoch 27/400\n",
      "Epoch 00027: val_loss improved from 1.09374 to 1.09358, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0934 - acc: 0.7778 - val_loss: 1.0936 - val_acc: 0.3333\n",
      "Epoch 28/400\n",
      "Epoch 00028: val_loss improved from 1.09358 to 1.09342, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0931 - acc: 0.7778 - val_loss: 1.0934 - val_acc: 0.3333\n",
      "Epoch 29/400\n",
      "Epoch 00029: val_loss improved from 1.09342 to 1.09325, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0929 - acc: 0.7778 - val_loss: 1.0933 - val_acc: 0.3333\n",
      "Epoch 30/400\n",
      "Epoch 00030: val_loss improved from 1.09325 to 1.09309, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0927 - acc: 0.7778 - val_loss: 1.0931 - val_acc: 0.3333\n",
      "Epoch 31/400\n",
      "Epoch 00031: val_loss improved from 1.09309 to 1.09293, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0925 - acc: 0.7778 - val_loss: 1.0929 - val_acc: 0.3333\n",
      "Epoch 32/400\n",
      "Epoch 00032: val_loss improved from 1.09293 to 1.09276, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0923 - acc: 0.8889 - val_loss: 1.0928 - val_acc: 0.3333\n",
      "Epoch 33/400\n",
      "Epoch 00033: val_loss improved from 1.09276 to 1.09259, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0921 - acc: 0.8889 - val_loss: 1.0926 - val_acc: 0.5000\n",
      "Epoch 34/400\n",
      "Epoch 00034: val_loss improved from 1.09259 to 1.09242, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0918 - acc: 0.8889 - val_loss: 1.0924 - val_acc: 0.5000\n",
      "Epoch 35/400\n",
      "Epoch 00035: val_loss improved from 1.09242 to 1.09226, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0916 - acc: 0.8889 - val_loss: 1.0923 - val_acc: 0.5000\n",
      "Epoch 36/400\n",
      "Epoch 00036: val_loss improved from 1.09226 to 1.09208, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0914 - acc: 0.8889 - val_loss: 1.0921 - val_acc: 0.5000\n",
      "Epoch 37/400\n",
      "Epoch 00037: val_loss improved from 1.09208 to 1.09191, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0912 - acc: 0.8889 - val_loss: 1.0919 - val_acc: 0.5000\n",
      "Epoch 38/400\n",
      "Epoch 00038: val_loss improved from 1.09191 to 1.09174, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0909 - acc: 0.8889 - val_loss: 1.0917 - val_acc: 0.5000\n",
      "Epoch 39/400\n",
      "Epoch 00039: val_loss improved from 1.09174 to 1.09156, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0907 - acc: 0.8889 - val_loss: 1.0916 - val_acc: 0.5000\n",
      "Epoch 40/400\n",
      "Epoch 00040: val_loss improved from 1.09156 to 1.09138, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0905 - acc: 0.8889 - val_loss: 1.0914 - val_acc: 0.5000\n",
      "Epoch 41/400\n",
      "Epoch 00041: val_loss improved from 1.09138 to 1.09120, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0902 - acc: 0.8889 - val_loss: 1.0912 - val_acc: 0.5000\n",
      "Epoch 42/400\n",
      "Epoch 00042: val_loss improved from 1.09120 to 1.09102, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0900 - acc: 0.8889 - val_loss: 1.0910 - val_acc: 0.5000\n",
      "Epoch 43/400\n",
      "Epoch 00043: val_loss improved from 1.09102 to 1.09084, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0897 - acc: 0.8889 - val_loss: 1.0908 - val_acc: 0.5000\n",
      "Epoch 44/400\n",
      "Epoch 00044: val_loss improved from 1.09084 to 1.09065, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0895 - acc: 0.8889 - val_loss: 1.0907 - val_acc: 0.5000\n",
      "Epoch 45/400\n",
      "Epoch 00045: val_loss improved from 1.09065 to 1.09046, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0893 - acc: 0.8889 - val_loss: 1.0905 - val_acc: 0.5000\n",
      "Epoch 46/400\n",
      "Epoch 00046: val_loss improved from 1.09046 to 1.09027, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0890 - acc: 0.8889 - val_loss: 1.0903 - val_acc: 0.5000\n",
      "Epoch 47/400\n",
      "Epoch 00047: val_loss improved from 1.09027 to 1.09008, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0888 - acc: 0.8889 - val_loss: 1.0901 - val_acc: 0.5000\n",
      "Epoch 48/400\n",
      "Epoch 00048: val_loss improved from 1.09008 to 1.08989, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0885 - acc: 0.8889 - val_loss: 1.0899 - val_acc: 0.5000\n",
      "Epoch 49/400\n",
      "Epoch 00049: val_loss improved from 1.08989 to 1.08969, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0882 - acc: 0.8889 - val_loss: 1.0897 - val_acc: 0.5000\n",
      "Epoch 50/400\n",
      "Epoch 00050: val_loss improved from 1.08969 to 1.08949, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0880 - acc: 0.8889 - val_loss: 1.0895 - val_acc: 0.5000\n",
      "Epoch 51/400\n",
      "Epoch 00051: val_loss improved from 1.08949 to 1.08929, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0877 - acc: 0.8889 - val_loss: 1.0893 - val_acc: 0.5000\n",
      "Epoch 52/400\n",
      "Epoch 00052: val_loss improved from 1.08929 to 1.08909, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0875 - acc: 0.8889 - val_loss: 1.0891 - val_acc: 0.5000\n",
      "Epoch 53/400\n",
      "Epoch 00053: val_loss improved from 1.08909 to 1.08888, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0872 - acc: 0.8889 - val_loss: 1.0889 - val_acc: 0.5000\n",
      "Epoch 54/400\n",
      "Epoch 00054: val_loss improved from 1.08888 to 1.08867, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0869 - acc: 0.8889 - val_loss: 1.0887 - val_acc: 0.6667\n",
      "Epoch 55/400\n",
      "Epoch 00055: val_loss improved from 1.08867 to 1.08846, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0866 - acc: 0.8889 - val_loss: 1.0885 - val_acc: 0.6667\n",
      "Epoch 56/400\n",
      "Epoch 00056: val_loss improved from 1.08846 to 1.08825, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0864 - acc: 0.8889 - val_loss: 1.0882 - val_acc: 0.6667\n",
      "Epoch 57/400\n",
      "Epoch 00057: val_loss improved from 1.08825 to 1.08803, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0861 - acc: 0.8889 - val_loss: 1.0880 - val_acc: 0.6667\n",
      "Epoch 58/400\n",
      "Epoch 00058: val_loss improved from 1.08803 to 1.08781, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0858 - acc: 0.8889 - val_loss: 1.0878 - val_acc: 0.6667\n",
      "Epoch 59/400\n",
      "Epoch 00059: val_loss improved from 1.08781 to 1.08759, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0855 - acc: 0.8889 - val_loss: 1.0876 - val_acc: 0.6667\n",
      "Epoch 60/400\n",
      "Epoch 00060: val_loss improved from 1.08759 to 1.08736, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0852 - acc: 0.8889 - val_loss: 1.0874 - val_acc: 0.6667\n",
      "Epoch 61/400\n",
      "Epoch 00061: val_loss improved from 1.08736 to 1.08713, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0849 - acc: 0.8889 - val_loss: 1.0871 - val_acc: 0.6667\n",
      "Epoch 62/400\n",
      "Epoch 00062: val_loss improved from 1.08713 to 1.08690, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0846 - acc: 0.8889 - val_loss: 1.0869 - val_acc: 0.6667\n",
      "Epoch 63/400\n",
      "Epoch 00063: val_loss improved from 1.08690 to 1.08666, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0843 - acc: 0.8889 - val_loss: 1.0867 - val_acc: 0.6667\n",
      "Epoch 64/400\n",
      "Epoch 00064: val_loss improved from 1.08666 to 1.08642, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0840 - acc: 0.8889 - val_loss: 1.0864 - val_acc: 0.6667\n",
      "Epoch 65/400\n",
      "Epoch 00065: val_loss improved from 1.08642 to 1.08618, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0837 - acc: 0.8889 - val_loss: 1.0862 - val_acc: 0.6667\n",
      "Epoch 66/400\n",
      "Epoch 00066: val_loss improved from 1.08618 to 1.08593, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0834 - acc: 0.8889 - val_loss: 1.0859 - val_acc: 0.6667\n",
      "Epoch 67/400\n",
      "Epoch 00067: val_loss improved from 1.08593 to 1.08568, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0831 - acc: 0.8889 - val_loss: 1.0857 - val_acc: 0.6667\n",
      "Epoch 68/400\n",
      "Epoch 00068: val_loss improved from 1.08568 to 1.08542, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0827 - acc: 0.8889 - val_loss: 1.0854 - val_acc: 0.6667\n",
      "Epoch 69/400\n",
      "Epoch 00069: val_loss improved from 1.08542 to 1.08516, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0824 - acc: 0.8889 - val_loss: 1.0852 - val_acc: 0.6667\n",
      "Epoch 70/400\n",
      "Epoch 00070: val_loss improved from 1.08516 to 1.08489, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0821 - acc: 0.8889 - val_loss: 1.0849 - val_acc: 0.6667\n",
      "Epoch 71/400\n",
      "Epoch 00071: val_loss improved from 1.08489 to 1.08462, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0817 - acc: 0.8889 - val_loss: 1.0846 - val_acc: 0.6667\n",
      "Epoch 72/400\n",
      "Epoch 00072: val_loss improved from 1.08462 to 1.08434, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0814 - acc: 0.8889 - val_loss: 1.0843 - val_acc: 0.6667\n",
      "Epoch 73/400\n",
      "Epoch 00073: val_loss improved from 1.08434 to 1.08405, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0810 - acc: 0.8889 - val_loss: 1.0841 - val_acc: 0.6667\n",
      "Epoch 74/400\n",
      "Epoch 00074: val_loss improved from 1.08405 to 1.08376, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0807 - acc: 0.8889 - val_loss: 1.0838 - val_acc: 0.6667\n",
      "Epoch 75/400\n",
      "Epoch 00075: val_loss improved from 1.08376 to 1.08346, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0803 - acc: 0.8889 - val_loss: 1.0835 - val_acc: 0.6667\n",
      "Epoch 76/400\n",
      "Epoch 00076: val_loss improved from 1.08346 to 1.08316, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0799 - acc: 0.8889 - val_loss: 1.0832 - val_acc: 0.6667\n",
      "Epoch 77/400\n",
      "Epoch 00077: val_loss improved from 1.08316 to 1.08284, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0795 - acc: 0.8889 - val_loss: 1.0828 - val_acc: 0.6667\n",
      "Epoch 78/400\n",
      "Epoch 00078: val_loss improved from 1.08284 to 1.08252, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0791 - acc: 0.8889 - val_loss: 1.0825 - val_acc: 0.6667\n",
      "Epoch 79/400\n",
      "Epoch 00079: val_loss improved from 1.08252 to 1.08219, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0787 - acc: 0.8889 - val_loss: 1.0822 - val_acc: 0.6667\n",
      "Epoch 80/400\n",
      "Epoch 00080: val_loss improved from 1.08219 to 1.08186, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0783 - acc: 0.8889 - val_loss: 1.0819 - val_acc: 0.6667\n",
      "Epoch 81/400\n",
      "Epoch 00081: val_loss improved from 1.08186 to 1.08152, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0779 - acc: 0.8889 - val_loss: 1.0815 - val_acc: 0.6667\n",
      "Epoch 82/400\n",
      "Epoch 00082: val_loss improved from 1.08152 to 1.08116, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0775 - acc: 0.8889 - val_loss: 1.0812 - val_acc: 0.6667\n",
      "Epoch 83/400\n",
      "Epoch 00083: val_loss improved from 1.08116 to 1.08080, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0771 - acc: 1.0000 - val_loss: 1.0808 - val_acc: 0.6667\n",
      "Epoch 84/400\n",
      "Epoch 00084: val_loss improved from 1.08080 to 1.08043, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0766 - acc: 1.0000 - val_loss: 1.0804 - val_acc: 0.6667\n",
      "Epoch 85/400\n",
      "Epoch 00085: val_loss improved from 1.08043 to 1.08006, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0761 - acc: 1.0000 - val_loss: 1.0801 - val_acc: 0.6667\n",
      "Epoch 86/400\n",
      "Epoch 00086: val_loss improved from 1.08006 to 1.07967, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0757 - acc: 1.0000 - val_loss: 1.0797 - val_acc: 0.6667\n",
      "Epoch 87/400\n",
      "Epoch 00087: val_loss improved from 1.07967 to 1.07927, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0752 - acc: 1.0000 - val_loss: 1.0793 - val_acc: 0.6667\n",
      "Epoch 88/400\n",
      "Epoch 00088: val_loss improved from 1.07927 to 1.07887, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0747 - acc: 1.0000 - val_loss: 1.0789 - val_acc: 0.6667\n",
      "Epoch 89/400\n",
      "Epoch 00089: val_loss improved from 1.07887 to 1.07845, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0742 - acc: 0.8889 - val_loss: 1.0784 - val_acc: 0.6667\n",
      "Epoch 90/400\n",
      "Epoch 00090: val_loss improved from 1.07845 to 1.07801, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0737 - acc: 0.8889 - val_loss: 1.0780 - val_acc: 0.6667\n",
      "Epoch 91/400\n",
      "Epoch 00091: val_loss improved from 1.07801 to 1.07757, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0732 - acc: 0.8889 - val_loss: 1.0776 - val_acc: 0.6667\n",
      "Epoch 92/400\n",
      "Epoch 00092: val_loss improved from 1.07757 to 1.07711, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0726 - acc: 0.8889 - val_loss: 1.0771 - val_acc: 0.6667\n",
      "Epoch 93/400\n",
      "Epoch 00093: val_loss improved from 1.07711 to 1.07663, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0721 - acc: 0.8889 - val_loss: 1.0766 - val_acc: 0.6667\n",
      "Epoch 94/400\n",
      "Epoch 00094: val_loss improved from 1.07663 to 1.07613, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0715 - acc: 0.8889 - val_loss: 1.0761 - val_acc: 0.6667\n",
      "Epoch 95/400\n",
      "Epoch 00095: val_loss improved from 1.07613 to 1.07561, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0709 - acc: 0.8889 - val_loss: 1.0756 - val_acc: 0.6667\n",
      "Epoch 96/400\n",
      "Epoch 00096: val_loss improved from 1.07561 to 1.07507, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0703 - acc: 1.0000 - val_loss: 1.0751 - val_acc: 0.6667\n",
      "Epoch 97/400\n",
      "Epoch 00097: val_loss improved from 1.07507 to 1.07450, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0696 - acc: 1.0000 - val_loss: 1.0745 - val_acc: 0.6667\n",
      "Epoch 98/400\n",
      "Epoch 00098: val_loss improved from 1.07450 to 1.07389, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0690 - acc: 1.0000 - val_loss: 1.0739 - val_acc: 0.6667\n",
      "Epoch 99/400\n",
      "Epoch 00099: val_loss improved from 1.07389 to 1.07325, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0682 - acc: 1.0000 - val_loss: 1.0733 - val_acc: 0.6667\n",
      "Epoch 100/400\n",
      "Epoch 00100: val_loss improved from 1.07325 to 1.07257, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0675 - acc: 1.0000 - val_loss: 1.0726 - val_acc: 0.6667\n",
      "Epoch 101/400\n",
      "Epoch 00101: val_loss improved from 1.07257 to 1.07183, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0667 - acc: 1.0000 - val_loss: 1.0718 - val_acc: 0.6667\n",
      "Epoch 102/400\n",
      "Epoch 00102: val_loss improved from 1.07183 to 1.07103, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0658 - acc: 1.0000 - val_loss: 1.0710 - val_acc: 0.6667\n",
      "Epoch 103/400\n",
      "Epoch 00103: val_loss improved from 1.07103 to 1.07020, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0649 - acc: 1.0000 - val_loss: 1.0702 - val_acc: 0.8333\n",
      "Epoch 104/400\n",
      "Epoch 00104: val_loss improved from 1.07020 to 1.06920, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0640 - acc: 1.0000 - val_loss: 1.0692 - val_acc: 0.6667\n",
      "Epoch 105/400\n",
      "Epoch 00105: val_loss improved from 1.06920 to 1.06876, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0630 - acc: 0.8889 - val_loss: 1.0688 - val_acc: 0.8333\n",
      "Epoch 106/400\n",
      "Epoch 00106: val_loss improved from 1.06876 to 1.06754, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0621 - acc: 1.0000 - val_loss: 1.0675 - val_acc: 0.5000\n",
      "Epoch 107/400\n",
      "Epoch 00107: val_loss improved from 1.06754 to 1.06672, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0613 - acc: 0.6667 - val_loss: 1.0667 - val_acc: 0.8333\n",
      "Epoch 108/400\n",
      "Epoch 00108: val_loss improved from 1.06672 to 1.06513, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0599 - acc: 0.8889 - val_loss: 1.0651 - val_acc: 0.6667\n",
      "Epoch 109/400\n",
      "Epoch 00109: val_loss improved from 1.06513 to 1.06422, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0586 - acc: 0.8889 - val_loss: 1.0642 - val_acc: 0.8333\n",
      "Epoch 110/400\n",
      "Epoch 00110: val_loss improved from 1.06422 to 1.06244, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0572 - acc: 0.8889 - val_loss: 1.0624 - val_acc: 0.6667\n",
      "Epoch 111/400\n",
      "Epoch 00111: val_loss improved from 1.06244 to 1.06167, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0559 - acc: 0.8889 - val_loss: 1.0617 - val_acc: 0.8333\n",
      "Epoch 112/400\n",
      "Epoch 00112: val_loss improved from 1.06167 to 1.05978, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0544 - acc: 0.7778 - val_loss: 1.0598 - val_acc: 0.5000\n",
      "Epoch 113/400\n",
      "Epoch 00113: val_loss improved from 1.05978 to 1.05857, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0533 - acc: 0.8889 - val_loss: 1.0586 - val_acc: 0.8333\n",
      "Epoch 114/400\n",
      "Epoch 00114: val_loss improved from 1.05857 to 1.05640, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0512 - acc: 0.7778 - val_loss: 1.0564 - val_acc: 0.5000\n",
      "Epoch 115/400\n",
      "Epoch 00115: val_loss improved from 1.05640 to 1.05455, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0500 - acc: 0.8889 - val_loss: 1.0545 - val_acc: 0.8333\n",
      "Epoch 116/400\n",
      "Epoch 00116: val_loss improved from 1.05455 to 1.05264, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0474 - acc: 0.7778 - val_loss: 1.0526 - val_acc: 0.5000\n",
      "Epoch 117/400\n",
      "Epoch 00117: val_loss improved from 1.05264 to 1.05015, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0464 - acc: 0.7778 - val_loss: 1.0502 - val_acc: 0.8333\n",
      "Epoch 118/400\n",
      "Epoch 00118: val_loss improved from 1.05015 to 1.04925, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0434 - acc: 0.7778 - val_loss: 1.0493 - val_acc: 0.5000\n",
      "Epoch 119/400\n",
      "Epoch 00119: val_loss improved from 1.04925 to 1.04451, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0431 - acc: 0.7778 - val_loss: 1.0445 - val_acc: 0.8333\n",
      "Epoch 120/400\n",
      "Epoch 00120: val_loss improved from 1.04451 to 1.04441, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0387 - acc: 0.7778 - val_loss: 1.0444 - val_acc: 0.5000\n",
      "Epoch 121/400\n",
      "Epoch 00121: val_loss improved from 1.04441 to 1.03887, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0386 - acc: 0.7778 - val_loss: 1.0389 - val_acc: 0.8333\n",
      "Epoch 122/400\n",
      "Epoch 00122: val_loss did not improve\n",
      " - 3s - loss: 1.0342 - acc: 0.7778 - val_loss: 1.0410 - val_acc: 0.5000\n",
      "Epoch 123/400\n",
      "Epoch 00123: val_loss improved from 1.03887 to 1.03183, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0350 - acc: 0.7778 - val_loss: 1.0318 - val_acc: 0.8333\n",
      "Epoch 124/400\n",
      "Epoch 00124: val_loss did not improve\n",
      " - 3s - loss: 1.0292 - acc: 0.7778 - val_loss: 1.0334 - val_acc: 0.5000\n",
      "Epoch 125/400\n",
      "Epoch 00125: val_loss improved from 1.03183 to 1.02469, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0284 - acc: 0.7778 - val_loss: 1.0247 - val_acc: 0.8333\n",
      "Epoch 126/400\n",
      "Epoch 00126: val_loss did not improve\n",
      " - 3s - loss: 1.0243 - acc: 0.7778 - val_loss: 1.0266 - val_acc: 0.6667\n",
      "Epoch 127/400\n",
      "Epoch 00127: val_loss improved from 1.02469 to 1.01716, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0226 - acc: 0.6667 - val_loss: 1.0172 - val_acc: 0.8333\n",
      "Epoch 128/400\n",
      "Epoch 00128: val_loss improved from 1.01716 to 1.01596, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0196 - acc: 0.7778 - val_loss: 1.0160 - val_acc: 0.8333\n",
      "Epoch 129/400\n",
      "Epoch 00129: val_loss improved from 1.01596 to 1.00503, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0153 - acc: 0.6667 - val_loss: 1.0050 - val_acc: 0.8333\n",
      "Epoch 130/400\n",
      "Epoch 00130: val_loss improved from 1.00503 to 0.99801, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0136 - acc: 0.7778 - val_loss: 0.9980 - val_acc: 0.8333\n",
      "Epoch 131/400\n",
      "Epoch 00131: val_loss improved from 0.99801 to 0.99630, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0076 - acc: 0.8889 - val_loss: 0.9963 - val_acc: 0.8333\n",
      "Epoch 132/400\n",
      "Epoch 00132: val_loss improved from 0.99630 to 0.98890, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0047 - acc: 0.7778 - val_loss: 0.9889 - val_acc: 0.8333\n",
      "Epoch 133/400\n",
      "Epoch 00133: val_loss did not improve\n",
      " - 3s - loss: 1.0026 - acc: 1.0000 - val_loss: 1.0280 - val_acc: 0.5000\n",
      "Epoch 134/400\n",
      "Epoch 00134: val_loss did not improve\n",
      " - 3s - loss: 1.0157 - acc: 0.6667 - val_loss: 1.0538 - val_acc: 0.6667\n",
      "Epoch 135/400\n",
      "Epoch 00135: val_loss improved from 0.98890 to 0.98230, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0398 - acc: 0.7778 - val_loss: 0.9823 - val_acc: 0.8333\n",
      "Epoch 136/400\n",
      "Epoch 00136: val_loss did not improve\n",
      " - 3s - loss: 1.0002 - acc: 0.7778 - val_loss: 1.0052 - val_acc: 0.6667\n",
      "Epoch 137/400\n",
      "Epoch 00137: val_loss did not improve\n",
      " - 3s - loss: 1.0018 - acc: 0.6667 - val_loss: 0.9885 - val_acc: 0.8333\n",
      "Epoch 138/400\n",
      "Epoch 00138: val_loss improved from 0.98230 to 0.97592, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 1.0028 - acc: 0.7778 - val_loss: 0.9759 - val_acc: 0.8333\n",
      "Epoch 139/400\n",
      "Epoch 00139: val_loss did not improve\n",
      " - 3s - loss: 0.9977 - acc: 0.7778 - val_loss: 0.9802 - val_acc: 0.8333\n",
      "Epoch 140/400\n",
      "Epoch 00140: val_loss did not improve\n",
      " - 3s - loss: 0.9909 - acc: 0.6667 - val_loss: 0.9765 - val_acc: 0.8333\n",
      "Epoch 141/400\n",
      "Epoch 00141: val_loss improved from 0.97592 to 0.97022, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9978 - acc: 0.7778 - val_loss: 0.9702 - val_acc: 0.8333\n",
      "Epoch 142/400\n",
      "Epoch 00142: val_loss did not improve\n",
      " - 3s - loss: 0.9941 - acc: 0.7778 - val_loss: 0.9758 - val_acc: 0.8333\n",
      "Epoch 143/400\n",
      "Epoch 00143: val_loss did not improve\n",
      " - 3s - loss: 0.9875 - acc: 0.6667 - val_loss: 0.9812 - val_acc: 0.8333\n",
      "Epoch 144/400\n",
      "Epoch 00144: val_loss improved from 0.97022 to 0.96468, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9967 - acc: 0.7778 - val_loss: 0.9647 - val_acc: 0.8333\n",
      "Epoch 145/400\n",
      "Epoch 00145: val_loss did not improve\n",
      " - 3s - loss: 0.9811 - acc: 0.8889 - val_loss: 1.0657 - val_acc: 0.3333\n",
      "Epoch 146/400\n",
      "Epoch 00146: val_loss did not improve\n",
      " - 3s - loss: 1.0495 - acc: 0.3333 - val_loss: 0.9683 - val_acc: 0.8333\n",
      "Epoch 147/400\n",
      "Epoch 00147: val_loss improved from 0.96468 to 0.96319, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9924 - acc: 0.7778 - val_loss: 0.9632 - val_acc: 0.8333\n",
      "Epoch 148/400\n",
      "Epoch 00148: val_loss did not improve\n",
      " - 3s - loss: 0.9882 - acc: 0.7778 - val_loss: 0.9696 - val_acc: 0.8333\n",
      "Epoch 149/400\n",
      "Epoch 00149: val_loss did not improve\n",
      " - 3s - loss: 0.9808 - acc: 0.6667 - val_loss: 0.9647 - val_acc: 0.8333\n",
      "Epoch 150/400\n",
      "Epoch 00150: val_loss improved from 0.96319 to 0.95887, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9897 - acc: 0.7778 - val_loss: 0.9589 - val_acc: 0.8333\n",
      "Epoch 151/400\n",
      "Epoch 00151: val_loss improved from 0.95887 to 0.95737, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9861 - acc: 0.7778 - val_loss: 0.9574 - val_acc: 0.8333\n",
      "Epoch 152/400\n",
      "Epoch 00152: val_loss improved from 0.95737 to 0.95705, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9700 - acc: 0.7778 - val_loss: 0.9571 - val_acc: 0.8333\n",
      "Epoch 153/400\n",
      "Epoch 00153: val_loss improved from 0.95705 to 0.95252, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9856 - acc: 0.7778 - val_loss: 0.9525 - val_acc: 0.8333\n",
      "Epoch 154/400\n",
      "Epoch 00154: val_loss did not improve\n",
      " - 3s - loss: 0.9814 - acc: 0.7778 - val_loss: 0.9649 - val_acc: 0.8333\n",
      "Epoch 155/400\n",
      "Epoch 00155: val_loss did not improve\n",
      " - 3s - loss: 0.9775 - acc: 0.6667 - val_loss: 0.9582 - val_acc: 0.8333\n",
      "Epoch 156/400\n",
      "Epoch 00156: val_loss improved from 0.95252 to 0.94921, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9842 - acc: 0.7778 - val_loss: 0.9492 - val_acc: 0.8333\n",
      "Epoch 157/400\n",
      "Epoch 00157: val_loss improved from 0.94921 to 0.94710, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9800 - acc: 0.7778 - val_loss: 0.9471 - val_acc: 0.8333\n",
      "Epoch 158/400\n",
      "Epoch 00158: val_loss improved from 0.94710 to 0.94521, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9594 - acc: 0.7778 - val_loss: 0.9452 - val_acc: 0.8333\n",
      "Epoch 159/400\n",
      "Epoch 00159: val_loss improved from 0.94521 to 0.94275, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9559 - acc: 1.0000 - val_loss: 0.9428 - val_acc: 0.8333\n",
      "Epoch 160/400\n",
      "Epoch 00160: val_loss did not improve\n",
      " - 3s - loss: 0.9549 - acc: 1.0000 - val_loss: 1.0783 - val_acc: 0.3333\n",
      "Epoch 161/400\n",
      "Epoch 00161: val_loss did not improve\n",
      " - 3s - loss: 1.0672 - acc: 0.3333 - val_loss: 0.9959 - val_acc: 0.5000\n",
      "Epoch 162/400\n",
      "Epoch 00162: val_loss did not improve\n",
      " - 3s - loss: 0.9800 - acc: 0.6667 - val_loss: 0.9677 - val_acc: 0.8333\n",
      "Epoch 163/400\n",
      "Epoch 00163: val_loss improved from 0.94275 to 0.94100, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9824 - acc: 0.7778 - val_loss: 0.9410 - val_acc: 0.8333\n",
      "Epoch 164/400\n",
      "Epoch 00164: val_loss did not improve\n",
      " - 3s - loss: 0.9663 - acc: 0.7778 - val_loss: 1.0596 - val_acc: 0.3333\n",
      "Epoch 165/400\n",
      "Epoch 00165: val_loss did not improve\n",
      " - 3s - loss: 1.0386 - acc: 0.3333 - val_loss: 0.9459 - val_acc: 0.8333\n",
      "Epoch 166/400\n",
      "Epoch 00166: val_loss improved from 0.94100 to 0.93947, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9756 - acc: 0.7778 - val_loss: 0.9395 - val_acc: 0.8333\n",
      "Epoch 167/400\n",
      "Epoch 00167: val_loss did not improve\n",
      " - 3s - loss: 0.9611 - acc: 0.7778 - val_loss: 1.0449 - val_acc: 0.3333\n",
      "Epoch 168/400\n",
      "Epoch 00168: val_loss did not improve\n",
      " - 3s - loss: 1.0182 - acc: 0.4444 - val_loss: 0.9442 - val_acc: 0.8333\n",
      "Epoch 169/400\n",
      "Epoch 00169: val_loss improved from 0.93947 to 0.93765, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9740 - acc: 0.7778 - val_loss: 0.9376 - val_acc: 0.8333\n",
      "Epoch 170/400\n",
      "Epoch 00170: val_loss did not improve\n",
      " - 3s - loss: 0.9649 - acc: 0.7778 - val_loss: 0.9634 - val_acc: 0.8333\n",
      "Epoch 171/400\n",
      "Epoch 00171: val_loss improved from 0.93765 to 0.93437, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9641 - acc: 0.6667 - val_loss: 0.9344 - val_acc: 0.8333\n",
      "Epoch 172/400\n",
      "Epoch 00172: val_loss did not improve\n",
      " - 3s - loss: 0.9518 - acc: 0.8889 - val_loss: 1.0388 - val_acc: 0.3333\n",
      "Epoch 173/400\n",
      "Epoch 00173: val_loss did not improve\n",
      " - 3s - loss: 1.0095 - acc: 0.4444 - val_loss: 0.9369 - val_acc: 0.8333\n",
      "Epoch 174/400\n",
      "Epoch 00174: val_loss improved from 0.93437 to 0.93109, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9680 - acc: 0.7778 - val_loss: 0.9311 - val_acc: 0.8333\n",
      "Epoch 175/400\n",
      "Epoch 00175: val_loss did not improve\n",
      " - 3s - loss: 0.9419 - acc: 0.8889 - val_loss: 0.9915 - val_acc: 0.5000\n",
      "Epoch 176/400\n",
      "Epoch 00176: val_loss improved from 0.93109 to 0.92802, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9715 - acc: 0.6667 - val_loss: 0.9280 - val_acc: 0.6667\n",
      "Epoch 177/400\n",
      "Epoch 00177: val_loss did not improve\n",
      " - 3s - loss: 0.9443 - acc: 0.8889 - val_loss: 1.0349 - val_acc: 0.5000\n",
      "Epoch 178/400\n",
      "Epoch 00178: val_loss did not improve\n",
      " - 3s - loss: 1.0024 - acc: 0.5556 - val_loss: 0.9296 - val_acc: 0.6667\n",
      "Epoch 179/400\n",
      "Epoch 00179: val_loss improved from 0.92802 to 0.92697, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9605 - acc: 0.7778 - val_loss: 0.9270 - val_acc: 0.6667\n",
      "Epoch 180/400\n",
      "Epoch 00180: val_loss improved from 0.92697 to 0.92599, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9367 - acc: 0.7778 - val_loss: 0.9260 - val_acc: 0.6667\n",
      "Epoch 181/400\n",
      "Epoch 00181: val_loss improved from 0.92599 to 0.92176, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9595 - acc: 0.7778 - val_loss: 0.9218 - val_acc: 0.6667\n",
      "Epoch 182/400\n",
      "Epoch 00182: val_loss improved from 0.92176 to 0.92024, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9279 - acc: 0.8889 - val_loss: 0.9202 - val_acc: 0.8333\n",
      "Epoch 183/400\n",
      "Epoch 00183: val_loss did not improve\n",
      " - 3s - loss: 0.9540 - acc: 0.7778 - val_loss: 0.9261 - val_acc: 0.8333\n",
      "Epoch 184/400\n",
      "Epoch 00184: val_loss improved from 0.92024 to 0.91980, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9429 - acc: 0.6667 - val_loss: 0.9198 - val_acc: 0.8333\n",
      "Epoch 185/400\n",
      "Epoch 00185: val_loss improved from 0.91980 to 0.91872, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9541 - acc: 0.7778 - val_loss: 0.9187 - val_acc: 0.8333\n",
      "Epoch 186/400\n",
      "Epoch 00186: val_loss did not improve\n",
      " - 3s - loss: 0.9320 - acc: 0.7778 - val_loss: 0.9223 - val_acc: 0.8333\n",
      "Epoch 187/400\n",
      "Epoch 00187: val_loss improved from 0.91872 to 0.91417, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9584 - acc: 0.7778 - val_loss: 0.9142 - val_acc: 0.8333\n",
      "Epoch 188/400\n",
      "Epoch 00188: val_loss did not improve\n",
      " - 3s - loss: 0.9486 - acc: 0.7778 - val_loss: 0.9334 - val_acc: 0.8333\n",
      "Epoch 189/400\n",
      "Epoch 00189: val_loss improved from 0.91417 to 0.91300, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9446 - acc: 0.6667 - val_loss: 0.9130 - val_acc: 0.8333\n",
      "Epoch 190/400\n",
      "Epoch 00190: val_loss did not improve\n",
      " - 3s - loss: 0.9389 - acc: 0.7778 - val_loss: 1.0306 - val_acc: 0.3333\n",
      "Epoch 191/400\n",
      "Epoch 00191: val_loss did not improve\n",
      " - 3s - loss: 0.9944 - acc: 0.5556 - val_loss: 0.9224 - val_acc: 0.8333\n",
      "Epoch 192/400\n",
      "Epoch 00192: val_loss improved from 0.91300 to 0.91189, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9560 - acc: 0.7778 - val_loss: 0.9119 - val_acc: 0.6667\n",
      "Epoch 193/400\n",
      "Epoch 00193: val_loss did not improve\n",
      " - 3s - loss: 0.9453 - acc: 0.7778 - val_loss: 0.9161 - val_acc: 0.8333\n",
      "Epoch 194/400\n",
      "Epoch 00194: val_loss improved from 0.91189 to 0.91057, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9307 - acc: 0.7778 - val_loss: 0.9106 - val_acc: 0.8333\n",
      "Epoch 195/400\n",
      "Epoch 00195: val_loss did not improve\n",
      " - 3s - loss: 0.9435 - acc: 0.7778 - val_loss: 0.9170 - val_acc: 0.8333\n",
      "Epoch 196/400\n",
      "Epoch 00196: val_loss improved from 0.91057 to 0.90862, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9304 - acc: 0.6667 - val_loss: 0.9086 - val_acc: 0.8333\n",
      "Epoch 197/400\n",
      "Epoch 00197: val_loss did not improve\n",
      " - 3s - loss: 0.9387 - acc: 0.7778 - val_loss: 0.9487 - val_acc: 0.6667\n",
      "Epoch 198/400\n",
      "Epoch 00198: val_loss improved from 0.90862 to 0.90436, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9426 - acc: 0.6667 - val_loss: 0.9044 - val_acc: 0.6667\n",
      "Epoch 199/400\n",
      "Epoch 00199: val_loss did not improve\n",
      " - 3s - loss: 0.9105 - acc: 0.8889 - val_loss: 0.9670 - val_acc: 0.6667\n",
      "Epoch 200/400\n",
      "Epoch 00200: val_loss improved from 0.90436 to 0.90081, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9478 - acc: 0.6667 - val_loss: 0.9008 - val_acc: 0.6667\n",
      "Epoch 201/400\n",
      "Epoch 00201: val_loss did not improve\n",
      " - 3s - loss: 0.9105 - acc: 0.8889 - val_loss: 1.0179 - val_acc: 0.5000\n",
      "Epoch 202/400\n",
      "Epoch 00202: val_loss did not improve\n",
      " - 3s - loss: 0.9768 - acc: 0.6667 - val_loss: 0.9079 - val_acc: 0.6667\n",
      "Epoch 203/400\n",
      "Epoch 00203: val_loss improved from 0.90081 to 0.89778, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9468 - acc: 0.6667 - val_loss: 0.8978 - val_acc: 0.6667\n",
      "Epoch 204/400\n",
      "Epoch 00204: val_loss did not improve\n",
      " - 3s - loss: 0.9299 - acc: 0.6667 - val_loss: 0.9580 - val_acc: 0.6667\n",
      "Epoch 205/400\n",
      "Epoch 00205: val_loss improved from 0.89778 to 0.89486, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9416 - acc: 0.6667 - val_loss: 0.8949 - val_acc: 0.6667\n",
      "Epoch 206/400\n",
      "Epoch 00206: val_loss improved from 0.89486 to 0.89037, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8947 - acc: 0.7778 - val_loss: 0.8904 - val_acc: 0.6667\n",
      "Epoch 207/400\n",
      "Epoch 00207: val_loss improved from 0.89037 to 0.88744, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8910 - acc: 0.7778 - val_loss: 0.8874 - val_acc: 0.6667\n",
      "Epoch 208/400\n",
      "Epoch 00208: val_loss did not improve\n",
      " - 3s - loss: 0.8960 - acc: 0.7778 - val_loss: 1.0257 - val_acc: 0.5000\n",
      "Epoch 209/400\n",
      "Epoch 00209: val_loss did not improve\n",
      " - 3s - loss: 0.9798 - acc: 0.5556 - val_loss: 0.9029 - val_acc: 0.6667\n",
      "Epoch 210/400\n",
      "Epoch 00210: val_loss did not improve\n",
      " - 3s - loss: 0.9431 - acc: 0.6667 - val_loss: 0.8915 - val_acc: 0.6667\n",
      "Epoch 211/400\n",
      "Epoch 00211: val_loss improved from 0.88744 to 0.88384, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9367 - acc: 0.6667 - val_loss: 0.8838 - val_acc: 0.6667\n",
      "Epoch 212/400\n",
      "Epoch 00212: val_loss did not improve\n",
      " - 3s - loss: 0.8913 - acc: 0.7778 - val_loss: 0.9662 - val_acc: 0.6667\n",
      "Epoch 213/400\n",
      "Epoch 00213: val_loss improved from 0.88384 to 0.88231, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9410 - acc: 0.6667 - val_loss: 0.8823 - val_acc: 0.6667\n",
      "Epoch 214/400\n",
      "Epoch 00214: val_loss improved from 0.88231 to 0.87925, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8821 - acc: 0.7778 - val_loss: 0.8792 - val_acc: 0.6667\n",
      "Epoch 215/400\n",
      "Epoch 00215: val_loss did not improve\n",
      " - 3s - loss: 0.8857 - acc: 0.7778 - val_loss: 0.8878 - val_acc: 0.6667\n",
      "Epoch 216/400\n",
      "Epoch 00216: val_loss improved from 0.87925 to 0.87902, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9369 - acc: 0.6667 - val_loss: 0.8790 - val_acc: 0.6667\n",
      "Epoch 217/400\n",
      "Epoch 00217: val_loss improved from 0.87902 to 0.87359, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9310 - acc: 0.6667 - val_loss: 0.8736 - val_acc: 0.6667\n",
      "Epoch 218/400\n",
      "Epoch 00218: val_loss did not improve\n",
      " - 3s - loss: 0.8794 - acc: 0.7778 - val_loss: 0.9900 - val_acc: 0.5000\n",
      "Epoch 219/400\n",
      "Epoch 00219: val_loss did not improve\n",
      " - 3s - loss: 0.9478 - acc: 0.6667 - val_loss: 0.8755 - val_acc: 0.6667\n",
      "Epoch 220/400\n",
      "Epoch 00220: val_loss did not improve\n",
      " - 3s - loss: 0.9203 - acc: 0.6667 - val_loss: 0.8994 - val_acc: 0.8333\n",
      "Epoch 221/400\n",
      "Epoch 00221: val_loss did not improve\n",
      " - 3s - loss: 0.9183 - acc: 0.6667 - val_loss: 0.8741 - val_acc: 0.6667\n",
      "Epoch 222/400\n",
      "Epoch 00222: val_loss did not improve\n",
      " - 3s - loss: 0.8767 - acc: 0.7778 - val_loss: 0.9163 - val_acc: 0.8333\n",
      "Epoch 223/400\n",
      "Epoch 00223: val_loss improved from 0.87359 to 0.87147, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9207 - acc: 0.6667 - val_loss: 0.8715 - val_acc: 0.6667\n",
      "Epoch 224/400\n",
      "Epoch 00224: val_loss improved from 0.87147 to 0.86776, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8686 - acc: 0.7778 - val_loss: 0.8678 - val_acc: 0.6667\n",
      "Epoch 225/400\n",
      "Epoch 00225: val_loss did not improve\n",
      " - 3s - loss: 0.8750 - acc: 0.7778 - val_loss: 0.8994 - val_acc: 0.6667\n",
      "Epoch 226/400\n",
      "Epoch 00226: val_loss did not improve\n",
      " - 3s - loss: 0.9337 - acc: 0.6667 - val_loss: 0.8686 - val_acc: 0.6667\n",
      "Epoch 227/400\n",
      "Epoch 00227: val_loss improved from 0.86776 to 0.86185, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9248 - acc: 0.6667 - val_loss: 0.8618 - val_acc: 0.6667\n",
      "Epoch 228/400\n",
      "Epoch 00228: val_loss did not improve\n",
      " - 3s - loss: 0.8741 - acc: 0.7778 - val_loss: 1.0915 - val_acc: 0.3333\n",
      "Epoch 229/400\n",
      "Epoch 00229: val_loss did not improve\n",
      " - 3s - loss: 1.0662 - acc: 0.3333 - val_loss: 0.8635 - val_acc: 0.6667\n",
      "Epoch 230/400\n",
      "Epoch 00230: val_loss improved from 0.86185 to 0.86069, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8608 - acc: 0.7778 - val_loss: 0.8607 - val_acc: 0.6667\n",
      "Epoch 231/400\n",
      "Epoch 00231: val_loss did not improve\n",
      " - 3s - loss: 0.8607 - acc: 0.7778 - val_loss: 0.8634 - val_acc: 0.6667\n",
      "Epoch 232/400\n",
      "Epoch 00232: val_loss improved from 0.86069 to 0.85884, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9163 - acc: 0.6667 - val_loss: 0.8588 - val_acc: 0.6667\n",
      "Epoch 233/400\n",
      "Epoch 00233: val_loss did not improve\n",
      " - 3s - loss: 0.8752 - acc: 0.7778 - val_loss: 0.8816 - val_acc: 0.6667\n",
      "Epoch 234/400\n",
      "Epoch 00234: val_loss did not improve\n",
      " - 3s - loss: 0.9260 - acc: 0.6667 - val_loss: 0.8628 - val_acc: 0.6667\n",
      "Epoch 235/400\n",
      "Epoch 00235: val_loss improved from 0.85884 to 0.85424, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9197 - acc: 0.6667 - val_loss: 0.8542 - val_acc: 0.6667\n",
      "Epoch 236/400\n",
      "Epoch 00236: val_loss did not improve\n",
      " - 3s - loss: 0.8693 - acc: 0.7778 - val_loss: 1.0948 - val_acc: 0.3333\n",
      "Epoch 237/400\n",
      "Epoch 00237: val_loss did not improve\n",
      " - 3s - loss: 1.0717 - acc: 0.3333 - val_loss: 0.8576 - val_acc: 0.6667\n",
      "Epoch 238/400\n",
      "Epoch 00238: val_loss did not improve\n",
      " - 3s - loss: 0.8700 - acc: 0.7778 - val_loss: 0.8667 - val_acc: 0.6667\n",
      "Epoch 239/400\n",
      "Epoch 00239: val_loss improved from 0.85424 to 0.85346, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9163 - acc: 0.6667 - val_loss: 0.8535 - val_acc: 0.6667\n",
      "Epoch 240/400\n",
      "Epoch 00240: val_loss improved from 0.85346 to 0.85060, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8501 - acc: 0.7778 - val_loss: 0.8506 - val_acc: 0.6667\n",
      "Epoch 241/400\n",
      "Epoch 00241: val_loss did not improve\n",
      " - 3s - loss: 0.8500 - acc: 0.7778 - val_loss: 0.8542 - val_acc: 0.6667\n",
      "Epoch 242/400\n",
      "Epoch 00242: val_loss did not improve\n",
      " - 3s - loss: 0.9067 - acc: 0.6667 - val_loss: 0.8592 - val_acc: 0.6667\n",
      "Epoch 243/400\n",
      "Epoch 00243: val_loss did not improve\n",
      " - 3s - loss: 0.8873 - acc: 0.7778 - val_loss: 0.8620 - val_acc: 0.6667\n",
      "Epoch 244/400\n",
      "Epoch 00244: val_loss improved from 0.85060 to 0.84708, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9140 - acc: 0.6667 - val_loss: 0.8471 - val_acc: 0.6667\n",
      "Epoch 245/400\n",
      "Epoch 00245: val_loss did not improve\n",
      " - 3s - loss: 0.8464 - acc: 0.7778 - val_loss: 0.8585 - val_acc: 0.6667\n",
      "Epoch 246/400\n",
      "Epoch 00246: val_loss did not improve\n",
      " - 3s - loss: 0.8875 - acc: 0.6667 - val_loss: 0.8605 - val_acc: 0.6667\n",
      "Epoch 247/400\n",
      "Epoch 00247: val_loss improved from 0.84708 to 0.84405, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9128 - acc: 0.6667 - val_loss: 0.8441 - val_acc: 0.6667\n",
      "Epoch 248/400\n",
      "Epoch 00248: val_loss did not improve\n",
      " - 3s - loss: 0.8467 - acc: 0.7778 - val_loss: 0.9434 - val_acc: 0.6667\n",
      "Epoch 249/400\n",
      "Epoch 00249: val_loss improved from 0.84405 to 0.84302, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9169 - acc: 0.6667 - val_loss: 0.8430 - val_acc: 0.6667\n",
      "Epoch 250/400\n",
      "Epoch 00250: val_loss did not improve\n",
      " - 3s - loss: 0.8513 - acc: 0.7778 - val_loss: 1.0487 - val_acc: 0.3333\n",
      "Epoch 251/400\n",
      "Epoch 00251: val_loss did not improve\n",
      " - 3s - loss: 0.9882 - acc: 0.5556 - val_loss: 0.9043 - val_acc: 0.6667\n",
      "Epoch 252/400\n",
      "Epoch 00252: val_loss did not improve\n",
      " - 3s - loss: 0.9194 - acc: 0.6667 - val_loss: 0.8548 - val_acc: 0.6667\n",
      "Epoch 253/400\n",
      "Epoch 00253: val_loss improved from 0.84302 to 0.84223, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9118 - acc: 0.6667 - val_loss: 0.8422 - val_acc: 0.6667\n",
      "Epoch 254/400\n",
      "Epoch 00254: val_loss improved from 0.84223 to 0.83612, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8986 - acc: 0.6667 - val_loss: 0.8361 - val_acc: 0.6667\n",
      "Epoch 255/400\n",
      "Epoch 00255: val_loss did not improve\n",
      " - 3s - loss: 0.8509 - acc: 0.6667 - val_loss: 0.8456 - val_acc: 0.6667\n",
      "Epoch 256/400\n",
      "Epoch 00256: val_loss improved from 0.83612 to 0.83409, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.9050 - acc: 0.6667 - val_loss: 0.8341 - val_acc: 0.6667\n",
      "Epoch 257/400\n",
      "Epoch 00257: val_loss did not improve\n",
      " - 3s - loss: 0.8384 - acc: 0.7778 - val_loss: 0.8799 - val_acc: 0.8333\n",
      "Epoch 258/400\n",
      "Epoch 00258: val_loss improved from 0.83409 to 0.83201, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8968 - acc: 0.6667 - val_loss: 0.8320 - val_acc: 0.6667\n",
      "Epoch 259/400\n",
      "Epoch 00259: val_loss improved from 0.83201 to 0.82890, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8262 - acc: 0.7778 - val_loss: 0.8289 - val_acc: 0.6667\n",
      "Epoch 260/400\n",
      "Epoch 00260: val_loss did not improve\n",
      " - 3s - loss: 0.8280 - acc: 0.7778 - val_loss: 0.8360 - val_acc: 0.6667\n",
      "Epoch 261/400\n",
      "Epoch 00261: val_loss improved from 0.82890 to 0.82553, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8991 - acc: 0.6667 - val_loss: 0.8255 - val_acc: 0.6667\n",
      "Epoch 262/400\n",
      "Epoch 00262: val_loss improved from 0.82553 to 0.82321, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8197 - acc: 0.7778 - val_loss: 0.8232 - val_acc: 0.6667\n",
      "Epoch 263/400\n",
      "Epoch 00263: val_loss improved from 0.82321 to 0.82180, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8178 - acc: 0.7778 - val_loss: 0.8218 - val_acc: 0.6667\n",
      "Epoch 264/400\n",
      "Epoch 00264: val_loss improved from 0.82180 to 0.82125, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8183 - acc: 0.7778 - val_loss: 0.8213 - val_acc: 0.6667\n",
      "Epoch 265/400\n",
      "Epoch 00265: val_loss did not improve\n",
      " - 3s - loss: 0.8484 - acc: 0.7778 - val_loss: 0.8622 - val_acc: 0.6667\n",
      "Epoch 266/400\n",
      "Epoch 00266: val_loss did not improve\n",
      " - 3s - loss: 0.9050 - acc: 0.6667 - val_loss: 0.8273 - val_acc: 0.6667\n",
      "Epoch 267/400\n",
      "Epoch 00267: val_loss improved from 0.82125 to 0.81689, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8970 - acc: 0.6667 - val_loss: 0.8169 - val_acc: 0.6667\n",
      "Epoch 268/400\n",
      "Epoch 00268: val_loss did not improve\n",
      " - 3s - loss: 0.8236 - acc: 0.7778 - val_loss: 1.0972 - val_acc: 0.3333\n",
      "Epoch 269/400\n",
      "Epoch 00269: val_loss did not improve\n",
      " - 3s - loss: 1.0410 - acc: 0.3333 - val_loss: 0.8830 - val_acc: 0.6667\n",
      "Epoch 270/400\n",
      "Epoch 00270: val_loss did not improve\n",
      " - 3s - loss: 0.9045 - acc: 0.6667 - val_loss: 0.8336 - val_acc: 0.6667\n",
      "Epoch 271/400\n",
      "Epoch 00271: val_loss did not improve\n",
      " - 3s - loss: 0.8983 - acc: 0.6667 - val_loss: 0.8205 - val_acc: 0.6667\n",
      "Epoch 272/400\n",
      "Epoch 00272: val_loss improved from 0.81689 to 0.81239, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8885 - acc: 0.6667 - val_loss: 0.8124 - val_acc: 0.6667\n",
      "Epoch 273/400\n",
      "Epoch 00273: val_loss improved from 0.81239 to 0.81058, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8071 - acc: 0.7778 - val_loss: 0.8106 - val_acc: 0.6667\n",
      "Epoch 274/400\n",
      "Epoch 00274: val_loss improved from 0.81058 to 0.80878, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8051 - acc: 0.7778 - val_loss: 0.8088 - val_acc: 0.6667\n",
      "Epoch 275/400\n",
      "Epoch 00275: val_loss improved from 0.80878 to 0.80704, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8031 - acc: 0.7778 - val_loss: 0.8070 - val_acc: 0.6667\n",
      "Epoch 276/400\n",
      "Epoch 00276: val_loss improved from 0.80704 to 0.80526, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8011 - acc: 0.7778 - val_loss: 0.8053 - val_acc: 0.6667\n",
      "Epoch 277/400\n",
      "Epoch 00277: val_loss improved from 0.80526 to 0.80361, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7992 - acc: 0.7778 - val_loss: 0.8036 - val_acc: 0.6667\n",
      "Epoch 278/400\n",
      "Epoch 00278: val_loss improved from 0.80361 to 0.80183, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7973 - acc: 0.7778 - val_loss: 0.8018 - val_acc: 0.6667\n",
      "Epoch 279/400\n",
      "Epoch 00279: val_loss improved from 0.80183 to 0.80033, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7955 - acc: 0.7778 - val_loss: 0.8003 - val_acc: 0.6667\n",
      "Epoch 280/400\n",
      "Epoch 00280: val_loss improved from 0.80033 to 0.79844, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7940 - acc: 0.7778 - val_loss: 0.7984 - val_acc: 0.6667\n",
      "Epoch 281/400\n",
      "Epoch 00281: val_loss did not improve\n",
      " - 3s - loss: 0.7939 - acc: 0.7778 - val_loss: 0.7996 - val_acc: 0.6667\n",
      "Epoch 282/400\n",
      "Epoch 00282: val_loss did not improve\n",
      " - 3s - loss: 0.8562 - acc: 0.6667 - val_loss: 1.1555 - val_acc: 0.3333\n",
      "Epoch 283/400\n",
      "Epoch 00283: val_loss did not improve\n",
      " - 3s - loss: 1.1395 - acc: 0.3333 - val_loss: 1.0717 - val_acc: 0.3333\n",
      "Epoch 284/400\n",
      "Epoch 00284: val_loss did not improve\n",
      " - 3s - loss: 0.9992 - acc: 0.5556 - val_loss: 0.8871 - val_acc: 0.6667\n",
      "Epoch 285/400\n",
      "Epoch 00285: val_loss did not improve\n",
      " - 3s - loss: 0.8972 - acc: 0.6667 - val_loss: 0.8212 - val_acc: 0.6667\n",
      "Epoch 286/400\n",
      "Epoch 00286: val_loss did not improve\n",
      " - 4s - loss: 0.8902 - acc: 0.6667 - val_loss: 0.8055 - val_acc: 0.6667\n",
      "Epoch 287/400\n",
      "Epoch 00287: val_loss improved from 0.79844 to 0.79616, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8784 - acc: 0.6667 - val_loss: 0.7962 - val_acc: 0.6667\n",
      "Epoch 288/400\n",
      "Epoch 00288: val_loss improved from 0.79616 to 0.79507, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7906 - acc: 0.7778 - val_loss: 0.7951 - val_acc: 0.6667\n",
      "Epoch 289/400\n",
      "Epoch 00289: val_loss improved from 0.79507 to 0.79256, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7898 - acc: 0.7778 - val_loss: 0.7926 - val_acc: 0.6667\n",
      "Epoch 290/400\n",
      "Epoch 00290: val_loss did not improve\n",
      " - 3s - loss: 0.7884 - acc: 0.7778 - val_loss: 0.7927 - val_acc: 0.6667\n",
      "Epoch 291/400\n",
      "Epoch 00291: val_loss did not improve\n",
      " - 3s - loss: 0.8013 - acc: 0.7778 - val_loss: 1.0386 - val_acc: 0.3333\n",
      "Epoch 292/400\n",
      "Epoch 00292: val_loss did not improve\n",
      " - 3s - loss: 0.9659 - acc: 0.5556 - val_loss: 0.8615 - val_acc: 0.6667\n",
      "Epoch 293/400\n",
      "Epoch 00293: val_loss did not improve\n",
      " - 3s - loss: 0.8910 - acc: 0.6667 - val_loss: 0.8141 - val_acc: 0.6667\n",
      "Epoch 294/400\n",
      "Epoch 00294: val_loss did not improve\n",
      " - 3s - loss: 0.8856 - acc: 0.6667 - val_loss: 0.7988 - val_acc: 0.6667\n",
      "Epoch 295/400\n",
      "Epoch 00295: val_loss improved from 0.79256 to 0.78881, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8777 - acc: 0.6667 - val_loss: 0.7888 - val_acc: 0.6667\n",
      "Epoch 296/400\n",
      "Epoch 00296: val_loss improved from 0.78881 to 0.78724, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7894 - acc: 0.7778 - val_loss: 0.7872 - val_acc: 0.6667\n",
      "Epoch 297/400\n",
      "Epoch 00297: val_loss did not improve\n",
      " - 3s - loss: 0.8218 - acc: 0.6667 - val_loss: 0.7915 - val_acc: 0.6667\n",
      "Epoch 298/400\n",
      "Epoch 00298: val_loss did not improve\n",
      " - 3s - loss: 0.8588 - acc: 0.6667 - val_loss: 0.8432 - val_acc: 0.8333\n",
      "Epoch 299/400\n",
      "Epoch 00299: val_loss improved from 0.78724 to 0.78647, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.8733 - acc: 0.6667 - val_loss: 0.7865 - val_acc: 0.6667\n",
      "Epoch 300/400\n",
      "Epoch 00300: val_loss improved from 0.78647 to 0.78388, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7772 - acc: 0.7778 - val_loss: 0.7839 - val_acc: 0.6667\n",
      "Epoch 301/400\n",
      "Epoch 00301: val_loss improved from 0.78388 to 0.78206, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7751 - acc: 0.7778 - val_loss: 0.7821 - val_acc: 0.6667\n",
      "Epoch 302/400\n",
      "Epoch 00302: val_loss improved from 0.78206 to 0.77981, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7731 - acc: 0.7778 - val_loss: 0.7798 - val_acc: 0.6667\n",
      "Epoch 303/400\n",
      "Epoch 00303: val_loss improved from 0.77981 to 0.77803, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7712 - acc: 0.7778 - val_loss: 0.7780 - val_acc: 0.6667\n",
      "Epoch 304/400\n",
      "Epoch 00304: val_loss improved from 0.77803 to 0.77597, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7692 - acc: 0.7778 - val_loss: 0.7760 - val_acc: 0.6667\n",
      "Epoch 305/400\n",
      "Epoch 00305: val_loss improved from 0.77597 to 0.77423, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7673 - acc: 0.7778 - val_loss: 0.7742 - val_acc: 0.6667\n",
      "Epoch 306/400\n",
      "Epoch 00306: val_loss improved from 0.77423 to 0.77228, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7655 - acc: 0.7778 - val_loss: 0.7723 - val_acc: 0.6667\n",
      "Epoch 307/400\n",
      "Epoch 00307: val_loss improved from 0.77228 to 0.77057, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7636 - acc: 0.7778 - val_loss: 0.7706 - val_acc: 0.6667\n",
      "Epoch 308/400\n",
      "Epoch 00308: val_loss improved from 0.77057 to 0.76869, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7618 - acc: 0.7778 - val_loss: 0.7687 - val_acc: 0.6667\n",
      "Epoch 309/400\n",
      "Epoch 00309: val_loss improved from 0.76869 to 0.76702, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7600 - acc: 0.7778 - val_loss: 0.7670 - val_acc: 0.6667\n",
      "Epoch 310/400\n",
      "Epoch 00310: val_loss improved from 0.76702 to 0.76518, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7582 - acc: 0.7778 - val_loss: 0.7652 - val_acc: 0.6667\n",
      "Epoch 311/400\n",
      "Epoch 00311: val_loss improved from 0.76518 to 0.76355, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7564 - acc: 0.7778 - val_loss: 0.7635 - val_acc: 0.6667\n",
      "Epoch 312/400\n",
      "Epoch 00312: val_loss improved from 0.76355 to 0.76168, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7546 - acc: 0.7778 - val_loss: 0.7617 - val_acc: 0.6667\n",
      "Epoch 313/400\n",
      "Epoch 00313: val_loss improved from 0.76168 to 0.76012, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7528 - acc: 0.7778 - val_loss: 0.7601 - val_acc: 0.6667\n",
      "Epoch 314/400\n",
      "Epoch 00314: val_loss improved from 0.76012 to 0.75816, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7510 - acc: 0.7778 - val_loss: 0.7582 - val_acc: 0.6667\n",
      "Epoch 315/400\n",
      "Epoch 00315: val_loss improved from 0.75816 to 0.75683, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7493 - acc: 0.7778 - val_loss: 0.7568 - val_acc: 0.6667\n",
      "Epoch 316/400\n",
      "Epoch 00316: val_loss improved from 0.75683 to 0.75457, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7479 - acc: 0.7778 - val_loss: 0.7546 - val_acc: 0.6667\n",
      "Epoch 317/400\n",
      "Epoch 00317: val_loss did not improve\n",
      " - 3s - loss: 0.7479 - acc: 0.7778 - val_loss: 0.7595 - val_acc: 0.6667\n",
      "Epoch 318/400\n",
      "Epoch 00318: val_loss did not improve\n",
      " - 3s - loss: 0.8593 - acc: 0.6667 - val_loss: 0.7546 - val_acc: 0.6667\n",
      "Epoch 319/400\n",
      "Epoch 00319: val_loss did not improve\n",
      " - 3s - loss: 0.8137 - acc: 0.7778 - val_loss: 1.1353 - val_acc: 0.3333\n",
      "Epoch 320/400\n",
      "Epoch 00320: val_loss did not improve\n",
      " - 3s - loss: 0.9983 - acc: 0.5556 - val_loss: 1.1307 - val_acc: 0.3333\n",
      "Epoch 321/400\n",
      "Epoch 00321: val_loss did not improve\n",
      " - 3s - loss: 0.9953 - acc: 0.5556 - val_loss: 1.1262 - val_acc: 0.3333\n",
      "Epoch 322/400\n",
      "Epoch 00322: val_loss did not improve\n",
      " - 3s - loss: 0.9924 - acc: 0.5556 - val_loss: 1.1208 - val_acc: 0.3333\n",
      "Epoch 323/400\n",
      "Epoch 00323: val_loss did not improve\n",
      " - 3s - loss: 0.9895 - acc: 0.5556 - val_loss: 1.1069 - val_acc: 0.3333\n",
      "Epoch 324/400\n",
      "Epoch 00324: val_loss did not improve\n",
      " - 3s - loss: 0.9834 - acc: 0.5556 - val_loss: 0.7555 - val_acc: 0.6667\n",
      "Epoch 325/400\n",
      "Epoch 00325: val_loss did not improve\n",
      " - 3s - loss: 0.8218 - acc: 0.8889 - val_loss: 1.2376 - val_acc: 0.3333\n",
      "Epoch 326/400\n",
      "Epoch 00326: val_loss did not improve\n",
      " - 3s - loss: 1.2284 - acc: 0.3333 - val_loss: 1.2134 - val_acc: 0.3333\n",
      "Epoch 327/400\n",
      "Epoch 00327: val_loss did not improve\n",
      " - 3s - loss: 1.1977 - acc: 0.3333 - val_loss: 1.1024 - val_acc: 0.3333\n",
      "Epoch 328/400\n",
      "Epoch 00328: val_loss did not improve\n",
      " - 3s - loss: 1.0246 - acc: 0.5556 - val_loss: 0.9875 - val_acc: 0.3333\n",
      "Epoch 329/400\n",
      "Epoch 00329: val_loss did not improve\n",
      " - 3s - loss: 0.8801 - acc: 0.6667 - val_loss: 0.7689 - val_acc: 0.6667\n",
      "Epoch 330/400\n",
      "Epoch 00330: val_loss did not improve\n",
      " - 3s - loss: 0.8424 - acc: 0.6667 - val_loss: 0.7607 - val_acc: 0.6667\n",
      "Epoch 331/400\n",
      "Epoch 00331: val_loss did not improve\n",
      " - 3s - loss: 0.8061 - acc: 0.7778 - val_loss: 0.7599 - val_acc: 0.6667\n",
      "Epoch 332/400\n",
      "Epoch 00332: val_loss improved from 0.75457 to 0.75396, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7515 - acc: 0.7778 - val_loss: 0.7540 - val_acc: 0.6667\n",
      "Epoch 333/400\n",
      "Epoch 00333: val_loss improved from 0.75396 to 0.75375, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7451 - acc: 0.7778 - val_loss: 0.7538 - val_acc: 0.6667\n",
      "Epoch 334/400\n",
      "Epoch 00334: val_loss improved from 0.75375 to 0.75007, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7439 - acc: 0.7778 - val_loss: 0.7501 - val_acc: 0.6667\n",
      "Epoch 335/400\n",
      "Epoch 00335: val_loss improved from 0.75007 to 0.74852, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7394 - acc: 0.7778 - val_loss: 0.7485 - val_acc: 0.6667\n",
      "Epoch 336/400\n",
      "Epoch 00336: val_loss improved from 0.74852 to 0.74665, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7376 - acc: 0.7778 - val_loss: 0.7467 - val_acc: 0.6667\n",
      "Epoch 337/400\n",
      "Epoch 00337: val_loss improved from 0.74665 to 0.74495, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7360 - acc: 0.7778 - val_loss: 0.7449 - val_acc: 0.6667\n",
      "Epoch 338/400\n",
      "Epoch 00338: val_loss improved from 0.74495 to 0.74323, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7343 - acc: 0.7778 - val_loss: 0.7432 - val_acc: 0.6667\n",
      "Epoch 339/400\n",
      "Epoch 00339: val_loss improved from 0.74323 to 0.74155, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7327 - acc: 0.7778 - val_loss: 0.7415 - val_acc: 0.6667\n",
      "Epoch 340/400\n",
      "Epoch 00340: val_loss improved from 0.74155 to 0.73987, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7310 - acc: 0.7778 - val_loss: 0.7399 - val_acc: 0.6667\n",
      "Epoch 341/400\n",
      "Epoch 00341: val_loss improved from 0.73987 to 0.73820, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7294 - acc: 0.7778 - val_loss: 0.7382 - val_acc: 0.6667\n",
      "Epoch 342/400\n",
      "Epoch 00342: val_loss improved from 0.73820 to 0.73654, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7277 - acc: 0.7778 - val_loss: 0.7365 - val_acc: 0.6667\n",
      "Epoch 343/400\n",
      "Epoch 00343: val_loss improved from 0.73654 to 0.73488, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7261 - acc: 0.7778 - val_loss: 0.7349 - val_acc: 0.6667\n",
      "Epoch 344/400\n",
      "Epoch 00344: val_loss improved from 0.73488 to 0.73323, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7244 - acc: 0.7778 - val_loss: 0.7332 - val_acc: 0.6667\n",
      "Epoch 345/400\n",
      "Epoch 00345: val_loss improved from 0.73323 to 0.73157, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7228 - acc: 0.7778 - val_loss: 0.7316 - val_acc: 0.6667\n",
      "Epoch 346/400\n",
      "Epoch 00346: val_loss improved from 0.73157 to 0.72991, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7211 - acc: 0.7778 - val_loss: 0.7299 - val_acc: 0.6667\n",
      "Epoch 347/400\n",
      "Epoch 00347: val_loss improved from 0.72991 to 0.72826, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7194 - acc: 0.7778 - val_loss: 0.7283 - val_acc: 0.6667\n",
      "Epoch 348/400\n",
      "Epoch 00348: val_loss improved from 0.72826 to 0.72661, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7178 - acc: 0.7778 - val_loss: 0.7266 - val_acc: 0.6667\n",
      "Epoch 349/400\n",
      "Epoch 00349: val_loss improved from 0.72661 to 0.72495, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7161 - acc: 0.7778 - val_loss: 0.7249 - val_acc: 0.6667\n",
      "Epoch 350/400\n",
      "Epoch 00350: val_loss improved from 0.72495 to 0.72328, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7144 - acc: 0.7778 - val_loss: 0.7233 - val_acc: 0.6667\n",
      "Epoch 351/400\n",
      "Epoch 00351: val_loss improved from 0.72328 to 0.72161, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7127 - acc: 0.7778 - val_loss: 0.7216 - val_acc: 0.6667\n",
      "Epoch 352/400\n",
      "Epoch 00352: val_loss improved from 0.72161 to 0.71993, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7110 - acc: 0.7778 - val_loss: 0.7199 - val_acc: 0.6667\n",
      "Epoch 353/400\n",
      "Epoch 00353: val_loss improved from 0.71993 to 0.71825, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7093 - acc: 0.7778 - val_loss: 0.7182 - val_acc: 0.6667\n",
      "Epoch 354/400\n",
      "Epoch 00354: val_loss improved from 0.71825 to 0.71655, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7076 - acc: 0.7778 - val_loss: 0.7165 - val_acc: 0.6667\n",
      "Epoch 355/400\n",
      "Epoch 00355: val_loss improved from 0.71655 to 0.71484, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7058 - acc: 0.7778 - val_loss: 0.7148 - val_acc: 0.6667\n",
      "Epoch 356/400\n",
      "Epoch 00356: val_loss improved from 0.71484 to 0.71311, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7041 - acc: 0.7778 - val_loss: 0.7131 - val_acc: 0.6667\n",
      "Epoch 357/400\n",
      "Epoch 00357: val_loss improved from 0.71311 to 0.71138, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7024 - acc: 0.7778 - val_loss: 0.7114 - val_acc: 0.6667\n",
      "Epoch 358/400\n",
      "Epoch 00358: val_loss improved from 0.71138 to 0.70963, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.7006 - acc: 0.7778 - val_loss: 0.7096 - val_acc: 0.6667\n",
      "Epoch 359/400\n",
      "Epoch 00359: val_loss improved from 0.70963 to 0.70787, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.6989 - acc: 0.7778 - val_loss: 0.7079 - val_acc: 0.6667\n",
      "Epoch 360/400\n",
      "Epoch 00360: val_loss improved from 0.70787 to 0.70610, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.6971 - acc: 0.7778 - val_loss: 0.7061 - val_acc: 0.6667\n",
      "Epoch 361/400\n",
      "Epoch 00361: val_loss improved from 0.70610 to 0.70432, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.6953 - acc: 0.7778 - val_loss: 0.7043 - val_acc: 0.6667\n",
      "Epoch 362/400\n",
      "Epoch 00362: val_loss improved from 0.70432 to 0.70252, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.6935 - acc: 0.7778 - val_loss: 0.7025 - val_acc: 0.6667\n",
      "Epoch 363/400\n",
      "Epoch 00363: val_loss improved from 0.70252 to 0.70071, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.6917 - acc: 0.7778 - val_loss: 0.7007 - val_acc: 0.6667\n",
      "Epoch 364/400\n",
      "Epoch 00364: val_loss improved from 0.70071 to 0.69890, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.6899 - acc: 0.7778 - val_loss: 0.6989 - val_acc: 0.6667\n",
      "Epoch 365/400\n",
      "Epoch 00365: val_loss improved from 0.69890 to 0.69706, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.6881 - acc: 0.7778 - val_loss: 0.6971 - val_acc: 0.6667\n",
      "Epoch 366/400\n",
      "Epoch 00366: val_loss improved from 0.69706 to 0.69525, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.6863 - acc: 0.7778 - val_loss: 0.6953 - val_acc: 0.6667\n",
      "Epoch 367/400\n",
      "Epoch 00367: val_loss improved from 0.69525 to 0.69337, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.6845 - acc: 0.7778 - val_loss: 0.6934 - val_acc: 0.6667\n",
      "Epoch 368/400\n",
      "Epoch 00368: val_loss improved from 0.69337 to 0.69161, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.6826 - acc: 0.7778 - val_loss: 0.6916 - val_acc: 0.6667\n",
      "Epoch 369/400\n",
      "Epoch 00369: val_loss improved from 0.69161 to 0.68957, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.6808 - acc: 0.7778 - val_loss: 0.6896 - val_acc: 0.6667\n",
      "Epoch 370/400\n",
      "Epoch 00370: val_loss improved from 0.68957 to 0.68829, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.6790 - acc: 0.7778 - val_loss: 0.6883 - val_acc: 0.6667\n",
      "Epoch 371/400\n",
      "Epoch 00371: val_loss improved from 0.68829 to 0.68576, saving model to model-3-best.hdf5\n",
      " - 3s - loss: 0.6777 - acc: 0.7778 - val_loss: 0.6858 - val_acc: 0.6667\n",
      "Epoch 372/400\n",
      "Epoch 00372: val_loss did not improve\n",
      " - 3s - loss: 0.7232 - acc: 0.6667 - val_loss: 1.1737 - val_acc: 0.3333\n",
      "Epoch 373/400\n",
      "Epoch 00373: val_loss did not improve\n",
      " - 3s - loss: 1.0048 - acc: 0.5556 - val_loss: 1.1677 - val_acc: 0.3333\n",
      "Epoch 374/400\n",
      "Epoch 00374: val_loss did not improve\n",
      " - 3s - loss: 1.0000 - acc: 0.5556 - val_loss: 1.1626 - val_acc: 0.3333\n",
      "Epoch 375/400\n",
      "Epoch 00375: val_loss did not improve\n",
      " - 3s - loss: 0.9963 - acc: 0.5556 - val_loss: 1.1580 - val_acc: 0.3333\n",
      "Epoch 376/400\n",
      "Epoch 00376: val_loss did not improve\n",
      " - 3s - loss: 0.9930 - acc: 0.5556 - val_loss: 1.1537 - val_acc: 0.3333\n",
      "Epoch 377/400\n",
      "Epoch 00377: val_loss did not improve\n",
      " - 3s - loss: 0.9900 - acc: 0.5556 - val_loss: 1.1496 - val_acc: 0.3333\n",
      "Epoch 378/400\n",
      "Epoch 00378: val_loss did not improve\n",
      " - 3s - loss: 0.9872 - acc: 0.5556 - val_loss: 1.1457 - val_acc: 0.3333\n",
      "Epoch 379/400\n",
      "Epoch 00379: val_loss did not improve\n",
      " - 3s - loss: 0.9846 - acc: 0.5556 - val_loss: 1.1419 - val_acc: 0.3333\n",
      "Epoch 380/400\n",
      "Epoch 00380: val_loss did not improve\n",
      " - 3s - loss: 0.9821 - acc: 0.5556 - val_loss: 1.1381 - val_acc: 0.3333\n",
      "Epoch 381/400\n",
      "Epoch 00381: val_loss did not improve\n",
      " - 3s - loss: 0.9797 - acc: 0.7778 - val_loss: 1.1345 - val_acc: 0.3333\n",
      "Epoch 382/400\n",
      "Epoch 00382: val_loss did not improve\n",
      " - 3s - loss: 0.9774 - acc: 0.7778 - val_loss: 1.1309 - val_acc: 0.3333\n",
      "Epoch 383/400\n",
      "Epoch 00383: val_loss did not improve\n",
      " - 3s - loss: 0.9751 - acc: 0.7778 - val_loss: 1.1274 - val_acc: 0.3333\n",
      "Epoch 384/400\n",
      "Epoch 00384: val_loss did not improve\n",
      " - 3s - loss: 0.9730 - acc: 0.7778 - val_loss: 1.1239 - val_acc: 0.3333\n",
      "Epoch 385/400\n",
      "Epoch 00385: val_loss did not improve\n",
      " - 3s - loss: 0.9708 - acc: 0.7778 - val_loss: 1.1204 - val_acc: 0.5000\n",
      "Epoch 386/400\n",
      "Epoch 00386: val_loss did not improve\n",
      " - 3s - loss: 0.9687 - acc: 0.7778 - val_loss: 1.1170 - val_acc: 0.5000\n",
      "Epoch 387/400\n",
      "Epoch 00387: val_loss did not improve\n",
      " - 3s - loss: 0.9667 - acc: 0.7778 - val_loss: 1.1136 - val_acc: 0.5000\n",
      "Epoch 388/400\n",
      "Epoch 00388: val_loss did not improve\n",
      " - 3s - loss: 0.9647 - acc: 0.7778 - val_loss: 1.1102 - val_acc: 0.5000\n",
      "Epoch 389/400\n",
      "Epoch 00389: val_loss did not improve\n",
      " - 3s - loss: 0.9627 - acc: 0.7778 - val_loss: 1.1068 - val_acc: 0.5000\n",
      "Epoch 390/400\n",
      "Epoch 00390: val_loss did not improve\n",
      " - 3s - loss: 0.9607 - acc: 0.7778 - val_loss: 1.1034 - val_acc: 0.5000\n",
      "Epoch 391/400\n",
      "Epoch 00391: val_loss did not improve\n",
      " - 3s - loss: 0.9588 - acc: 0.7778 - val_loss: 1.1000 - val_acc: 0.5000\n",
      "Epoch 392/400\n",
      "Epoch 00392: val_loss did not improve\n",
      " - 3s - loss: 0.9569 - acc: 0.7778 - val_loss: 1.0966 - val_acc: 0.5000\n",
      "Epoch 393/400\n",
      "Epoch 00393: val_loss did not improve\n",
      " - 3s - loss: 0.9550 - acc: 0.7778 - val_loss: 1.0932 - val_acc: 0.5000\n",
      "Epoch 394/400\n",
      "Epoch 00394: val_loss did not improve\n",
      " - 3s - loss: 0.9531 - acc: 0.7778 - val_loss: 1.0897 - val_acc: 0.5000\n",
      "Epoch 395/400\n",
      "Epoch 00395: val_loss did not improve\n",
      " - 3s - loss: 0.9513 - acc: 0.6667 - val_loss: 1.0862 - val_acc: 0.5000\n",
      "Epoch 396/400\n",
      "Epoch 00396: val_loss did not improve\n",
      " - 3s - loss: 0.9494 - acc: 0.6667 - val_loss: 1.0826 - val_acc: 0.5000\n",
      "Epoch 397/400\n",
      "Epoch 00397: val_loss did not improve\n",
      " - 3s - loss: 0.9475 - acc: 0.6667 - val_loss: 1.0790 - val_acc: 0.5000\n",
      "Epoch 398/400\n",
      "Epoch 00398: val_loss did not improve\n",
      " - 3s - loss: 0.9456 - acc: 0.6667 - val_loss: 1.0752 - val_acc: 0.5000\n",
      "Epoch 399/400\n",
      "Epoch 00399: val_loss did not improve\n",
      " - 3s - loss: 0.9436 - acc: 0.6667 - val_loss: 1.0713 - val_acc: 0.6667\n",
      "Epoch 400/400\n",
      "Epoch 00400: val_loss did not improve\n",
      " - 3s - loss: 0.9416 - acc: 0.6667 - val_loss: 1.0672 - val_acc: 0.6667\n"
     ]
    }
   ],
   "source": [
    "print('Training ------------')\n",
    "model_history=model.fit(x_train, y_train,\n",
    "          validation_data=(x_test,y_test),epochs=400,verbose=2,\n",
    "          batch_size=9,callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEJCAYAAACdePCvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhFBRUQBCCKGi/gMdAt6XDEws/QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2c3d862feb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_plot(model_history,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
