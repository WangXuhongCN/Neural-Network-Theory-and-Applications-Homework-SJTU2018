{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "from numpy import random\n",
    "from sklearn import svm\n",
    "from __future__ import print_function\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from random import choice\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import validation_curve\n",
    "from pylab import *  \n",
    "from matplotlib.ticker import MultipleLocator, FormatStrFormatter  \n",
    "from collections import Counter\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# This is a bit of magic to make matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window.\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (16.0, 9.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data=np.load(\"D:/GitHub/Neural-Network-Theory-and-Applications-Homework-SJTU2018/Homework Assignment 2/data_hw2/train_data.npy\")\n",
    "train_label=np.load(\"D:/GitHub/Neural-Network-Theory-and-Applications-Homework-SJTU2018/Homework Assignment 2/data_hw2/train_label.npy\")\n",
    "test_data=np.load(\"D:/GitHub/Neural-Network-Theory-and-Applications-Homework-SJTU2018/Homework Assignment 2/data_hw2/test_data.npy\")\n",
    "test_label=np.load(\"D:/GitHub/Neural-Network-Theory-and-Applications-Homework-SJTU2018/Homework Assignment 2/data_hw2/test_label.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##原来的标签是{-1,0,1}，现在变为三堆样本标签，正样本是0，负样本是1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_label_0=np.where(train_label == 0, 0, 1)\n",
    "train_label_1=np.where(train_label == 1, 0, 1)\n",
    "train_label_negative1=np.where(train_label == -1, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##建立正负样本索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_index_0_0=[]\n",
    "train_index_0_1=[]\n",
    "train_index_1_0=[]\n",
    "train_index_1_1=[]\n",
    "train_index_negative1_0=[]\n",
    "train_index_negative1_1=[]\n",
    "for i in range(37367):\n",
    "    if train_label_0[i] == 0:\n",
    "        train_index_0_0.append(i)\n",
    "    else:\n",
    "        train_index_0_1.append(i)\n",
    "for i in range(37367):\n",
    "    if train_label_1[i] == 0:\n",
    "        train_index_1_0.append(i)\n",
    "    else:\n",
    "        train_index_1_1.append(i)\n",
    "for i in range(37367):\n",
    "    if train_label_negative1[i] == 0:\n",
    "        train_index_negative1_0.append(i)\n",
    "    else:\n",
    "        train_index_negative1_1.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##将索引随机打乱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(train_index_0_0)\n",
    "np.random.shuffle(train_index_0_1)\n",
    "np.random.shuffle(train_index_1_0)\n",
    "np.random.shuffle(train_index_1_1)\n",
    "np.random.shuffle(train_index_negative1_0)\n",
    "np.random.shuffle(train_index_negative1_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 实现了论文中的正负索引随机分堆，共3个二分类问题，每个二分类问题正样本2堆，负样本4堆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_index_0_0_1st=train_index_0_0[:int(0.5*len(train_index_0_0))]\n",
    "train_index_0_0_2st=train_index_0_0[int(0.5*len(train_index_0_0)):]\n",
    "train_index_0_1_1st=train_index_0_1[:int(0.25*len(train_index_0_1))]\n",
    "train_index_0_1_2st=train_index_0_1[int(0.25*len(train_index_0_1)):int(0.5*len(train_index_0_1))]\n",
    "train_index_0_1_3st=train_index_0_1[int(0.5*len(train_index_0_1)):int(0.75*len(train_index_0_1))]\n",
    "train_index_0_1_4st=train_index_0_1[int(0.75*len(train_index_0_1)):]\n",
    "\n",
    "train_index_1_0_1st=train_index_1_0[:int(0.5*len(train_index_1_0))]\n",
    "train_index_1_0_2st=train_index_1_0[int(0.5*len(train_index_1_0)):]\n",
    "train_index_1_1_1st=train_index_1_1[:int(0.25*len(train_index_1_1))]\n",
    "train_index_1_1_2st=train_index_1_1[int(0.25*len(train_index_1_1)):int(0.5*len(train_index_1_1))]\n",
    "train_index_1_1_3st=train_index_1_1[int(0.5*len(train_index_1_1)):int(0.75*len(train_index_1_1))]\n",
    "train_index_1_1_4st=train_index_1_1[int(0.75*len(train_index_1_1)):]\n",
    "\n",
    "train_index_negative1_0_1st=train_index_negative1_0[:int(0.5*len(train_index_negative1_0))]\n",
    "train_index_negative1_0_2st=train_index_negative1_0[int(0.5*len(train_index_negative1_0)):]\n",
    "train_index_negative1_1_1st=train_index_negative1_1[:int(0.25*len(train_index_negative1_1))]\n",
    "train_index_negative1_1_2st=train_index_negative1_1[int(0.25*len(train_index_negative1_1)):int(0.5*len(train_index_negative1_1))]\n",
    "train_index_negative1_1_3st=train_index_negative1_1[int(0.5*len(train_index_negative1_1)):int(0.75*len(train_index_negative1_1))]\n",
    "train_index_negative1_1_4st=train_index_negative1_1[int(0.75*len(train_index_negative1_1)):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##实现了论文中的正负索引组合，生成8堆混合样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_index_0_11=np.concatenate((train_index_0_0_1st,train_index_0_1_1st)) \n",
    "train_index_0_12=np.concatenate((train_index_0_0_1st,train_index_0_1_2st)) \n",
    "train_index_0_13=np.concatenate((train_index_0_0_1st,train_index_0_1_3st)) \n",
    "train_index_0_14=np.concatenate((train_index_0_0_1st,train_index_0_1_4st)) \n",
    "train_index_0_21=np.concatenate((train_index_0_0_2st,train_index_0_1_1st)) \n",
    "train_index_0_22=np.concatenate((train_index_0_0_2st,train_index_0_1_2st)) \n",
    "train_index_0_23=np.concatenate((train_index_0_0_2st,train_index_0_1_3st)) \n",
    "train_index_0_24=np.concatenate((train_index_0_0_2st,train_index_0_1_4st)) \n",
    "\n",
    "train_index_1_11=np.concatenate((train_index_1_0_1st,train_index_1_1_1st)) \n",
    "train_index_1_12=np.concatenate((train_index_1_0_1st,train_index_1_1_2st)) \n",
    "train_index_1_13=np.concatenate((train_index_1_0_1st,train_index_1_1_3st)) \n",
    "train_index_1_14=np.concatenate((train_index_1_0_1st,train_index_1_1_4st)) \n",
    "train_index_1_21=np.concatenate((train_index_1_0_2st,train_index_1_1_1st)) \n",
    "train_index_1_22=np.concatenate((train_index_1_0_2st,train_index_1_1_2st)) \n",
    "train_index_1_23=np.concatenate((train_index_1_0_2st,train_index_1_1_3st)) \n",
    "train_index_1_24=np.concatenate((train_index_1_0_2st,train_index_1_1_4st)) \n",
    "\n",
    "train_index_negative1_11=np.concatenate((train_index_negative1_0_1st,train_index_negative1_1_1st)) \n",
    "train_index_negative1_12=np.concatenate((train_index_negative1_0_1st,train_index_negative1_1_2st)) \n",
    "train_index_negative1_13=np.concatenate((train_index_negative1_0_1st,train_index_negative1_1_3st)) \n",
    "train_index_negative1_14=np.concatenate((train_index_negative1_0_1st,train_index_negative1_1_4st)) \n",
    "train_index_negative1_21=np.concatenate((train_index_negative1_0_2st,train_index_negative1_1_1st)) \n",
    "train_index_negative1_22=np.concatenate((train_index_negative1_0_2st,train_index_negative1_1_2st)) \n",
    "train_index_negative1_23=np.concatenate((train_index_negative1_0_2st,train_index_negative1_1_3st)) \n",
    "train_index_negative1_24=np.concatenate((train_index_negative1_0_2st,train_index_negative1_1_4st)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##为每个二分类问题建立8个分类器，一共24个SVM分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CalibratedClassifierCV(base_estimator=LinearSVC(C=2e-07, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "            cv=3, method='sigmoid')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_0=CalibratedClassifierCV(svm.LinearSVC(C=2e-7)) \n",
    "svc_1=CalibratedClassifierCV(svm.LinearSVC(C=2e-7)) \n",
    "svc_negative1=CalibratedClassifierCV(svm.LinearSVC(C=2e-7)) \n",
    "\n",
    "svc_0.fit(train_data, train_label_0)\n",
    "svc_1.fit(train_data, train_label_1)\n",
    "svc_negative1.fit(train_data, train_label_negative1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_pred=[]\n",
    "train_pred=[]\n",
    "test_pred_0 = svc_0.predict_proba(test_data)\n",
    "test_pred_1 = svc_1.predict_proba(test_data)\n",
    "test_pred_negative1 = svc_negative1.predict_proba(test_data)\n",
    "for i in range(13588):\n",
    "    maxone=max(test_pred_0[i][0],test_pred_1[i][0],test_pred_negative1[i][0])\n",
    "    if maxone == test_pred_0[i][0]:\n",
    "        test_pred.append(0)\n",
    "    elif maxone == test_pred_1[i][0]:\n",
    "        test_pred.append(1)\n",
    "    elif maxone == test_pred_negative1[i][0]:\n",
    "        test_pred.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_pred_0 = svc_0.predict_proba(train_data)\n",
    "train_pred_1 = svc_1.predict_proba(train_data)\n",
    "train_pred_negative1 = svc_negative1.predict_proba(train_data)\n",
    "for i in range(37367):\n",
    "    maxone=max(train_pred_0[i][0],train_pred_1[i][0],train_pred_negative1[i][0])\n",
    "    if maxone == train_pred_0[i][0]:\n",
    "        train_pred.append(0)\n",
    "    elif maxone == train_pred_1[i][0]:\n",
    "        train_pred.append(1)\n",
    "    elif maxone == train_pred_negative1[i][0]:\n",
    "        train_pred.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.581836914925\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_label, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.603045467926\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(train_label, train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.63      0.47      0.54     12320\n",
      "    class 1       0.54      0.59      0.56     12144\n",
      "    class 2       0.64      0.74      0.69     12903\n",
      "\n",
      "avg / total       0.61      0.60      0.60     37367\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['class 0', 'class 1', 'class 2']\n",
    "print(classification_report(train_label, train_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.68      0.14      0.23      4480\n",
      "    class 1       0.54      0.74      0.62      4416\n",
      "    class 2       0.61      0.86      0.71      4692\n",
      "\n",
      "avg / total       0.61      0.58      0.52     13588\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_label, test_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
